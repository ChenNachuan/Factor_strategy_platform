import pandas as pd
import numpy as np
import sys
from pathlib import Path
from typing import Optional, List
import statsmodels.api as sm

# è·¯å¾„ï¼šæŠŠé¡¹ç›®æ ¹ç›®å½•åŠ å…¥ sys.pathï¼Œä¾¿äºä½¿ç”¨ç»å¯¹åŒ…å¯¼å…¥
PROJECT_ROOT = Path(__file__).resolve().parents[2]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

from data_manager.data import DataManager


def calculate_overnight_factor(
    data_manager: DataManager,
    start_date: str,
    end_date: str,
    stock_codes: Optional[List[str]] = None,
    lookback_period: int = 20,
) -> pd.DataFrame:
    """
    è®¡ç®—æ–°éš”å¤œå› å­ (MIF, Market Inefficiency Factor)ã€‚
    
    æ ¹æ®å›½ç››è¯åˆ¸ã€Šå¦‚ä½•å°†éš”å¤œæ¶¨è·Œå˜ä¸ºæœ‰æ•ˆçš„é€‰è‚¡å› å­?ã€‹ç ”ç©¶æŠ¥å‘Šï¼š
    - MIF å› å­åˆ»ç”»çŸ¥æƒ…äº¤æ˜“è€…çš„ä¿¡æ¯ä¼˜åŠ¿
    - IC å€¼é€šå¸¸ä¸ºè´Ÿï¼ˆåè½¬å› å­ï¼‰
    - å› å­å€¼è¶Šä½ï¼Œæœªæ¥é¢„æœŸæ”¶ç›Šè¶Šé«˜

    å› å­æ„å»ºæ­¥éª¤ï¼š
    1. è®¡ç®—"éš”å¤œæ¶¨è·Œå¹…ç»å¯¹å€¼"ä¸"æ˜¨æ—¥æ¢æ‰‹ç‡"çš„æ»šåŠ¨ç›¸å…³ç³»æ•°
    2. å¯¹ç›¸å…³ç³»æ•°å› å­è¿›è¡Œå¸‚å€¼ä¸­æ€§åŒ–
    3. å¯¹"éš”å¤œè·³ç©ºå› å­"(abs_overnight_ret_mean) è¿›è¡Œå¸‚å€¼ä¸­æ€§åŒ–
    4. å°†æ­¥éª¤2çš„ç»“æœå¯¹æ­¥éª¤3çš„ç»“æœè¿›è¡Œæ­£äº¤åŒ–ï¼ˆå›å½’å–æ®‹å·®ï¼‰

    Parameters
    ----------
    data_manager : DataManager
        æ•°æ®ç®¡ç†å™¨å®ä¾‹
    start_date : str
        å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD'
    end_date : str
        ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD'
    stock_codes : Optional[List[str]]
        è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œå¦‚ä¸º None åˆ™ä½¿ç”¨æ‰€æœ‰å¯ç”¨è‚¡ç¥¨
    lookback_period : int
        æ»šåŠ¨è®¡ç®—å‘¨æœŸï¼Œé»˜è®¤ 20 å¤©

    Returns
    -------
    DataFrame
        MultiIndex (trade_date, ts_code) with single column 'factor'.
        å› å­å€¼ä¸º MIFï¼Œå€¼è¶Šä½è¡¨ç¤ºæœªæ¥é¢„æœŸæ”¶ç›Šè¶Šé«˜ï¼ˆåè½¬å› å­ï¼‰ã€‚
    """
    # è‚¡ç¥¨æ± 
    if stock_codes is None:
        all_daily = data_manager.load_data('daily', start_date=start_date, end_date=end_date, cleaned=True)
        if all_daily is None or all_daily.empty:
            stock_codes = ['000001.SZ', '000002.SZ', '000858.SZ', '600000.SH', '600036.SH', '600519.SH']
        else:
            stock_codes = all_daily['ts_code'].unique().tolist()

    # åŠ è½½æ—¥çº¿æ•°æ®ï¼ˆéœ€è¦è¶³å¤Ÿçš„å†å²æ•°æ®ï¼‰
    buffer_days = lookback_period * 3
    start_date_extended = pd.to_datetime(start_date) - pd.Timedelta(days=buffer_days)
    start_date_extended = start_date_extended.strftime('%Y-%m-%d')
    
    daily = data_manager.load_data(
        'daily', 
        start_date=start_date_extended, 
        end_date=end_date, 
        stock_codes=stock_codes
    )
    if daily is None or daily.empty:
        raise ValueError('æ— æ³•è·å–æ—¥è¡Œæƒ…æ•°æ®')
    
    # ç»Ÿä¸€æ—¥æœŸæ ¼å¼
    daily = daily.copy()
    daily['trade_date'] = pd.to_datetime(daily['trade_date'], errors='coerce')
    if daily['trade_date'].isna().any():
        daily['trade_date'] = pd.to_datetime(daily['trade_date'].astype(str), format='%Y%m%d', errors='coerce')
    daily = daily.dropna(subset=['trade_date'])
    daily = daily.sort_values(['ts_code', 'trade_date']).reset_index(drop=True)

    # æ£€æŸ¥å¿…è¦å­—æ®µ
    required_cols = ['open', 'close', 'pre_close', 'vol', 'amount']
    missing_cols = [col for col in required_cols if col not in daily.columns]
    if missing_cols:
        raise ValueError(f'æ—¥çº¿æ•°æ®ç¼ºå°‘å¿…è¦å­—æ®µ: {missing_cols}')

    print(f"\nè®¡ç®—éš”å¤œå› å­ (MIF)...")
    print(f"å›çœ‹å‘¨æœŸ: {lookback_period} å¤©")
    
    # æ­¥éª¤ 1: è®¡ç®—ä¸­é—´å˜é‡
    print("\n[1/5] è®¡ç®—ä¸­é—´å˜é‡...")
    
    # éš”å¤œæ”¶ç›Šç‡ = ä»Šæ—¥å¼€ç›˜ä»· / æ˜¨æ—¥æ”¶ç›˜ä»· - 1
    daily['overnight_ret'] = daily.groupby('ts_code')['open'].transform(
        lambda x: x / x.shift(1)
    ) - 1
    
    # éš”å¤œæ¶¨è·Œå¹…ç»å¯¹å€¼
    daily['abs_overnight_ret'] = daily['overnight_ret'].abs()
    
    # è®¡ç®—æ¢æ‰‹ç‡æ›¿ä»£æŒ‡æ ‡ï¼šæˆäº¤é‡ / æˆäº¤é‡å‡å€¼
    # æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬ï¼ŒçœŸå®æ¢æ‰‹ç‡ = æˆäº¤é‡ / æµé€šè‚¡æœ¬
    daily['turnover_proxy'] = daily.groupby('ts_code')['vol'].transform(
        lambda x: x / x.rolling(window=20, min_periods=1).mean()
    )
    
    # æ˜¨æ—¥æ¢æ‰‹ç‡ï¼ˆä½¿ç”¨æ›¿ä»£æŒ‡æ ‡ï¼‰
    daily['yesterday_turn'] = daily.groupby('ts_code')['turnover_proxy'].shift(1)
    
    # å¯¹æ•°å¸‚å€¼æ›¿ä»£ï¼šä½¿ç”¨æˆäº¤é¢ä½œä¸ºå¸‚å€¼çš„ä»£ç†å˜é‡
    # æ³¨æ„ï¼šè¿™æ˜¯ç®€åŒ–æ–¹æ¡ˆï¼ŒçœŸå®å¸‚å€¼éœ€è¦ä»åŸºæœ¬é¢æ•°æ®è·å–
    daily['log_market_cap'] = np.log(daily['amount'] + 1)  # åŠ 1é¿å…log(0)
    
    # éš”å¤œè·³ç©ºå› å­å‡å€¼ï¼ˆ20æ—¥å‡å€¼ï¼‰
    daily['abs_overnight_ret_mean'] = daily.groupby('ts_code')['abs_overnight_ret'].transform(
        lambda x: x.rolling(window=lookback_period, min_periods=lookback_period).mean()
    )
    
    # æ­¥éª¤ 2: è®¡ç®—æ»šåŠ¨ç›¸å…³ç³»æ•°
    print(f"[2/5] è®¡ç®— {lookback_period} æ—¥æ»šåŠ¨ç›¸å…³ç³»æ•°...")
    
    def rolling_corr(group):
        """è®¡ç®—å•ä¸ªè‚¡ç¥¨çš„æ»šåŠ¨ç›¸å…³ç³»æ•°"""
        df = group[['trade_date', 'abs_overnight_ret', 'yesterday_turn']].copy()
        
        # è®¡ç®—æ»šåŠ¨ç›¸å…³ç³»æ•°
        corr_series = df['abs_overnight_ret'].rolling(
            window=lookback_period, 
            min_periods=lookback_period
        ).corr(df['yesterday_turn'])
        
        df['corr_factor'] = corr_series
        return df[['trade_date', 'corr_factor']]
    
    corr_parts = []
    for code, group in daily.groupby('ts_code'):
        corr_result = rolling_corr(group)
        corr_result['ts_code'] = code
        corr_parts.append(corr_result)
    
    corr_data = pd.concat(corr_parts, axis=0, ignore_index=True)
    
    # åˆå¹¶å›åŸå§‹æ•°æ®
    daily = pd.merge(
        daily,
        corr_data[['ts_code', 'trade_date', 'corr_factor']],
        on=['ts_code', 'trade_date'],
        how='left'
    )
    
    # æ­¥éª¤ 3 & 4: å¸‚å€¼ä¸­æ€§åŒ–
    print("[3/5] å¯¹ç›¸å…³ç³»æ•°å› å­è¿›è¡Œå¸‚å€¼ä¸­æ€§åŒ–...")
    print("[4/5] å¯¹éš”å¤œè·³ç©ºå› å­è¿›è¡Œå¸‚å€¼ä¸­æ€§åŒ–...")
    
    def neutralize_by_market_cap(group, factor_col):
        """å¸‚å€¼ä¸­æ€§åŒ–ï¼šå¯¹å› å­è¿›è¡Œå¸‚å€¼å›å½’ï¼Œå–æ®‹å·®"""
        clean_group = group[[factor_col, 'log_market_cap']].dropna()
        
        if clean_group.shape[0] < 2:
            return pd.Series(np.nan, index=group.index)
        
        Y = clean_group[factor_col]
        X = sm.add_constant(clean_group['log_market_cap'])
        
        try:
            model = sm.OLS(Y, X).fit()
            residuals = pd.Series(model.resid, index=clean_group.index)
            return residuals.reindex(group.index)
        except:
            return pd.Series(np.nan, index=group.index)
    
    # æŒ‰æ—¥æœŸåˆ†ç»„è¿›è¡Œä¸­æ€§åŒ–ï¼ˆå¿½ç•¥ pandas å¼ƒç”¨è­¦å‘Šï¼‰
    import warnings
    with warnings.catch_warnings():
        warnings.filterwarnings('ignore', category=DeprecationWarning)
        daily['corr_factor_neutralized'] = daily.groupby('trade_date', group_keys=False).apply(
            lambda x: neutralize_by_market_cap(x, 'corr_factor')
        )
        
        daily['abs_overnight_ret_desize'] = daily.groupby('trade_date', group_keys=False).apply(
            lambda x: neutralize_by_market_cap(x, 'abs_overnight_ret_mean')
        )
    
    # æ­¥éª¤ 5: æ­£äº¤åŒ–ï¼ˆå›å½’å–æ®‹å·®ï¼‰
    print("[5/5] å¯¹éš”å¤œè·³ç©ºå› å­è¿›è¡Œæ­£äº¤åŒ–ï¼Œç”Ÿæˆ MIF...")
    
    def orthogonalize(group):
        """æ­£äº¤åŒ–ï¼šcorr_factor_neutralized å¯¹ abs_overnight_ret_desize å›å½’å–æ®‹å·®"""
        clean_group = group[['corr_factor_neutralized', 'abs_overnight_ret_desize']].dropna()
        
        if clean_group.shape[0] < 2:
            return pd.Series(np.nan, index=group.index)
        
        Y = clean_group['corr_factor_neutralized']
        X = sm.add_constant(clean_group['abs_overnight_ret_desize'])
        
        try:
            model = sm.OLS(Y, X).fit()
            residuals = pd.Series(model.resid, index=clean_group.index)
            return residuals.reindex(group.index)
        except:
            return pd.Series(np.nan, index=group.index)
    
    with warnings.catch_warnings():
        warnings.filterwarnings('ignore', category=DeprecationWarning)
        daily['MIF'] = daily.groupby('trade_date', group_keys=False).apply(orthogonalize)
    
    # è¿‡æ»¤åˆ°æŒ‡å®šæ—¥æœŸèŒƒå›´
    daily = daily[daily['trade_date'] >= start_date]
    
    # æ„å»ºå› å­æ•°æ®
    factor_data = daily[['trade_date', 'ts_code', 'MIF']].copy()
    factor_data = factor_data.dropna()
    
    # è®¾ç½® MultiIndex
    factor = factor_data.set_index(['trade_date', 'ts_code'])[['MIF']]
    factor.columns = ['factor']
    factor.index.names = ['trade_date', 'ts_code']
    
    print(f"\nMIF å› å­è®¡ç®—å®Œæˆï¼å…± {len(factor)} æ¡è®°å½•")
    print(f"å› å­å€¼èŒƒå›´: [{factor['factor'].min():.6f}, {factor['factor'].max():.6f}]")
    
    return factor


def run_overnight_factor_backtest(start_date: str = '2024-01-01',
                                  end_date: str = '2024-02-29',
                                  stock_codes: Optional[List[str]] = None,
                                  lookback_period: int = 20,
                                  rebalance_freq: str = 'weekly',
                                  transaction_cost: float = 0.0003,
                                  long_direction: str = 'low') -> dict:
    """
    ä½¿ç”¨ BacktestEngine ä¸»è·¯å¾„è¿è¡Œéš”å¤œå› å­ç­–ç•¥å›æµ‹ï¼Œå¹¶é›†æˆ PerformanceAnalyzer è®¡ç®— ICã€‚
    
    æ ¹æ®ç ”ç©¶æŠ¥å‘Šï¼ŒMIF æ˜¯åè½¬å› å­ï¼Œåº”åšå¤šä½ MIF è‚¡ç¥¨ï¼ˆä¿¡æ¯ä¼˜åŠ¿è¾ƒå¼±ï¼Œè¢«ä½ä¼°ï¼‰ã€‚
    
    Parameters
    ----------
    start_date : str
        å›æµ‹å¼€å§‹æ—¥æœŸ
    end_date : str
        å›æµ‹ç»“æŸæ—¥æœŸ
    stock_codes : Optional[List[str]]
        è‚¡ç¥¨ä»£ç åˆ—è¡¨
    lookback_period : int
        æ»šåŠ¨è®¡ç®—å‘¨æœŸï¼Œé»˜è®¤ 20 å¤©
    rebalance_freq : str
        è°ƒä»“é¢‘ç‡ï¼š'daily', 'weekly', 'monthly'
    transaction_cost : float
        å•è¾¹äº¤æ˜“è´¹ç”¨ï¼Œé»˜è®¤ 0.03%
    long_direction : str
        å¤šå¤´æ–¹å‘ï¼š'low' åšå¤šä½MIFï¼ˆæ¨èï¼‰ï¼Œ'high' åšå¤šé«˜MIF
        
    Returns
    -------
    dict
        åŒ…å«å› å­æ•°æ®ã€ç»„åˆæ”¶ç›Šã€ä¸šç»©æŒ‡æ ‡å’ŒICåˆ†æç»“æœ
    """
    # åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
    data_manager = DataManager()

    # ä½¿ç”¨ BacktestEngine ä¸»è·¯å¾„
    from backtest_engine.engine import BacktestEngine
    
    # è®¡ç®— MIF å› å­
    print("\n" + "=" * 60)
    print("å¼€å§‹è®¡ç®—éš”å¤œå› å­ (MIF)...")
    
    factor_data = calculate_overnight_factor(
        data_manager=data_manager,
        start_date=start_date,
        end_date=end_date,
        stock_codes=stock_codes,
        lookback_period=lookback_period
    )
    
    print("=" * 60 + "\n")
    
    # åˆ›å»ºå›æµ‹å¼•æ“
    engine = BacktestEngine(
        data_manager=data_manager,
        fee=transaction_cost,
        long_direction=long_direction,
        rebalance_freq=rebalance_freq,
        factor_name='factor',
    )
    
    # ç›´æ¥è®¾ç½®å› å­æ•°æ®
    engine.factor_data = factor_data
    
    # å‡†å¤‡æ”¶ç›Šç‡æ•°æ®
    stock_list = factor_data.index.get_level_values('ts_code').unique().tolist()
    stock_data = data_manager.load_data(
        'daily',
        start_date=start_date,
        end_date=end_date,
        stock_codes=stock_list
    )
    
    if stock_data is None or stock_data.empty:
        raise ValueError('æ— æ³•åŠ è½½è‚¡ç¥¨æ•°æ®ç”¨äºå›æµ‹')
    
    # è®¡ç®—æ¬¡æ—¥æ”¶ç›Šç‡
    stock_data = stock_data.sort_values(['ts_code', 'trade_date'])
    stock_data['next_return'] = stock_data.groupby('ts_code')['close'].pct_change().shift(-1)
    
    # åˆå¹¶å› å­å’Œæ”¶ç›Šç‡
    factor_reset = factor_data.reset_index()
    stock_subset = stock_data[['ts_code', 'trade_date', 'next_return']].copy()
    
    engine.combined_data = pd.merge(
        factor_reset,
        stock_subset,
        on=['ts_code', 'trade_date'],
        how='inner'
    )
    engine.combined_data.dropna(subset=['factor', 'next_return'], inplace=True)
    
    # è¿è¡Œå›æµ‹
    print("å¼€å§‹å›æµ‹...")
    portfolio_returns = engine.run()
    print("å›æµ‹å®Œæˆï¼\n")

    # è®¡ç®—åŸºæœ¬ä¸šç»©æŒ‡æ ‡ï¼ˆåŸºäº Long_Onlyï¼‰
    if not isinstance(portfolio_returns, pd.DataFrame) or 'Long_Only' not in portfolio_returns.columns:
        raise ValueError('å›æµ‹ç»“æœç¼ºå°‘ Long_Only åˆ—')

    series = portfolio_returns['Long_Only']
    cum = (1 + series).cumprod()
    total_return = float(cum.iloc[-1] - 1) if len(cum) else np.nan
    trading_days = len(series)
    annualized_return = float(cum.iloc[-1] ** (252 / trading_days) - 1) if trading_days > 0 else np.nan
    volatility = float(series.std() * np.sqrt(252))
    sharpe_ratio = float(annualized_return / volatility) if volatility > 0 and not np.isnan(annualized_return) else 0.0
    running_max = cum.cummax()
    drawdown = cum / running_max - 1
    max_drawdown = float(drawdown.min()) if not drawdown.empty else np.nan

    # é›†æˆ PerformanceAnalyzerï¼ˆå« IC åˆ†æï¼‰
    analyzer = engine.get_performance_analysis()
    metrics_df = analyzer.calculate_metrics()
    ic_series = analyzer.ic_series
    analysis_results = {
        'metrics': metrics_df,
        'ic_series': ic_series
    }

    return {
        'factor_data': engine.factor_data,
        'portfolio_returns': portfolio_returns,
        'positions': None,
        'performance_metrics': {
            'total_return': total_return,
            'annualized_return': annualized_return,
            'volatility': volatility,
            'sharpe_ratio': sharpe_ratio,
            'max_drawdown': max_drawdown,
            'rebalance_count': len(engine._get_rebalance_dates()),
        },
        'analysis_results': analysis_results,
    }


def main():
    """ä¸»å‡½æ•°ï¼šæ¼”ç¤ºéš”å¤œå› å­è®¡ç®—å’Œå›æµ‹"""
    print("éš”å¤œå› å­ (MIF) ç­–ç•¥æ¼”ç¤º")
    print("=" * 50)

    try:
        # é…ç½®å‚æ•°
        config = {
            'start_date': '2020-01-01',
            'end_date': '2023-12-31',
            'lookback_period': 20,
            'rebalance_freq': 'weekly',
            'transaction_cost': 0.0003,  # 0.03% äº¤æ˜“è´¹ç”¨
            'long_direction': 'low',  # åšå¤šä½ MIFï¼ˆåè½¬å› å­ï¼‰
        }

        print("å›æµ‹é…ç½®:")
        for key, value in config.items():
            print(f"  {key}: {value}")

        # è¿è¡Œå›æµ‹
        results = run_overnight_factor_backtest(**config)

        # ç»“æœæ€»ç»“ï¼ˆåŸºäº Long_Onlyï¼‰
        print("\nå›æµ‹ç»“æœæ€»ç»“ (Long_Only):")
        metrics = results['performance_metrics']
        print(f"  å¤æ™®æ¯”ç‡: {metrics['sharpe_ratio']:.3f}")
        print(f"  æ€»æ”¶ç›Š: {metrics['total_return']:.2%}")
        print(f"  å¹´åŒ–æ”¶ç›Š: {metrics['annualized_return']:.2%}")
        print(f"  å¹´åŒ–æ³¢åŠ¨: {metrics['volatility']:.2%}")
        print(f"  æœ€å¤§å›æ’¤: {metrics['max_drawdown']:.2%}")
        print(f"  è°ƒä»“æ¬¡æ•°: {metrics['rebalance_count']}")

        # IC åˆ†æ
        if results['analysis_results']['ic_series'] is not None:
            ic = results['analysis_results']['ic_series']
            print(f"\nIC åˆ†æ:")
            print(f"  IC å‡å€¼: {ic.mean():.4f}")
            print(f"  IC æ ‡å‡†å·®: {ic.std():.4f}")
            print(f"  ICIR: {ic.mean() / ic.std():.4f}" if ic.std() > 0 else "  ICIR: N/A")
            print(f"  IC>0 å æ¯”: {(ic > 0).mean():.2%}")
            print(f"\nğŸ’¡ æ³¨æ„: MIF æ˜¯åè½¬å› å­ï¼ŒIC å‡å€¼é€šå¸¸ä¸ºè´Ÿå€¼ï¼ˆåšå¤šä½MIFï¼‰")

        print("\néš”å¤œå› å­ç­–ç•¥æ¼”ç¤ºå®Œæˆ!")

    except Exception as e:
        print(f"æ¼”ç¤ºè¿è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise


if __name__ == "__main__":
    main()
