"""
å­£åº¦ç›ˆåˆ©æƒŠå–œ (Quarterly Earnings Surprise) å› å­

å› å­é€»è¾‘ï¼š
-----------
é€šè¿‡å¯¹æ¯”æœ¬å­£åº¦EPSä¸å»å¹´åŒæœŸEPSçš„å·®å¼‚ï¼Œæ•æ‰å…¬å¸ç›ˆåˆ©çš„å­£åº¦æ”¹å–„ä¿¡å·ã€‚
ä½¿ç”¨å…¬å‘Šæ—¥å‰ä¸€å¤©çš„è‚¡ä»·è¿›è¡Œæ ‡å‡†åŒ–ï¼Œä½¿å¾—å› å­å€¼åœ¨ä¸åŒè‚¡ç¥¨é—´å¯æ¯”ã€‚

å› å­å…¬å¼ï¼š
---------
Factor_Value = (EPS_current - EPS_last_year_same_quarter) / Price_announcement_date-1

å…¶ä¸­ï¼š
- EPS_current: æœ¬å­£åº¦æ¯è‚¡æ”¶ç›Š
- EPS_last_year_same_quarter: å»å¹´åŒæœŸæ¯è‚¡æ”¶ç›Š
- Price_announcement_date-1: è´¢æŠ¥å…¬å‘Šæ—¥å‰ä¸€å¤©çš„æ”¶ç›˜ä»·

æ•°æ®æ¥æºï¼š
---------
1. è´¢åŠ¡æ•°æ®: incomeè¡¨ï¼ˆåˆ©æ¶¦è¡¨ï¼‰
   - ts_code: è‚¡ç¥¨ä»£ç 
   - ann_date: è´¢æŠ¥å…¬å‘Šæ—¥
   - end_date: æŠ¥å‘ŠæœŸç»“æŸæ—¥
   - eps: åŸºæœ¬æ¯è‚¡æ”¶ç›Š
   - report_type: æŠ¥å‘Šç±»å‹ï¼ˆ1=å¹´æŠ¥,2=ä¸­æŠ¥,3=å­£æŠ¥ï¼‰

2. è¡Œæƒ…æ•°æ®: dailyè¡¨
   - close: æ”¶ç›˜ä»·

å› å­ç‰¹å¾ï¼š
---------
- å› å­ç±»å‹: åŸºæœ¬é¢ - ç›ˆåˆ©è´¨é‡å› å­
- å› å­æ–¹å‘: åšå¤šé«˜å› å­å€¼ï¼ˆç›ˆåˆ©æ”¹å–„çš„è‚¡ç¥¨ï¼‰
- æ›´æ–°é¢‘ç‡: æ¯æ—¥ï¼ˆåœ¨è´¢æŠ¥å…¬å‘Šæ—¥æ›´æ–°ï¼Œå…¶ä»–æ—¥æœŸå»¶ç»­ä¸Šæ¬¡å€¼ï¼‰
- é€‚ç”¨èŒƒå›´: å…¨å¸‚åœºAè‚¡

åº”ç”¨ç­–ç•¥ï¼š
---------
1. åœ¨æ¯ä¸ªè´¢æŠ¥å…¬å‘Šæ—¥(ann_date)ï¼Œè®¡ç®—è¯¥è‚¡ç¥¨çš„å› å­å€¼
2. è¯¥å› å­å€¼åœ¨è‚¡ç¥¨ä¸Šä¿ç•™ï¼Œç›´åˆ°ä¸‹ä¸€ä¸ªè´¢æŠ¥å…¬å‘Šæ—¥
3. è¿™æ ·å½¢æˆæ¯æ—¥æ›´æ–°çš„å› å­åºåˆ—ï¼Œå¯ç”¨äºå›æµ‹
"""

import pandas as pd
import numpy as np
import sys
from pathlib import Path
from typing import Optional, List
from datetime import datetime, timedelta

# è·¯å¾„ï¼šæŠŠé¡¹ç›®æ ¹ç›®å½•åŠ å…¥ sys.pathï¼Œä¾¿äºä½¿ç”¨ç»å¯¹åŒ…å¯¼å…¥
PROJECT_ROOT = Path(__file__).resolve().parents[2]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

from data_manager.data import DataManager


def calculate_earnings_surprise_factor(
    data_manager: DataManager,
    start_date: str,
    end_date: str,
    stock_codes: Optional[List[str]] = None,
) -> pd.DataFrame:
    """
    è®¡ç®—å­£åº¦ç›ˆåˆ©æƒŠå–œå› å­
    
    å› å­è®¡ç®—æ­¥éª¤ï¼š
    1. åŠ è½½åˆ©æ¶¦è¡¨æ•°æ®ï¼Œè·å–æ¯ä¸ªå­£åº¦çš„EPSå’Œå…¬å‘Šæ—¥
    2. å¯¹æ¯ä¸ªå­£åº¦è´¢æŠ¥ï¼Œæ‰¾åˆ°å…¶å»å¹´åŒæœŸçš„å­£æŠ¥
    3. è®¡ç®—EPSåŒæ¯”å·®å€¼ (EPS_diff)
    4. è·å–å…¬å‘Šæ—¥å‰ä¸€å¤©çš„è‚¡ä»·
    5. æ ‡å‡†åŒ–: Factor = EPS_diff / Price
    6. å°†å› å­å€¼åœ¨å…¬å‘Šæ—¥åˆ°ä¸‹ä¸€ä¸ªå…¬å‘Šæ—¥ä¹‹é—´å»¶ç»­ï¼ˆforward fillï¼‰
    
    Parameters
    ----------
    data_manager : DataManager
        æ•°æ®ç®¡ç†å™¨å®ä¾‹
    start_date : str
        å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD'
    end_date : str
        ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD'
    stock_codes : Optional[List[str]]
        è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œå¦‚ä¸º None åˆ™ä½¿ç”¨æ‰€æœ‰å¯ç”¨è‚¡ç¥¨

    Returns
    -------
    DataFrame
        MultiIndex (trade_date, ts_code) with single column 'factor'.
        å› å­å€¼ä¸ºæ ‡å‡†åŒ–çš„ç›ˆåˆ©æƒŠå–œå€¼ï¼Œå€¼è¶Šé«˜è¡¨ç¤ºç›ˆåˆ©æ”¹å–„è¶Šæ˜æ˜¾ã€‚
        
    Notes
    -----
    - åªä½¿ç”¨å­£æŠ¥æ•°æ®ï¼ˆå¯ä»¥æ‰©å±•åˆ°åŒ…æ‹¬å¹´æŠ¥ã€ä¸­æŠ¥ï¼‰
    - å»å¹´åŒæœŸæ•°æ®ç¼ºå¤±çš„è®°å½•ä¼šè¢«è·³è¿‡
    - è‚¡ä»·ä¸º0æˆ–ç¼ºå¤±çš„è®°å½•ä¼šè¢«è¿‡æ»¤
    - å¼‚å¸¸å€¼ï¼ˆç»å¯¹å€¼è¿‡å¤§ï¼‰ä¼šè¢«æˆªæ–­å¤„ç†
    """
    print(f"\n{'='*60}")
    print("å­£åº¦ç›ˆåˆ©æƒŠå–œ (Quarterly Earnings Surprise) å› å­è®¡ç®—")
    print(f"{'='*60}")
    
    # æ­¥éª¤1: åŠ è½½åˆ©æ¶¦è¡¨æ•°æ®
    print("\næ­¥éª¤1: åŠ è½½åˆ©æ¶¦è¡¨æ•°æ®...")
    income_data = data_manager.load_data('income', stock_codes=stock_codes)
    
    if income_data is None or income_data.empty:
        raise ValueError("æ— æ³•åŠ è½½åˆ©æ¶¦è¡¨æ•°æ®")
    
    print(f"âœ… åŠ è½½åˆ©æ¶¦è¡¨æ•°æ®: {len(income_data):,} æ¡è®°å½•")
    
    # æ£€æŸ¥å¿…è¦å­—æ®µ
    required_fields = ['ts_code', 'ann_date', 'end_date', 'basic_eps']
    missing_fields = [f for f in required_fields if f not in income_data.columns]
    if missing_fields:
        raise ValueError(f"åˆ©æ¶¦è¡¨æ•°æ®ç¼ºå°‘å¿…è¦å­—æ®µ: {missing_fields}")
    
    # è½¬æ¢æ—¥æœŸæ ¼å¼
    income_data = income_data.copy()
    income_data['ann_date'] = pd.to_datetime(income_data['ann_date'])
    income_data['end_date'] = pd.to_datetime(income_data['end_date'])
    
    # è¿‡æ»¤ï¼šåªä¿ç•™æœ‰å…¬å‘Šæ—¥å’ŒæŠ¥å‘ŠæœŸçš„æ•°æ®
    income_data = income_data.dropna(subset=['ann_date', 'end_date', 'basic_eps'])
    print(f"âœ… è¿‡æ»¤åæ•°æ®: {len(income_data):,} æ¡è®°å½•")
    
    # æ­¥éª¤2: è¯†åˆ«å­£åº¦æŠ¥å‘Š
    print("\næ­¥éª¤2: è¯†åˆ«å­£åº¦æŠ¥å‘Š...")
    # æå–å­£åº¦ä¿¡æ¯ï¼ˆQ1, Q2, Q3, Q4ï¼‰
    income_data['year'] = income_data['end_date'].dt.year
    income_data['quarter'] = income_data['end_date'].dt.quarter
    
    # åªä¿ç•™å­£æŠ¥æ•°æ®ï¼ˆå¯ä»¥é€šè¿‡end_dateçš„æœˆä»½åˆ¤æ–­ï¼š3,6,9,12æœˆï¼‰
    income_data = income_data[income_data['end_date'].dt.month.isin([3, 6, 9, 12])]
    print(f"âœ… å­£æŠ¥æ•°æ®: {len(income_data):,} æ¡è®°å½•")
    print(f"   è¦†ç›–è‚¡ç¥¨: {income_data['ts_code'].nunique()} åª")
    print(f"   æ—¶é—´èŒƒå›´: {income_data['end_date'].min()} è‡³ {income_data['end_date'].max()}")
    
    # æ­¥éª¤3: å¯¹é½å»å¹´åŒæœŸæ•°æ®
    print("\næ­¥éª¤3: å¯¹é½å»å¹´åŒæœŸæ•°æ®...")
    # ä¸ºæ¯æ¡è®°å½•æ·»åŠ å»å¹´åŒæœŸçš„end_date
    income_data['last_year_end_date'] = income_data['end_date'] - pd.DateOffset(years=1)
    
    # è‡ªè¿æ¥ï¼šåŒ¹é…å»å¹´åŒæœŸæ•°æ®
    # è¿æ¥æ¡ä»¶ï¼šç›¸åŒè‚¡ç¥¨ + ç›¸åŒå­£åº¦ + ç›¸éš”ä¸€å¹´
    merged = income_data.merge(
        income_data[['ts_code', 'end_date', 'basic_eps', 'ann_date']],
        left_on=['ts_code', 'last_year_end_date'],
        right_on=['ts_code', 'end_date'],
        suffixes=('_current', '_last_year'),
        how='left'
    )
    
    print(f"âœ… å¯¹é½å‰æ•°æ®: {len(income_data):,} æ¡")
    print(f"âœ… å¯¹é½åæ•°æ®: {len(merged):,} æ¡")
    
    # è¿‡æ»¤ï¼šåªä¿ç•™æˆåŠŸåŒ¹é…åˆ°å»å¹´åŒæœŸçš„è®°å½•
    merged = merged.dropna(subset=['basic_eps_last_year'])
    print(f"âœ… æˆåŠŸåŒ¹é…å»å¹´åŒæœŸ: {len(merged):,} æ¡è®°å½•")
    
    if merged.empty:
        raise ValueError("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å¯ä»¥åŒ¹é…å»å¹´åŒæœŸçš„æ•°æ®ï¼Œæ— æ³•è®¡ç®—å› å­")
    
    # æ­¥éª¤4: è®¡ç®—EPSå·®å€¼
    print("\næ­¥éª¤4: è®¡ç®—EPSåŒæ¯”å·®å€¼...")
    merged['eps_diff'] = merged['basic_eps_current'] - merged['basic_eps_last_year']
    
    # ç»Ÿè®¡
    print(f"   EPS_diff ç»Ÿè®¡:")
    print(f"     å‡å€¼: {merged['eps_diff'].mean():.4f}")
    print(f"     ä¸­ä½æ•°: {merged['eps_diff'].median():.4f}")
    print(f"     æ ‡å‡†å·®: {merged['eps_diff'].std():.4f}")
    print(f"     æ­£å€¼å æ¯”: {(merged['eps_diff'] > 0).sum() / len(merged) * 100:.1f}%")
    
    # æ­¥éª¤5: åŠ è½½è¡Œæƒ…æ•°æ®ï¼Œè·å–å…¬å‘Šæ—¥å‰ä¸€å¤©çš„è‚¡ä»·
    print("\næ­¥éª¤5: è·å–å…¬å‘Šæ—¥å‰ä¸€å¤©çš„è‚¡ä»·...")
    
    # è·å–æ‰€æœ‰éœ€è¦çš„è‚¡ç¥¨å’Œæ—¥æœŸèŒƒå›´
    all_stock_codes = merged['ts_code'].unique().tolist()
    # æ‰©å±•æ—¥æœŸèŒƒå›´ä»¥ç¡®ä¿èƒ½è·å–åˆ°å…¬å‘Šæ—¥å‰ä¸€å¤©çš„æ•°æ®
    min_ann_date = merged['ann_date_current'].min() - timedelta(days=5)
    max_ann_date = merged['ann_date_current'].max()
    
    print(f"   åŠ è½½è¡Œæƒ…æ•°æ®: {len(all_stock_codes)} åªè‚¡ç¥¨")
    print(f"   æ—¥æœŸèŒƒå›´: {min_ann_date.date()} è‡³ {max_ann_date.date()}")
    
    daily_data = data_manager.load_data(
        'daily',
        start_date=min_ann_date.strftime('%Y-%m-%d'),
        end_date=max_ann_date.strftime('%Y-%m-%d'),
        stock_codes=all_stock_codes
    )
    
    if daily_data is None or daily_data.empty:
        raise ValueError("æ— æ³•åŠ è½½æ—¥è¡Œæƒ…æ•°æ®")
    
    daily_data = daily_data.copy()
    daily_data['trade_date'] = pd.to_datetime(daily_data['trade_date'])
    print(f"âœ… åŠ è½½è¡Œæƒ…æ•°æ®: {len(daily_data):,} æ¡è®°å½•")
    
    # ä¸ºæ¯ä¸ªå…¬å‘Šæ—¥æ‰¾åˆ°å‰ä¸€äº¤æ˜“æ—¥çš„è‚¡ä»·
    factor_records = []
    
    print("\næ­¥éª¤6: è®¡ç®—å› å­å€¼...")
    for idx, row in merged.iterrows():
        ts_code = row['ts_code']
        ann_date = row['ann_date_current']
        eps_diff = row['eps_diff']
        
        # è·å–è¯¥è‚¡ç¥¨åœ¨å…¬å‘Šæ—¥å‰çš„è¡Œæƒ…æ•°æ®
        stock_daily = daily_data[
            (daily_data['ts_code'] == ts_code) & 
            (daily_data['trade_date'] < ann_date)
        ].sort_values('trade_date')
        
        if stock_daily.empty:
            continue
        
        # è·å–æœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥çš„æ”¶ç›˜ä»·
        price_prev = stock_daily.iloc[-1]['close']
        
        if pd.isna(price_prev) or price_prev <= 0:
            continue
        
        # è®¡ç®—å› å­å€¼ï¼šEPS_diff / Price
        factor_value = eps_diff / price_prev
        
        factor_records.append({
            'ts_code': ts_code,
            'ann_date': ann_date,
            'end_date': row['end_date_current'],
            'eps_current': row['basic_eps_current'],
            'eps_last_year': row['basic_eps_last_year'],
            'eps_diff': eps_diff,
            'price_prev': price_prev,
            'factor': factor_value
        })
    
    factor_df = pd.DataFrame(factor_records)
    print(f"âœ… è®¡ç®—å› å­å€¼: {len(factor_df):,} æ¡è®°å½•")
    
    if factor_df.empty:
        raise ValueError("è®¡ç®—å› å­åæ²¡æœ‰æœ‰æ•ˆæ•°æ®")
    
    # æ­¥éª¤7: å¼‚å¸¸å€¼å¤„ç†
    print("\næ­¥éª¤7: å¼‚å¸¸å€¼å¤„ç†...")
    # ä½¿ç”¨3å€æ ‡å‡†å·®æˆªæ–­
    factor_mean = factor_df['factor'].mean()
    factor_std = factor_df['factor'].std()
    lower_bound = factor_mean - 3 * factor_std
    upper_bound = factor_mean + 3 * factor_std
    
    print(f"   åŸå§‹å› å­ç»Ÿè®¡:")
    print(f"     å‡å€¼: {factor_mean:.6f}")
    print(f"     æ ‡å‡†å·®: {factor_std:.6f}")
    print(f"     èŒƒå›´: [{factor_df['factor'].min():.6f}, {factor_df['factor'].max():.6f}]")
    print(f"   æˆªæ–­èŒƒå›´: [{lower_bound:.6f}, {upper_bound:.6f}]")
    
    # æˆªæ–­å¤„ç†
    outlier_count = ((factor_df['factor'] < lower_bound) | (factor_df['factor'] > upper_bound)).sum()
    factor_df['factor'] = factor_df['factor'].clip(lower=lower_bound, upper=upper_bound)
    print(f"   å¤„ç†å¼‚å¸¸å€¼: {outlier_count} æ¡ ({outlier_count/len(factor_df)*100:.2f}%)")
    
    # æ­¥éª¤8: å°†å› å­å€¼æ‰©å±•åˆ°æ¯æ—¥æ•°æ®ï¼ˆForward Fillï¼‰
    print("\næ­¥éª¤8: æ‰©å±•å› å­å€¼åˆ°æ¯æ—¥...")
    
    # åŠ è½½å›æµ‹æœŸé—´çš„æ‰€æœ‰äº¤æ˜“æ—¥æ•°æ®
    daily_all = data_manager.load_data(
        'daily',
        start_date=start_date,
        end_date=end_date,
        stock_codes=all_stock_codes
    )
    
    if daily_all is None or daily_all.empty:
        raise ValueError("æ— æ³•åŠ è½½å›æµ‹æœŸé—´çš„æ—¥è¡Œæƒ…æ•°æ®")
    
    daily_all = daily_all.copy()
    daily_all['trade_date'] = pd.to_datetime(daily_all['trade_date'])
    
    # åˆ›å»ºæ‰€æœ‰äº¤æ˜“æ—¥å’Œè‚¡ç¥¨çš„ç»„åˆ
    all_dates = daily_all['trade_date'].unique()
    all_combinations = daily_all[['trade_date', 'ts_code']].drop_duplicates()
    
    print(f"   å›æµ‹æœŸé—´: {len(all_dates)} ä¸ªäº¤æ˜“æ—¥")
    print(f"   è‚¡ç¥¨æ•°é‡: {len(all_stock_codes)} åª")
    print(f"   æ€»ç»„åˆæ•°: {len(all_combinations):,}")
    
    # å°†å› å­æ•°æ®åˆå¹¶åˆ°æ¯æ—¥æ•°æ®ä¸Š
    # ç­–ç•¥ï¼šæ¯ä¸ªå…¬å‘Šæ—¥çš„å› å­å€¼ä¿æŒåˆ°ä¸‹ä¸€ä¸ªå…¬å‘Šæ—¥
    factor_daily_list = []
    
    for ts_code in all_stock_codes:
        # è·å–è¯¥è‚¡ç¥¨çš„æ‰€æœ‰å› å­è®°å½•ï¼ˆæŒ‰å…¬å‘Šæ—¥æ’åºï¼‰
        stock_factors = factor_df[factor_df['ts_code'] == ts_code].sort_values('ann_date')
        
        if stock_factors.empty:
            continue
        
        # è·å–è¯¥è‚¡ç¥¨çš„æ‰€æœ‰äº¤æ˜“æ—¥
        stock_dates = all_combinations[all_combinations['ts_code'] == ts_code]['trade_date'].values
        
        # å¯¹æ¯ä¸ªäº¤æ˜“æ—¥ï¼Œæ‰¾åˆ°æœ€è¿‘çš„ï¼ˆä¸”ä¸æ™šäºè¯¥æ—¥æœŸçš„ï¼‰å…¬å‘Šæ—¥çš„å› å­å€¼
        for trade_date in stock_dates:
            # æ‰¾åˆ°åœ¨è¯¥äº¤æ˜“æ—¥ä¹‹å‰æˆ–å½“å¤©çš„æœ€è¿‘å…¬å‘Š
            valid_factors = stock_factors[stock_factors['ann_date'] <= trade_date]
            
            if not valid_factors.empty:
                # ä½¿ç”¨æœ€è¿‘çš„å› å­å€¼
                latest_factor = valid_factors.iloc[-1]['factor']
                factor_daily_list.append({
                    'trade_date': trade_date,
                    'ts_code': ts_code,
                    'factor': latest_factor
                })
    
    result_df = pd.DataFrame(factor_daily_list)
    
    if result_df.empty:
        raise ValueError("æ‰©å±•åˆ°æ¯æ—¥åæ²¡æœ‰æœ‰æ•ˆæ•°æ®")
    
    print(f"âœ… æ¯æ—¥å› å­æ•°æ®: {len(result_df):,} æ¡è®°å½•")
    
    # è½¬æ¢ä¸ºMultiIndexæ ¼å¼
    result_df['trade_date'] = pd.to_datetime(result_df['trade_date'])
    result_df = result_df.set_index(['trade_date', 'ts_code'])
    result_df = result_df.sort_index()
    
    # æœ€ç»ˆç»Ÿè®¡
    print(f"\n{'='*60}")
    print("å› å­è®¡ç®—å®Œæˆï¼")
    print(f"{'='*60}")
    print(f"ğŸ“Š æœ€ç»ˆå› å­ç»Ÿè®¡:")
    print(f"   æ€»è®°å½•æ•°: {len(result_df):,}")
    print(f"   è¦†ç›–è‚¡ç¥¨: {result_df.index.get_level_values('ts_code').nunique()}")
    print(f"   è¦†ç›–æ—¥æœŸ: {result_df.index.get_level_values('trade_date').nunique()}")
    print(f"   å› å­å€¼èŒƒå›´: [{result_df['factor'].min():.6f}, {result_df['factor'].max():.6f}]")
    print(f"   å› å­å‡å€¼: {result_df['factor'].mean():.6f}")
    print(f"   å› å­æ ‡å‡†å·®: {result_df['factor'].std():.6f}")
    print(f"{'='*60}\n")
    
    return result_df


def run_earnings_surprise_backtest(
    start_date: str = '2024-01-01',
    end_date: str = '2025-09-30',
    rebalance_freq: str = 'monthly',
    transaction_cost: float = 0.0003,
) -> dict:
    """
    æ‰§è¡Œå­£åº¦ç›ˆåˆ©æƒŠå–œå› å­çš„å›æµ‹
    
    Parameters
    ----------
    start_date : str
        å›æµ‹å¼€å§‹æ—¥æœŸ
    end_date : str
        å›æµ‹ç»“æŸæ—¥æœŸ
    rebalance_freq : str
        è°ƒä»“é¢‘ç‡ ('daily', 'weekly', 'monthly')
    transaction_cost : float
        å•è¾¹äº¤æ˜“æˆæœ¬
        
    Returns
    -------
    dict
        åŒ…å«å›æµ‹ç»“æœçš„å­—å…¸
    """
    from backtest_engine.engine import BacktestEngine
    from backtest_engine.performance import PerformanceAnalyzer
    from scipy.stats import spearmanr
    
    print("\n" + "="*60)
    print("å­£åº¦ç›ˆåˆ©æƒŠå–œå› å­å›æµ‹")
    print("="*60)
    
    # åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
    data_manager = DataManager()
    
    # è®¡ç®—å› å­
    factor_data = calculate_earnings_surprise_factor(
        data_manager=data_manager,
        start_date=start_date,
        end_date=end_date,
    )
    
    if factor_data is None or factor_data.empty:
        return {
            'portfolio_returns': None,
            'performance_metrics': None,
            'factor_data': None,
            'analysis_results': {}
        }
    
    # åˆå§‹åŒ–å›æµ‹å¼•æ“
    engine = BacktestEngine(
        data_manager=data_manager,
        start_date=start_date,
        end_date=end_date
    )
    
    # æ‰§è¡ŒLong-Onlyå›æµ‹
    print("\næ‰§è¡ŒLong-Onlyå›æµ‹...")
    portfolio_returns = engine.run_backtest(
        factor_data=factor_data,
        strategy_type='long_only',
        rebalance_freq=rebalance_freq,
        transaction_cost=transaction_cost
    )
    
    if portfolio_returns is None or portfolio_returns.empty:
        print("âš ï¸ å›æµ‹å¤±è´¥ï¼šæœªç”Ÿæˆæœ‰æ•ˆæ”¶ç›Š")
        return {
            'portfolio_returns': None,
            'performance_metrics': None,
            'factor_data': factor_data,
            'analysis_results': {}
        }
    
    # è®¡ç®—ä¸šç»©æŒ‡æ ‡
    analyzer = PerformanceAnalyzer(portfolio_returns)
    metrics = analyzer.calculate_metrics()
    
    # ICåˆ†æ
    print("\nè®¡ç®—ICæŒ‡æ ‡...")
    ic_results = calculate_ic(data_manager, factor_data, start_date, end_date)
    
    # è¾“å‡ºç»“æœ
    print("\n" + "="*60)
    print("å›æµ‹ç»“æœ")
    print("="*60)
    print(f"\nğŸ“Š ä¸šç»©æŒ‡æ ‡:")
    print(f"  æ€»æ”¶ç›Šç‡:     {metrics['total_return']:.2%}")
    print(f"  å¹´åŒ–æ”¶ç›Šç‡:   {metrics['annualized_return']:.2%}")
    print(f"  å¹´åŒ–æ³¢åŠ¨ç‡:   {metrics['volatility']:.2%}")
    print(f"  å¤æ™®æ¯”ç‡:     {metrics['sharpe_ratio']:.3f}")
    print(f"  æœ€å¤§å›æ’¤:     {metrics['max_drawdown']:.2%}")
    
    if ic_results['ic_series'] is not None:
        print(f"\nğŸ“Š ICåˆ†æ:")
        print(f"  ICå‡å€¼:       {ic_results['ic_mean']:.4f}")
        print(f"  ICæ ‡å‡†å·®:     {ic_results['ic_std']:.4f}")
        print(f"  ICIR:         {ic_results['icir']:.4f}")
        print(f"  IC>0å æ¯”:     {ic_results['ic_positive_ratio']:.2%}")
    
    print("="*60 + "\n")
    
    return {
        'portfolio_returns': portfolio_returns,
        'performance_metrics': metrics,
        'factor_data': factor_data,
        'analysis_results': ic_results
    }


def calculate_ic(data_manager, factor_data, start_date, end_date):
    """è®¡ç®—ICæŒ‡æ ‡"""
    from scipy.stats import spearmanr
    
    # åŠ è½½æ”¶ç›Šç‡æ•°æ®
    daily_data = data_manager.load_data('daily', start_date=start_date, end_date=end_date)
    
    if daily_data is None or daily_data.empty:
        return {
            'ic_series': None,
            'ic_mean': np.nan,
            'ic_std': np.nan,
            'icir': np.nan,
            'ic_positive_ratio': np.nan
        }
    
    daily_data = daily_data.copy()
    daily_data['trade_date'] = pd.to_datetime(daily_data['trade_date'])
    
    # è®¡ç®—æ”¶ç›Šç‡
    daily_data = daily_data.sort_values(['ts_code', 'trade_date'])
    daily_data['returns'] = daily_data.groupby('ts_code')['close'].pct_change()
    
    # åˆå¹¶å› å­å’Œæ”¶ç›Šç‡
    factor_reset = factor_data.reset_index()
    merged = factor_reset.merge(
        daily_data[['ts_code', 'trade_date', 'returns']],
        on=['ts_code', 'trade_date'],
        how='inner'
    )
    
    # è®¡ç®—æ¯æ—¥IC
    ic_series = merged.groupby('trade_date').apply(
        lambda x: spearmanr(x['factor'], x['returns'])[0] if len(x) > 10 else np.nan
    )
    ic_series = ic_series.dropna()
    
    if len(ic_series) == 0:
        return {
            'ic_series': None,
            'ic_mean': np.nan,
            'ic_std': np.nan,
            'icir': np.nan,
            'ic_positive_ratio': np.nan
        }
    
    ic_mean = ic_series.mean()
    ic_std = ic_series.std()
    icir = ic_mean / ic_std if ic_std > 0 else 0
    ic_positive_ratio = (ic_series > 0).sum() / len(ic_series)
    
    return {
        'ic_series': ic_series,
        'ic_mean': ic_mean,
        'ic_std': ic_std,
        'icir': icir,
        'ic_positive_ratio': ic_positive_ratio
    }


if __name__ == '__main__':
    # æµ‹è¯•å› å­è®¡ç®—
    results = run_earnings_surprise_backtest(
        start_date='2024-01-01',
        end_date='2025-09-30',
        rebalance_freq='monthly',
        transaction_cost=0.0003
    )
