"""
ç›ˆåˆ©æ„å¤–å› å­ (Earnings Surprise Factor) - åŸºäºå­£åº¦è´¢æŠ¥

å› å­é€»è¾‘ï¼š
-----------
1. è®¡ç®—æœ¬æœŸå­£åº¦EPSä¸å»å¹´åŒæœŸå­£åº¦EPSçš„å·®å€¼
2. ç”¨è´¢æŠ¥å…¬å‘Šæ—¥å‰ä¸€å¤©çš„è‚¡ä»·è¿›è¡Œæ ‡å‡†åŒ–
3. å› å­å€¼ = (EPS_current - EPS_last_year_same_quarter) / Price_announcement_date-1
4. åœ¨è´¢æŠ¥å…¬å‘Šæ—¥æ›´æ–°å› å­å€¼ï¼Œå¹¶ä¿æŒåˆ°ä¸‹ä¸€ä¸ªè´¢æŠ¥å…¬å‘Šæ—¥

ç†è®ºåŸºç¡€ï¼š
-----------
- ç›ˆåˆ©å¢é•¿åæ˜ å…¬å¸åŸºæœ¬é¢æ”¹å–„
- ç›¸å¯¹å»å¹´åŒæœŸçš„å¢é•¿é¿å…å­£èŠ‚æ€§å½±å“
- è‚¡ä»·æ ‡å‡†åŒ–ä½¿ä¸åŒè‚¡ç¥¨é—´å¯æ¯”
- åŸºäºPost-Earnings-Announcement-Drift (PEAD) æ•ˆåº”

æ•°æ®æ¥æºï¼š
-----------
- income: åˆ©æ¶¦è¡¨ï¼ˆè·å–å­£åº¦EPSï¼Œå­—æ®µï¼šeps, ann_date, end_dateï¼‰
- daily: æ—¥è¡Œæƒ…ï¼ˆè·å–è‚¡ä»·ï¼Œå­—æ®µï¼šclose, trade_dateï¼‰

æ³¨æ„äº‹é¡¹ï¼š
-----------
- ä½¿ç”¨ann_dateï¼ˆå…¬å‘Šæ—¥ï¼‰è€Œéend_dateï¼ˆæŠ¥å‘ŠæœŸï¼‰ï¼Œé¿å…å‰è§†åå·®
- å› å­å€¼åœ¨è´¢æŠ¥å‘å¸ƒå½“æ—¥å¯ç”¨ï¼Œå‘åå¡«å……ç›´åˆ°ä¸‹ä¸€è´¢æŠ¥
- å»å¹´åŒæœŸå®šä¹‰ï¼šæŠ¥å‘ŠæœŸend_dateç›¸å·®çº¦365å¤©çš„å­£æŠ¥
"""

import pandas as pd
import numpy as np
import sys
from pathlib import Path
from typing import Optional, List
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).resolve().parents[2]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

from data_manager.data import DataManager
from backtest_engine.performance import PerformanceAnalyzer


def calculate_earnings_surprise_factor(
    data_manager: DataManager,
    start_date: str,
    end_date: str,
    stock_codes: Optional[List[str]] = None,
    lookback_days: int = 370,  # æŸ¥æ‰¾å»å¹´åŒæœŸçš„å¤©æ•°èŒƒå›´ï¼ˆÂ±5å¤©ï¼‰
    price_lag_days: int = 1,   # ä½¿ç”¨å…¬å‘Šæ—¥å‰Nå¤©çš„è‚¡ä»·
) -> pd.DataFrame:
    """
    è®¡ç®—å­£åº¦ç›ˆåˆ©æ„å¤–å› å­
    
    Parameters
    ----------
    data_manager : DataManager
        æ•°æ®ç®¡ç†å™¨å®ä¾‹
    start_date : str
        å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD'
    end_date : str
        ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD'
    stock_codes : Optional[List[str]]
        è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œå¦‚ä¸º None åˆ™ä½¿ç”¨æ‰€æœ‰å¯ç”¨è‚¡ç¥¨
    lookback_days : int
        æŸ¥æ‰¾å»å¹´åŒæœŸçš„å¤©æ•°ä¸­å¿ƒå€¼ï¼ˆé»˜è®¤370å¤©ï¼Œçº¦ä¸€å¹´+5å¤©å®¹å·®ï¼‰
    price_lag_days : int
        ä½¿ç”¨å…¬å‘Šæ—¥å‰Nå¤©çš„è‚¡ä»·è¿›è¡Œæ ‡å‡†åŒ–ï¼ˆé»˜è®¤1å¤©ï¼‰
    
    Returns
    -------
    pd.DataFrame
        MultiIndex (trade_date, ts_code) æ ¼å¼ï¼ŒåŒ…å« 'factor' åˆ—
        å› å­å€¼ = (EPS_current - EPS_last_year) / Price
    """
    
    print("=" * 80)
    print("ç›ˆåˆ©æ„å¤–å› å­ (Earnings Surprise Factor) - è®¡ç®—å¼€å§‹")
    print("=" * 80)
    
    # 1. è·å–è‚¡ç¥¨æ± 
    if stock_codes is None:
        all_daily = data_manager.load_data('daily', start_date=start_date, end_date=end_date, cleaned=True)
        if all_daily is None or all_daily.empty:
            print("âš ï¸  æ— æ³•è·å–æ—¥è¡Œæƒ…æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤è‚¡ç¥¨æ± ")
            stock_codes = ['000001.SZ', '000002.SZ', '600000.SH', '600036.SH']
        else:
            stock_codes = all_daily['ts_code'].unique().tolist()
    
    if stock_codes:
        print(f"è‚¡ç¥¨æ± å¤§å°: {len(stock_codes)} åªè‚¡ç¥¨")
    
    # 2. åŠ è½½åˆ©æ¶¦è¡¨æ•°æ®ï¼ˆè·å–å­£åº¦EPSï¼‰
    print("\nğŸ“Š åŠ è½½åˆ©æ¶¦è¡¨æ•°æ®...")
    income = data_manager.load_data('income', cleaned=True)
    if income is None or income.empty:
        raise ValueError("âŒ æ— æ³•è·å–åˆ©æ¶¦è¡¨æ•°æ®")
    
    # ç­›é€‰è‚¡ç¥¨æ± 
    if stock_codes:
        income = income[income['ts_code'].isin(stock_codes)].copy()
    
    # æ£€æŸ¥å¿…éœ€å­—æ®µ
    required_fields = ['ts_code', 'ann_date', 'end_date']
    eps_field = 'basic_eps' if 'basic_eps' in income.columns else 'diluted_eps'
    
    if eps_field not in income.columns:
        raise ValueError(f"âŒ åˆ©æ¶¦è¡¨ç¼ºå°‘EPSå­—æ®µ (basic_eps æˆ– diluted_eps)")
    
    required_fields.append(eps_field)
    missing_fields = [f for f in required_fields if f not in income.columns]
    if missing_fields:
        raise ValueError(f"âŒ åˆ©æ¶¦è¡¨ç¼ºå°‘å¿…éœ€å­—æ®µ: {missing_fields}")
    
    print(f"âœ… ä½¿ç”¨EPSå­—æ®µ: {eps_field}")
    
    # æå–å­£æŠ¥æ•°æ®ï¼ˆåªä¿ç•™å­£åº¦è´¢æŠ¥ï¼‰
    income_q = income[required_fields].copy()
    income_q = income_q.rename(columns={eps_field: 'eps'})
    income_q = income_q.dropna(subset=['eps', 'ann_date', 'end_date'])
    
    # è½¬æ¢æ—¥æœŸæ ¼å¼
    income_q['ann_date'] = pd.to_datetime(income_q['ann_date'], format='%Y%m%d', errors='coerce')
    income_q['end_date'] = pd.to_datetime(income_q['end_date'], format='%Y%m%d', errors='coerce')
    income_q = income_q.dropna(subset=['ann_date', 'end_date'])
    
    # åªä¿ç•™åœ¨å›æµ‹æœŸé—´æˆ–ä¹‹å‰å…¬å‘Šçš„è´¢æŠ¥
    income_q = income_q[income_q['ann_date'] <= pd.to_datetime(end_date)]
    
    print(f"âœ… åˆ©æ¶¦è¡¨æ•°æ®åŠ è½½å®Œæˆ")
    print(f"   åŸå§‹è®°å½•æ•°: {len(income)}")
    print(f"   æœ‰æ•ˆå­£æŠ¥æ•°: {len(income_q)}")
    print(f"   è¦†ç›–è‚¡ç¥¨æ•°: {income_q['ts_code'].nunique()}")
    print(f"   å…¬å‘Šæ—¥èŒƒå›´: {income_q['ann_date'].min()} è‡³ {income_q['ann_date'].max()}")
    
    # 3. åŠ è½½æ—¥è¡Œæƒ…æ•°æ®ï¼ˆè·å–è‚¡ä»·ï¼‰
    print("\nğŸ“ˆ åŠ è½½æ—¥è¡Œæƒ…æ•°æ®...")
    # éœ€è¦æ‰©å±•æ—¥æœŸèŒƒå›´ä»¥è·å–å…¬å‘Šæ—¥å‰çš„è‚¡ä»·
    extended_start = (pd.to_datetime(start_date) - timedelta(days=30)).strftime('%Y-%m-%d')
    daily = data_manager.load_data('daily', start_date=extended_start, end_date=end_date, 
                                   stock_codes=stock_codes, cleaned=True)
    if daily is None or daily.empty:
        raise ValueError("âŒ æ— æ³•è·å–æ—¥è¡Œæƒ…æ•°æ®")
    
    daily = daily.copy()
    daily['trade_date'] = pd.to_datetime(daily['trade_date'], format='%Y%m%d', errors='coerce')
    daily = daily.dropna(subset=['trade_date', 'close'])
    daily = daily.sort_values(['ts_code', 'trade_date']).reset_index(drop=True)
    
    print(f"âœ… æ—¥è¡Œæƒ…æ•°æ®åŠ è½½å®Œæˆ")
    print(f"   è®°å½•æ•°: {len(daily)}")
    print(f"   è¦†ç›–è‚¡ç¥¨æ•°: {daily['ts_code'].nunique()}")
    print(f"   æ—¥æœŸèŒƒå›´: {daily['trade_date'].min()} è‡³ {daily['trade_date'].max()}")
    
    # 4. è®¡ç®—ç›ˆåˆ©æ„å¤–å› å­
    print("\nğŸ”§ è®¡ç®—ç›ˆåˆ©æ„å¤–å› å­...")
    print(f"   å‚æ•°: å»å¹´åŒæœŸèŒƒå›´ Â±{lookback_days}å¤©, è‚¡ä»·æ»å {price_lag_days}å¤©")
    
    # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„å¤„ç†
    factor_list = []
    stock_count = 0
    total_stocks = income_q['ts_code'].nunique()
    
    for ts_code in income_q['ts_code'].unique():
        stock_count += 1
        if stock_count % 100 == 0:
            print(f"   è¿›åº¦: {stock_count}/{total_stocks} ({stock_count/total_stocks*100:.1f}%)")
        
        # è·å–è¯¥è‚¡ç¥¨çš„æ‰€æœ‰å­£æŠ¥
        stock_income = income_q[income_q['ts_code'] == ts_code].copy()
        stock_income = stock_income.sort_values('ann_date').reset_index(drop=True)
        
        # è·å–è¯¥è‚¡ç¥¨çš„æ—¥è¡Œæƒ…
        stock_daily = daily[daily['ts_code'] == ts_code].copy()
        if stock_daily.empty:
            continue
        
        # å¯¹æ¯ä¸€ä»½å­£æŠ¥ï¼Œå¯»æ‰¾å»å¹´åŒæœŸå­£æŠ¥å¹¶è®¡ç®—å› å­
        for idx, row in stock_income.iterrows():
            current_ann_date = row['ann_date']
            current_end_date = row['end_date']
            current_eps = row['eps']
            
            # è·³è¿‡å…¬å‘Šæ—¥åœ¨å›æµ‹æœŸä¹‹å‰çš„è´¢æŠ¥ï¼ˆä½†æˆ‘ä»¬éœ€è¦å®ƒä»¬ä½œä¸º"å»å¹´åŒæœŸ"ï¼‰
            if current_ann_date < pd.to_datetime(start_date):
                continue
            
            # å¯»æ‰¾å»å¹´åŒæœŸçš„å­£æŠ¥ï¼ˆend_dateç›¸å·®çº¦365å¤©ï¼‰
            target_end_date = current_end_date - timedelta(days=365)
            
            # åœ¨Â±5å¤©èŒƒå›´å†…æŸ¥æ‰¾å»å¹´åŒæœŸ
            last_year_data = stock_income[
                (stock_income['end_date'] >= target_end_date - timedelta(days=5)) &
                (stock_income['end_date'] <= target_end_date + timedelta(days=5)) &
                (stock_income['ann_date'] < current_ann_date)  # å¿…é¡»åœ¨å½“å‰è´¢æŠ¥ä¹‹å‰å…¬å‘Š
            ]
            
            if last_year_data.empty:
                continue
            
            # é€‰æ‹©æœ€æ¥è¿‘çš„å»å¹´åŒæœŸå­£æŠ¥
            last_year_data = last_year_data.iloc[0]
            last_year_eps = last_year_data['eps']
            
            # è®¡ç®—EPSå·®å€¼
            eps_diff = current_eps - last_year_eps
            
            # è·å–å…¬å‘Šæ—¥å‰Nå¤©çš„è‚¡ä»·
            price_date = current_ann_date - timedelta(days=price_lag_days)
            price_data = stock_daily[
                (stock_daily['trade_date'] <= price_date)
            ]
            
            if price_data.empty:
                continue
            
            # å–æœ€è¿‘çš„äº¤æ˜“æ—¥è‚¡ä»·
            price_data = price_data.iloc[-1]
            price = price_data['close']
            
            if price <= 0:
                continue
            
            # è®¡ç®—å› å­å€¼
            factor_value = eps_diff / price
            
            # è®°å½•å› å­å€¼ï¼ˆåœ¨å…¬å‘Šæ—¥å½“å¤©ç”Ÿæ•ˆï¼‰
            factor_list.append({
                'ts_code': ts_code,
                'ann_date': current_ann_date,
                'end_date': current_end_date,
                'eps_current': current_eps,
                'eps_last_year': last_year_eps,
                'eps_diff': eps_diff,
                'price': price,
                'factor': factor_value
            })
    
    if not factor_list:
        raise ValueError("âŒ æœªèƒ½è®¡ç®—å‡ºä»»ä½•å› å­å€¼ï¼Œè¯·æ£€æŸ¥æ•°æ®")
    
    factor_df = pd.DataFrame(factor_list)
    
    print(f"\nâœ… å› å­è®¡ç®—å®Œæˆ")
    print(f"   æœ‰æ•ˆå› å­è®°å½•æ•°: {len(factor_df)}")
    print(f"   è¦†ç›–è‚¡ç¥¨æ•°: {factor_df['ts_code'].nunique()}")
    
    # æ˜¾ç¤ºå› å­ç»Ÿè®¡
    print(f"\nğŸ“Š å› å­å€¼ç»Ÿè®¡:")
    print(f"   å‡å€¼: {factor_df['factor'].mean():.6f}")
    print(f"   ä¸­ä½æ•°: {factor_df['factor'].median():.6f}")
    print(f"   æ ‡å‡†å·®: {factor_df['factor'].std():.6f}")
    print(f"   æœ€å°å€¼: {factor_df['factor'].min():.6f}")
    print(f"   æœ€å¤§å€¼: {factor_df['factor'].max():.6f}")
    
    # æ˜¾ç¤ºEPSå·®å€¼ç»Ÿè®¡
    print(f"\nğŸ“Š EPSå·®å€¼ç»Ÿè®¡:")
    print(f"   å‡å€¼: {factor_df['eps_diff'].mean():.4f}")
    print(f"   ä¸­ä½æ•°: {factor_df['eps_diff'].median():.4f}")
    print(f"   EPSå¢é•¿(>0)å æ¯”: {(factor_df['eps_diff'] > 0).sum() / len(factor_df) * 100:.2f}%")
    
    # 5. å°†å› å­å€¼æ‰©å±•åˆ°æ¯ä¸ªäº¤æ˜“æ—¥ï¼ˆå‘åå¡«å……ç›´åˆ°ä¸‹ä¸€ä¸ªè´¢æŠ¥ï¼‰
    print("\nğŸ”„ å°†å› å­å€¼æ‰©å±•åˆ°æ¯ä¸ªäº¤æ˜“æ—¥...")
    
    # è·å–æ‰€æœ‰äº¤æ˜“æ—¥
    all_dates = daily[(daily['trade_date'] >= pd.to_datetime(start_date)) & 
                     (daily['trade_date'] <= pd.to_datetime(end_date))]['trade_date'].unique()
    all_dates = pd.Series(all_dates).sort_values().reset_index(drop=True)
    
    # åˆ›å»ºæ—¥æœŸ-è‚¡ç¥¨ç½‘æ ¼
    factor_daily_list = []
    
    for ts_code in factor_df['ts_code'].unique():
        stock_factors = factor_df[factor_df['ts_code'] == ts_code].copy()
        stock_factors = stock_factors.sort_values('ann_date').reset_index(drop=True)
        
        for trade_date in all_dates:
            # æ‰¾åˆ°è¯¥æ—¥æœŸä¹‹å‰æœ€è¿‘çš„ä¸€ä¸ªè´¢æŠ¥å…¬å‘Š
            valid_factors = stock_factors[stock_factors['ann_date'] <= trade_date]
            
            if not valid_factors.empty:
                # ä½¿ç”¨æœ€è¿‘çš„å› å­å€¼
                latest_factor = valid_factors.iloc[-1]
                factor_daily_list.append({
                    'trade_date': trade_date,
                    'ts_code': ts_code,
                    'factor': latest_factor['factor']
                })
    
    if not factor_daily_list:
        raise ValueError("âŒ æœªèƒ½ç”Ÿæˆæ—¥é¢‘å› å­æ•°æ®")
    
    result = pd.DataFrame(factor_daily_list)
    
    # è½¬æ¢ä¸º MultiIndex æ ¼å¼
    result = result.set_index(['trade_date', 'ts_code'])
    result = result.sort_index()
    
    print(f"\nâœ… æ—¥é¢‘å› å­æ•°æ®ç”Ÿæˆå®Œæˆ")
    print(f"   è®°å½•æ•°: {len(result)}")
    print(f"   è¦†ç›–è‚¡ç¥¨æ•°: {result.index.get_level_values('ts_code').nunique()}")
    print(f"   è¦†ç›–äº¤æ˜“æ—¥æ•°: {result.index.get_level_values('trade_date').nunique()}")
    
    print("\n" + "=" * 80)
    return result


def run_earnings_surprise_backtest(
    start_date: str = '2020-01-01',
    end_date: str = '2024-12-31',
    stock_codes: Optional[List[str]] = None,
    rebalance_freq: str = 'monthly',
    transaction_cost: float = 0.0003,
) -> dict:
    """
    æ‰§è¡Œç›ˆåˆ©æ„å¤–å› å­å›æµ‹
    
    Parameters
    ----------
    start_date : str
        å›æµ‹å¼€å§‹æ—¥æœŸ
    end_date : str
        å›æµ‹ç»“æŸæ—¥æœŸ
    stock_codes : Optional[List[str]]
        è‚¡ç¥¨æ± ï¼ŒNoneåˆ™ä½¿ç”¨å…¨å¸‚åœº
    rebalance_freq : str
        è°ƒä»“é¢‘ç‡ ('daily', 'weekly', 'monthly')
    transaction_cost : float
        å•è¾¹äº¤æ˜“æˆæœ¬
        
    Returns
    -------
    dict
        åŒ…å«å›æµ‹ç»“æœçš„å­—å…¸
    """
    print("\n" + "=" * 80)
    print("ç›ˆåˆ©æ„å¤–å› å­å›æµ‹ - æ‰§è¡Œå¼€å§‹")
    print("=" * 80)
    print(f"å›æµ‹å‚æ•°:")
    print(f"  æ—¶é—´èŒƒå›´: {start_date} è‡³ {end_date}")
    print(f"  è°ƒä»“é¢‘ç‡: {rebalance_freq}")
    print(f"  äº¤æ˜“æˆæœ¬: {transaction_cost:.4f}")
    
    # åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
    data_manager = DataManager()
    
    # è®¡ç®—å› å­
    print("\næ­¥éª¤ 1: è®¡ç®—ç›ˆåˆ©æ„å¤–å› å­...")
    factor_data = calculate_earnings_surprise_factor(
        data_manager=data_manager,
        start_date=start_date,
        end_date=end_date,
        stock_codes=stock_codes
    )
    
    if factor_data is None or factor_data.empty:
        print("âŒ å› å­è®¡ç®—å¤±è´¥")
        return {
            'factor_data': None,
            'portfolio_returns': None,
            'performance_metrics': None,
            'analysis_results': {}
        }
    
    # æ‰§è¡Œå›æµ‹
    print("\næ­¥éª¤ 2: æ‰§è¡Œå›æµ‹...")
    
    # å‡†å¤‡æ”¶ç›Šç‡æ•°æ®
    stock_list = factor_data.index.get_level_values('ts_code').unique().tolist()
    
    stock_data = data_manager.load_data(
        'daily',
        start_date=start_date,
        end_date=end_date,
        stock_codes=stock_list
    )
    
    if stock_data is None or stock_data.empty:
        raise ValueError("âŒ æ— æ³•åŠ è½½ç”¨äºå›æµ‹çš„è‚¡ç¥¨æ•°æ®")
    
    stock_data = stock_data.copy()
    stock_data['trade_date'] = pd.to_datetime(stock_data['trade_date'], format='%Y%m%d', errors='coerce')
    stock_data = stock_data.dropna(subset=['trade_date'])
    stock_data = stock_data.sort_values(['ts_code', 'trade_date'])
    
    # è®¡ç®—ä¸‹ä¸€æ—¥æ”¶ç›Šç‡
    stock_data['next_close'] = stock_data.groupby('ts_code')['close'].shift(-1)
    stock_data['next_return'] = (stock_data['next_close'] / stock_data['close']) - 1
    
    # åˆå¹¶å› å­å’Œæ”¶ç›Šæ•°æ®
    combined = pd.merge(
        factor_data.reset_index(),
        stock_data[['trade_date', 'ts_code', 'next_return']],
        on=['trade_date', 'ts_code'],
        how='inner'
    )
    
    combined = combined.dropna(subset=['next_return'])
    
    if combined.empty:
        print("âŒ åˆå¹¶åæ— æœ‰æ•ˆæ•°æ®")
        return {
            'factor_data': factor_data,
            'portfolio_returns': None,
            'performance_metrics': {},
            'analysis_results': {}
        }
    
    # Long-Onlyç­–ç•¥ï¼šç­‰æƒæŒæœ‰æ‰€æœ‰æœ‰å› å­å€¼çš„è‚¡ç¥¨
    portfolio_returns = combined.groupby('trade_date')['next_return'].mean()
    
    # æ¨¡æ‹Ÿäº¤æ˜“æˆæœ¬
    if rebalance_freq == 'daily':
        rebalance_dates = portfolio_returns.index
    else:
        freq_map = {'weekly': 'W-MON', 'monthly': 'MS'}
        rebalance_dates = pd.date_range(
            start=portfolio_returns.index.min(),
            end=portfolio_returns.index.max(),
            freq=freq_map.get(rebalance_freq, 'MS')
        )
        rebalance_dates = [d for d in rebalance_dates if d in portfolio_returns.index]
    
    # åœ¨è°ƒä»“æ—¥æ‰£é™¤äº¤æ˜“æˆæœ¬
    portfolio_returns_with_cost = portfolio_returns.copy()
    for rebal_date in rebalance_dates:
        if rebal_date in portfolio_returns_with_cost.index:
            portfolio_returns_with_cost.at[rebal_date] -= transaction_cost * 2  # åŒè¾¹æˆæœ¬
    
    # è®¡ç®—ä¸šç»©æŒ‡æ ‡
    print("\næ­¥éª¤ 3: è®¡ç®—ä¸šç»©æŒ‡æ ‡...")
    cum_returns = (1 + portfolio_returns_with_cost).cumprod()
    total_return = float(cum_returns.iloc[-1] - 1) if len(cum_returns) > 0 else 0.0
    ann_return = float(portfolio_returns_with_cost.mean() * 252)
    volatility = float(portfolio_returns_with_cost.std() * np.sqrt(252))
    sharpe = float(ann_return / volatility) if volatility > 0 else 0.0
    drawdowns = cum_returns / cum_returns.cummax() - 1
    max_dd = float(drawdowns.min())
    
    metrics = {
        'total_return': total_return,
        'annualized_return': ann_return,
        'volatility': volatility,
        'sharpe_ratio': sharpe,
        'max_drawdown': max_dd
    }
    
    # è®¡ç®—ICåˆ†æ
    print("\næ­¥éª¤ 4: ICåˆ†æ...")
    ic_analysis = calculate_ic_analysis(factor_data, data_manager, start_date, end_date)
    
    # æ˜¾ç¤ºç»“æœ
    print("\n" + "=" * 80)
    print("å›æµ‹ç»“æœæ±‡æ€»")
    print("=" * 80)
    print(f"\nğŸ“Š ä¸šç»©æŒ‡æ ‡:")
    print(f"  æ€»æ”¶ç›Šç‡:     {metrics['total_return']:.2%}")
    print(f"  å¹´åŒ–æ”¶ç›Šç‡:   {metrics['annualized_return']:.2%}")
    print(f"  å¹´åŒ–æ³¢åŠ¨ç‡:   {metrics['volatility']:.2%}")
    print(f"  å¤æ™®æ¯”ç‡:     {metrics['sharpe_ratio']:.3f}")
    print(f"  æœ€å¤§å›æ’¤:     {metrics['max_drawdown']:.2%}")
    
    if ic_analysis['ic_series'] is not None:
        print(f"\nğŸ“Š ICåˆ†æ:")
        print(f"  ICå‡å€¼:       {ic_analysis['ic_mean']:.4f}")
        print(f"  ICæ ‡å‡†å·®:     {ic_analysis['ic_std']:.4f}")
        print(f"  ICIR:         {ic_analysis['icir']:.4f}")
        print(f"  IC>0å æ¯”:     {ic_analysis['ic_positive_ratio']:.2%}")
    
    print("\n" + "=" * 80)
    
    return {
        'factor_data': factor_data,
        'portfolio_returns': portfolio_returns_with_cost,
        'performance_metrics': metrics,
        'analysis_results': ic_analysis
    }


def calculate_ic_analysis(
    factor_data: pd.DataFrame,
    data_manager: DataManager,
    start_date: str,
    end_date: str
) -> dict:
    """
    è®¡ç®—å› å­ICåˆ†æ
    
    Parameters
    ----------
    factor_data : pd.DataFrame
        å› å­æ•°æ®ï¼ŒMultiIndex (trade_date, ts_code)
    data_manager : DataManager
        æ•°æ®ç®¡ç†å™¨
    start_date : str
        å¼€å§‹æ—¥æœŸ
    end_date : str
        ç»“æŸæ—¥æœŸ
        
    Returns
    -------
    dict
        ICåˆ†æç»“æœ
    """
    try:
        # åŠ è½½æ”¶ç›Šç‡æ•°æ®
        daily = data_manager.load_data('daily', start_date=start_date, end_date=end_date, cleaned=True)
        if daily is None or daily.empty:
            return {
                'ic_series': None,
                'ic_mean': np.nan,
                'ic_std': np.nan,
                'icir': np.nan,
                'ic_positive_ratio': np.nan
            }
        
        daily = daily.copy()
        daily['trade_date'] = pd.to_datetime(daily['trade_date'], format='%Y%m%d', errors='coerce')
        daily = daily.dropna(subset=['trade_date'])
        daily = daily.sort_values(['ts_code', 'trade_date'])
        
        # è®¡ç®—æœªæ¥æ”¶ç›Šç‡ï¼ˆT+1ï¼‰
        daily['return'] = daily.groupby('ts_code')['close'].pct_change(1).shift(-1)
        
        # åˆå¹¶å› å­å’Œæ”¶ç›Šç‡
        factor_reset = factor_data.reset_index()
        merged = pd.merge(
            factor_reset,
            daily[['trade_date', 'ts_code', 'return']],
            on=['trade_date', 'ts_code'],
            how='inner'
        )
        
        if merged.empty:
            return {
                'ic_series': None,
                'ic_mean': np.nan,
                'ic_std': np.nan,
                'icir': np.nan,
                'ic_positive_ratio': np.nan
            }
        
        # è®¡ç®—æ¯æ—¥ICï¼ˆSpearmanç›¸å…³ç³»æ•°ï¼‰
        ic_list = []
        for date in merged['trade_date'].unique():
            date_data = merged[merged['trade_date'] == date]
            if len(date_data) >= 10:  # è‡³å°‘10åªè‚¡ç¥¨
                ic = date_data[['factor', 'return']].corr(method='spearman').iloc[0, 1]
                if not np.isnan(ic):
                    ic_list.append({'trade_date': date, 'ic': ic})
        
        if not ic_list:
            return {
                'ic_series': None,
                'ic_mean': np.nan,
                'ic_std': np.nan,
                'icir': np.nan,
                'ic_positive_ratio': np.nan
            }
        
        ic_df = pd.DataFrame(ic_list)
        ic_series = ic_df.set_index('trade_date')['ic']
        
        ic_mean = ic_series.mean()
        ic_std = ic_series.std()
        icir = ic_mean / ic_std if ic_std > 0 else np.nan
        ic_positive_ratio = (ic_series > 0).sum() / len(ic_series)
        
        return {
            'ic_series': ic_series,
            'ic_mean': ic_mean,
            'ic_std': ic_std,
            'icir': icir,
            'ic_positive_ratio': ic_positive_ratio
        }
    
    except Exception as e:
        print(f"âš ï¸  ICåˆ†æè®¡ç®—å¤±è´¥: {e}")
        return {
            'ic_series': None,
            'ic_mean': np.nan,
            'ic_std': np.nan,
            'icir': np.nan,
            'ic_positive_ratio': np.nan
        }


if __name__ == '__main__':
    # æµ‹è¯•å› å­è®¡ç®—å’Œå›æµ‹
    results = run_earnings_surprise_backtest(
        start_date='2020-01-01',
        end_date='2024-12-31',
        rebalance_freq='monthly',
        transaction_cost=0.0003
    )
