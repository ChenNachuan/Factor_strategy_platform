"""
OBV (On-Balance Volume) å¢å¼ºç‰ˆå› å­

ä¼˜åŒ–å†…å®¹ï¼ˆå‚è€ƒ pe_factor.py, rsi_factor.py, new_high_alpha_factor.pyï¼‰ï¼š
=================================================================

1. æ•°æ®è´¨é‡ç­›é€‰ âœ…
   - è¿‡æ»¤ ST è‚¡ç¥¨ï¼ˆé€šè¿‡æ¶¨è·Œå¹…é™åˆ¶åˆ¤æ–­ï¼‰
   - è¿‡æ»¤åœç‰Œæ•°æ®ï¼ˆæˆäº¤é‡/æˆäº¤é¢ä¸º0ï¼‰
   - è¿‡æ»¤æ¶¨è·Œåœæ•°æ®ï¼ˆÂ±9.8%ï¼‰
   - è¿‡æ»¤ä½æµåŠ¨æ€§è‚¡ç¥¨ï¼ˆæ¢æ‰‹ç‡è¿‡ä½ï¼‰
   - è¿‡æ»¤ä½ä»·è‚¡ï¼ˆä»·æ ¼ < 1å…ƒï¼‰
   - è¿‡æ»¤å¼‚å¸¸æ¶¨è·Œå¹…ï¼ˆ|æ¶¨è·Œå¹…| > 30%ï¼‰
   - æˆäº¤é‡å¼‚å¸¸å¤„ç†ï¼š
     * é›¶æˆäº¤é‡æ•°æ®
     * å¼‚å¸¸æ”¾é‡ï¼ˆ>å‡å€¼+10Ïƒï¼Œé™åˆ¶åˆ°å‡å€¼+5Ïƒï¼‰
     * å¼‚å¸¸ç¼©é‡ï¼ˆ<å‡å€¼1%ï¼‰
     * é‡ä»·ä¸€è‡´æ€§æ£€æŸ¥ï¼ˆæˆäº¤é¢/æˆäº¤é‡ vs ä»·æ ¼ï¼‰

2. OBV è®¡ç®—ä¼˜åŒ– âœ…
   - ä½¿ç”¨ç™¾åˆ†æ¯”å˜åŒ–è€Œéç»å¯¹å˜åŒ–ï¼ˆé¿å…ä»·æ ¼é‡çº§å½±å“ï¼‰
   - è®¾ç½®å˜åŒ–é˜ˆå€¼è¿‡æ»¤å™ªéŸ³ï¼ˆ0.01%ï¼‰
   - ä»·æ ¼å¹³ç¨³æ—¶å»¶ç»­å‰ä¸€æ—¥æ–¹å‘
   - ä»0å¼€å§‹ç´¯ç§¯ï¼ˆæ ‡å‡†åšæ³•ï¼‰
   - æ•°æ®è´¨é‡æ£€æŸ¥ï¼ˆNaNå€¼ã€å¼‚å¸¸å˜åŒ–ï¼‰
   - æˆäº¤é‡éªŒè¯ï¼š
     * ç¡®ä¿æˆäº¤é‡ä¸ºæ­£
     * æ£€æŸ¥æ•°æ®è¦†ç›–ç‡ï¼ˆ>50%ï¼‰
     * é™åˆ¶å•æ—¥æç«¯OBVå˜åŒ–ï¼ˆ<50å€ä¸­ä½æ•°ï¼‰
     * æˆäº¤é‡ç¨³å®šæ€§ç›‘æ§

3. å¼‚å¸¸å€¼å¤„ç† âœ…
   - ä½¿ç”¨ MAD (Median Absolute Deviation) æ–¹æ³•ï¼ˆæ¯”æ ‡å‡†å·®æ›´ç¨³å¥ï¼‰
   - ä¸‰å±‚é˜²æŠ¤ï¼šWinsorize â†’ æ ‡å‡†åŒ– â†’ æˆªå°¾
   - æŒ‰æ—¥æœŸåˆ†ç»„å¤„ç†ï¼Œé¿å…æ—¶åºåå·®
   - å®æ—¶ç›‘æ§ï¼šååº¦ã€å³°åº¦ã€ç¼ºå¤±ç‡

4. æ•°å€¼ç¨³å®šæ€§ âœ…
   - æ‰€æœ‰é™¤æ³•æ“ä½œæ·»åŠ æœ€å°å€¼ä¿æŠ¤ï¼ˆ1e-10ï¼‰
   - æ ‡å‡†åŒ–å‰æ£€æŸ¥æ ·æœ¬æ•°ï¼ˆâ‰¥10ï¼‰å’Œæ ‡å‡†å·®ï¼ˆâ‰¥1e-8ï¼‰
   - è‡ªåŠ¨æ£€æµ‹å¹¶æ›¿æ¢æ— ç©·å€¼/NaN
   - ç™¾åˆ†æ¯”å˜åŒ–é™åˆ¶åœ¨åˆç†èŒƒå›´ï¼ˆÂ±1000%ï¼‰
   - å®‰å…¨æ ‡å‡†åŒ–å‡½æ•°ï¼ˆsafe_standardizeï¼‰

5. è¾“å‡ºå¢å¼º âœ…
   - è¯¦ç»†çš„æ•°æ®ç­›é€‰ç»Ÿè®¡
   - OBV è®¡ç®—è´¨é‡æ£€æŸ¥
   - å­å› å­è´¡çŒ®åˆ†æ
   - æ•°æ®è´¨é‡è¯„ä¼°æŠ¥å‘Š

6. å›æµ‹ç©ºå€¼ä¿æŠ¤ âœ…
   - å› å­è®¡ç®—å¼‚å¸¸æ•è·
   - æ•°æ®åŠ è½½éªŒè¯ï¼ˆNone/Emptyæ£€æŸ¥ï¼‰
   - åˆ—å­˜åœ¨æ€§éªŒè¯
   - æœ‰æ•ˆå€¼æ¯”ä¾‹æ£€æŸ¥
   - åˆå¹¶æ“ä½œå¼‚å¸¸å¤„ç†
   - ä¸šç»©æŒ‡æ ‡å®‰å…¨è®¡ç®—
   - IC åˆ†æå¼‚å¸¸ä¿æŠ¤
   - å®Œæ•´çš„é”™è¯¯è¿”å›æœºåˆ¶

ä½œè€…ï¼šå‚è€ƒä¸šç•Œæœ€ä½³å®è·µ
ç‰ˆæœ¬ï¼šv2.0 (Enhanced)
"""

import pandas as pd
import numpy as np
import sys
from pathlib import Path
from typing import Optional, List

# è·¯å¾„ï¼šæŠŠé¡¹ç›®æ ¹ç›®å½•åŠ å…¥ sys.pathï¼Œä¾¿äºä½¿ç”¨ç»å¯¹åŒ…å¯¼å…¥
PROJECT_ROOT = Path(__file__).resolve().parents[2]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

from data_manager.data import DataManager


def calculate_obv_factor(
    data_manager: DataManager,
    start_date: str,
    end_date: str,
    stock_codes: Optional[List[str]] = None,
) -> pd.DataFrame:
    """
    è®¡ç®—åŸºç¡€ OBV (On-Balance Volume) å› å­ï¼Œå¹¶è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ã€‚
    
    Returns
    -------
    DataFrame
        MultiIndex (trade_date, ts_code) with single column 'factor'.
    """
    # è‚¡ç¥¨æ± 
    if stock_codes is None:
        all_daily = data_manager.load_data('daily', start_date=start_date, end_date=end_date, cleaned=True)
        if all_daily is None or all_daily.empty:
            stock_codes = ['000001.SZ', '000002.SZ', '000858.SZ', '600000.SH', '600036.SH', '600519.SH']
        else:
            stock_codes = all_daily['ts_code'].unique().tolist()

    # æ—¥çº¿æ•°æ®
    daily = data_manager.load_data('daily', start_date=start_date, end_date=end_date, stock_codes=stock_codes)
    if daily is None or daily.empty:
        raise ValueError('æ— æ³•è·å–æ—¥è¡Œæƒ…æ•°æ®')
    
    # ç»Ÿä¸€æ—¥æœŸä¸º datetime å¹¶æ’åº
    daily = daily.copy()
    daily['trade_date'] = pd.to_datetime(daily['trade_date'], errors='coerce')
    if daily['trade_date'].isna().any():
        daily['trade_date'] = pd.to_datetime(daily['trade_date'].astype(str), format='%Y%m%d', errors='coerce')
    daily = daily.dropna(subset=['trade_date'])
    daily = daily.sort_values(['ts_code', 'trade_date']).reset_index(drop=True)

    # è®¡ç®— OBV
    result_parts = []
    for code in daily['ts_code'].unique():
        stock_data = daily[daily['ts_code'] == code].sort_values('trade_date').copy()
        
        # === ä¼˜åŒ–çš„ OBV è®¡ç®—ï¼ˆä¸å¢å¼ºç‰ˆä¿æŒä¸€è‡´ï¼‰===
        stock_data['prev_close'] = stock_data['close'].shift(1)
        
        # ä½¿ç”¨ç™¾åˆ†æ¯”å˜åŒ–åˆ¤æ–­æ–¹å‘
        price_change_pct = (stock_data['close'] - stock_data['prev_close']) / stock_data['prev_close']
        price_threshold = 0.0001  # 0.01% çš„å˜åŒ–é˜ˆå€¼
        
        def determine_direction(change_pct, prev_direction):
            if pd.isna(change_pct):
                return 0
            elif change_pct > price_threshold:
                return 1
            elif change_pct < -price_threshold:
                return -1
            else:
                return prev_direction if not pd.isna(prev_direction) else 0
        
        # è®¡ç®—æ–¹å‘
        directions = [0]
        for i in range(1, len(stock_data)):
            direction = determine_direction(
                price_change_pct.iloc[i], 
                directions[-1]
            )
            directions.append(direction)
        
        stock_data['direction'] = directions
        
        # è®¡ç®— OBV
        obv = (stock_data['direction'] * stock_data['vol']).cumsum()
        
        # åˆ›å»ºç»“æœ DataFrame
        result = pd.DataFrame({
            'trade_date': stock_data['trade_date'],
            'ts_code': code,
            'factor': obv
        })
        result_parts.append(result)
    
    # åˆå¹¶æ‰€æœ‰è‚¡ç¥¨çš„ç»“æœ
    combined = pd.concat(result_parts, axis=0)
    
    # å¯¹æ¯ä¸ªäº¤æ˜“æ—¥çš„ OBV è¿›è¡Œæˆªé¢æ ‡å‡†åŒ–
    combined = combined.set_index(['trade_date', 'ts_code'])
    combined = combined.sort_index()
    
    # æŒ‰æ—¥æœŸåˆ†ç»„è¿›è¡Œæ ‡å‡†åŒ–
    grouped = combined.groupby('trade_date')
    combined['factor'] = grouped['factor'].transform(lambda x: (x - x.mean()) / x.std())
    
    return combined[['factor']]


def calculate_obv_advanced_factor(
    data_manager: DataManager,
    start_date: str,
    end_date: str,
    stock_codes: Optional[List[str]] = None,
    trend_period: int = 20,
    divergence_period: int = 20,
    rank_period: int = 120,
    # æ•°æ®è´¨é‡ç­›é€‰å‚æ•°
    filter_st: bool = True,
    filter_suspend: bool = True,
    filter_limit: bool = True,
    min_turnover_rate: float = 0.01,
    min_price: float = 1.0,
) -> pd.DataFrame:
    """
    è®¡ç®—å¢å¼ºç‰ˆ OBV ç»¼åˆå› å­ï¼ŒåŒ…æ‹¬è¶‹åŠ¿ç±»å’Œä»·æ ¼èƒŒç¦»å› å­ã€‚
    
    **å› å­ç»„æˆ**ï¼š
    1. OBV è¶‹åŠ¿æ–œç‡å› å­ï¼šçº¿æ€§å›å½’æ–œç‡ï¼Œè¡¡é‡èµ„é‡‘æµå…¥/æµå‡ºé€Ÿåº¦
    2. OBV å˜åŒ–ç‡å› å­ï¼šOBV çš„ç™¾åˆ†æ¯”å˜åŒ–ï¼Œè¡¡é‡ç´¯ç§¯é‡èƒ½å¢é•¿
    3. OBV ç›¸å¯¹å¼ºåº¦å› å­ï¼šOBV åœ¨å†å²åŒºé—´çš„åˆ†ä½æ•°æ’å
    4. é‡ä»·èƒŒç¦»å› å­ï¼šOBV è¶‹åŠ¿ä¸ä»·æ ¼è¶‹åŠ¿çš„å·®å¼‚åº¦
    5. OBV çªç ´å› å­ï¼šOBV çªç ´å†å²é«˜ç‚¹çš„å¼ºåº¦
    
    **é€‰è‚¡é€»è¾‘**ï¼š
    - é«˜å› å­å€¼ = èµ„é‡‘æŒç»­æµå…¥ + é‡ä»·é…åˆè‰¯å¥½ + OBV çªç ´
    - é€‚åˆæ•æ‰ä¸»åŠ›å»ºä»“å’Œè¶‹åŠ¿å¯åŠ¨ä¿¡å·
    
    **æ•°æ®è´¨é‡ç­›é€‰**ï¼ˆå‚è€ƒ new_high_alpha_factor.pyï¼‰ï¼š
    - è¿‡æ»¤ ST/ST* è‚¡ç¥¨ï¼ˆé«˜é£é™©ï¼‰
    - è¿‡æ»¤åœç‰Œæ—¥æ•°æ®ï¼ˆæ— äº¤æ˜“ï¼‰
    - è¿‡æ»¤æ¶¨è·Œåœæ—¥æ•°æ®ï¼ˆæ— æ³•æ­£å¸¸äº¤æ˜“ï¼‰
    - è¿‡æ»¤ä½æµåŠ¨æ€§è‚¡ç¥¨ï¼ˆæ¢æ‰‹ç‡è¿‡ä½ï¼‰
    - è¿‡æ»¤ä½ä»·è‚¡ï¼ˆä»·æ ¼è¿‡ä½ï¼Œæ˜“æ“çºµï¼‰
    
    Parameters
    ----------
    data_manager : DataManager
        æ•°æ®ç®¡ç†å™¨å®ä¾‹
    start_date : str
        å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD'
    end_date : str
        ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD'
    stock_codes : Optional[List[str]]
        è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œå¦‚ä¸º None åˆ™ä½¿ç”¨æ‰€æœ‰å¯ç”¨è‚¡ç¥¨
    trend_period : int
        è¶‹åŠ¿è®¡ç®—å‘¨æœŸï¼Œé»˜è®¤ 20 å¤©
    divergence_period : int
        èƒŒç¦»è®¡ç®—å‘¨æœŸï¼Œé»˜è®¤ 20 å¤©
    rank_period : int
        ç›¸å¯¹å¼ºåº¦è®¡ç®—å‘¨æœŸï¼Œé»˜è®¤ 120 å¤©
    filter_st : bool
        æ˜¯å¦è¿‡æ»¤ ST è‚¡ç¥¨ï¼Œé»˜è®¤ True
    filter_suspend : bool
        æ˜¯å¦è¿‡æ»¤åœç‰Œæ•°æ®ï¼Œé»˜è®¤ True
    filter_limit : bool
        æ˜¯å¦è¿‡æ»¤æ¶¨è·Œåœæ•°æ®ï¼Œé»˜è®¤ True
    min_turnover_rate : float
        æœ€å°æ¢æ‰‹ç‡é˜ˆå€¼ï¼ˆ%ï¼‰ï¼Œé»˜è®¤ 0.01%ï¼ˆè¿‡æ»¤æä½æµåŠ¨æ€§ï¼‰
    min_price : float
        æœ€å°ä»·æ ¼é˜ˆå€¼ï¼ˆå…ƒï¼‰ï¼Œé»˜è®¤ 1.0 å…ƒï¼ˆè¿‡æ»¤ä½ä»·è‚¡ï¼‰
    
    Returns
    -------
    DataFrame
        MultiIndex (trade_date, ts_code) with columns:
        - factor: ç»¼åˆå› å­ï¼ˆåŠ æƒå¹³å‡ï¼‰
        - obv_slope: OBV æ–œç‡å› å­
        - obv_change: OBV å˜åŒ–ç‡å› å­
        - obv_rank: OBV ç›¸å¯¹å¼ºåº¦å› å­
        - obv_divergence: é‡ä»·èƒŒç¦»å› å­
        - obv_breakthrough: OBV çªç ´å› å­
    """
    print(f"\n{'='*60}")
    print("OBV å¢å¼ºç‰ˆç»¼åˆå› å­è®¡ç®—")
    print(f"{'='*60}")
    
    # è‚¡ç¥¨æ± 
    if stock_codes is None:
        print("æœªæŒ‡å®šè‚¡ç¥¨æ± ï¼Œä½¿ç”¨å…¨å¸‚åœºè‚¡ç¥¨...")
        all_daily = data_manager.load_data('daily', start_date=start_date, end_date=end_date, cleaned=True)
        if all_daily is None or all_daily.empty:
            stock_codes = ['000001.SZ', '000002.SZ', '000858.SZ', '600000.SH', '600036.SH', '600519.SH']
        else:
            stock_codes = all_daily['ts_code'].unique().tolist()
        print(f"âœ… è‚¡ç¥¨æ± : {len(stock_codes)} åªè‚¡ç¥¨")
    else:
        print(f"âœ… ä½¿ç”¨æŒ‡å®šè‚¡ç¥¨æ± : {len(stock_codes)} åªè‚¡ç¥¨")
    
    # åŠ è½½æ—¥çº¿æ•°æ®ï¼ˆéœ€è¦è¶³å¤Ÿçš„å†å²æ•°æ®ï¼‰
    buffer_days = max(trend_period, divergence_period, rank_period) * 3
    start_date_extended = (pd.to_datetime(start_date) - pd.Timedelta(days=buffer_days)).strftime('%Y-%m-%d')
    
    daily = data_manager.load_data('daily', start_date=start_date_extended, end_date=end_date, stock_codes=stock_codes)
    if daily is None or daily.empty:
        raise ValueError('æ— æ³•è·å–æ—¥è¡Œæƒ…æ•°æ®')
    
    # ç»Ÿä¸€æ—¥æœŸä¸º datetime å¹¶æ’åº
    daily = daily.copy()
    daily['trade_date'] = pd.to_datetime(daily['trade_date'], errors='coerce')
    if daily['trade_date'].isna().any():
        daily['trade_date'] = pd.to_datetime(daily['trade_date'].astype(str), format='%Y%m%d', errors='coerce')
    daily = daily.dropna(subset=['trade_date'])
    daily = daily.sort_values(['ts_code', 'trade_date']).reset_index(drop=True)
    
    print(f"âœ… æˆåŠŸåŠ è½½æ•°æ®")
    print(f"   æ•°æ®æ—¶é—´èŒƒå›´: {daily['trade_date'].min()} ~ {daily['trade_date'].max()}")
    print(f"   åŸå§‹æ•°æ®é‡: {len(daily):,} æ¡è®°å½•")
    
    # === æ•°æ®è´¨é‡ç­›é€‰ ===
    print(f"\næ­¥éª¤ 1: æ•°æ®è´¨é‡ç­›é€‰...")
    original_count = len(daily)
    
    # 1.1 è¿‡æ»¤ ST è‚¡ç¥¨
    if filter_st:
        # ST è‚¡ç¥¨é€šå¸¸åœ¨è‚¡ç¥¨åç§°ä¸­åŒ…å« ST/ST*/é€€å¸‚ç­‰æ ‡è¯†
        # æˆ–è€…é€šè¿‡ ts_code åˆ¤æ–­ï¼ˆå¦‚æœæœ‰ name å­—æ®µæ›´å‡†ç¡®ï¼‰
        # ç®€åŒ–å¤„ç†ï¼šé€šè¿‡æ¶¨è·Œå¹…é™åˆ¶åˆ¤æ–­ï¼ˆST è‚¡ç¥¨æ¶¨è·Œå¹…é™åˆ¶ä¸º Â±5%ï¼‰
        st_mask = daily['pct_chg'].abs() <= 5.5  # ç•™å‡ºå®¹é”™ç©ºé—´
        # æ›´ä¸¥æ ¼çš„åˆ¤æ–­ï¼šè¿ç»­å¤šæ—¥æ¶¨è·Œå¹…éƒ½åœ¨ Â±5% ä»¥å†…çš„å¯èƒ½æ˜¯ ST
        daily['is_likely_st'] = daily.groupby('ts_code')['pct_chg'].transform(
            lambda x: (x.abs() <= 5.5).rolling(5).mean() > 0.8
        )
        st_count = daily['is_likely_st'].sum()
        daily = daily[~daily['is_likely_st']].copy()
        print(f"   âœ“ è¿‡æ»¤ ST è‚¡ç¥¨: å‰”é™¤ {st_count:,} æ¡è®°å½•")
    
    # 1.2 è¿‡æ»¤åœç‰Œæ•°æ®
    if filter_suspend:
        # åœç‰Œåˆ¤æ–­ï¼šæˆäº¤é‡ä¸º 0 æˆ–æ¥è¿‘ 0
        suspend_mask = (daily['vol'] <= 0) | (daily['amount'] <= 0)
        suspend_count = suspend_mask.sum()
        daily = daily[~suspend_mask].copy()
        print(f"   âœ“ è¿‡æ»¤åœç‰Œæ•°æ®: å‰”é™¤ {suspend_count:,} æ¡è®°å½•")
    
    # 1.3 è¿‡æ»¤æ¶¨è·Œåœæ•°æ®
    if filter_limit:
        # æ¶¨åœï¼šæ¶¨å¹… > 9.8%ï¼ˆç§‘åˆ›æ¿/åˆ›ä¸šæ¿ä¸º 19.8%ï¼‰
        # è·Œåœï¼šè·Œå¹… < -9.8%
        # ä¸ºç®€åŒ–ï¼Œç»Ÿä¸€ä½¿ç”¨ 9.8% é˜ˆå€¼
        limit_up_mask = daily['pct_chg'] > 9.8
        limit_down_mask = daily['pct_chg'] < -9.8
        limit_count = (limit_up_mask | limit_down_mask).sum()
        daily = daily[~(limit_up_mask | limit_down_mask)].copy()
        print(f"   âœ“ è¿‡æ»¤æ¶¨è·Œåœæ•°æ®: å‰”é™¤ {limit_count:,} æ¡è®°å½•")
    
    # 1.4 åŠ è½½æ¢æ‰‹ç‡å’ŒæµåŠ¨æ€§æ•°æ®ï¼ˆå¢å¼ºç‰ˆï¼‰
    # éœ€è¦ä» daily_basic è·å–
    print(f"\n   === æµåŠ¨æ€§ç­›é€‰ï¼ˆå¢å¼ºç‰ˆï¼‰===")
    
    try:
        daily_basic = data_manager.load_data(
            'daily_basic', 
            start_date=start_date_extended, 
            end_date=end_date, 
            stock_codes=stock_codes
        )
        
        if daily_basic is not None and not daily_basic.empty:
            daily_basic = daily_basic.copy()
            daily_basic['trade_date'] = pd.to_datetime(daily_basic['trade_date'])
            
            # åˆå¹¶æ¢æ‰‹ç‡å’Œå¸‚å€¼æ•°æ®
            daily = pd.merge(
                daily,
                daily_basic[['ts_code', 'trade_date', 'turnover_rate', 'turnover_rate_f', 'volume_ratio', 'float_share', 'total_mv']],
                on=['ts_code', 'trade_date'],
                how='left'
            )
            
            print(f"   âœ“ æˆåŠŸåŠ è½½æµåŠ¨æ€§æ•°æ®")
            print(f"      - turnover_rate: æ¢æ‰‹ç‡ï¼ˆ%ï¼‰")
            print(f"      - turnover_rate_f: æ¢æ‰‹ç‡ï¼ˆè‡ªç”±æµé€šè‚¡ï¼‰")
            print(f"      - volume_ratio: é‡æ¯”")
            print(f"      - float_share: æµé€šè‚¡æœ¬ï¼ˆä¸‡è‚¡ï¼‰")
            print(f"      - total_mv: æ€»å¸‚å€¼ï¼ˆä¸‡å…ƒï¼‰")
            
            # 1.5 å¤šç»´åº¦æµåŠ¨æ€§ç­›é€‰
            print(f"\n   å¤šç»´åº¦æµåŠ¨æ€§ç­›é€‰:")
            
            # æ–¹æ³•1: æ¢æ‰‹ç‡ç­›é€‰ï¼ˆåŸºç¡€ï¼‰
            if 'turnover_rate' in daily.columns:
                low_turnover_mask = daily['turnover_rate'] < min_turnover_rate
                low_turnover_count = low_turnover_mask.sum()
                daily = daily[~low_turnover_mask].copy()
                print(f"      âœ“ æ¢æ‰‹ç‡è¿‡æ»¤ï¼ˆ<{min_turnover_rate}%ï¼‰: å‰”é™¤ {low_turnover_count:,} æ¡")
            
            # æ–¹æ³•2: è‡ªç”±æµé€šæ¢æ‰‹ç‡ç­›é€‰ï¼ˆæ›´ä¸¥æ ¼ï¼‰
            if 'turnover_rate_f' in daily.columns:
                low_float_turnover_mask = (
                    daily['turnover_rate_f'].notna() & 
                    (daily['turnover_rate_f'] < min_turnover_rate * 1.2)  # è‡ªç”±æµé€šæ¢æ‰‹ç‡è¦æ±‚æ›´é«˜
                )
                low_float_turnover_count = low_float_turnover_mask.sum()
                daily = daily[~low_float_turnover_mask].copy()
                print(f"      âœ“ è‡ªç”±æµé€šæ¢æ‰‹ç‡è¿‡æ»¤ï¼ˆ<{min_turnover_rate*1.2}%ï¼‰: å‰”é™¤ {low_float_turnover_count:,} æ¡")
            
            # æ–¹æ³•3: è¿ç»­ä½æ¢æ‰‹ç‡ç­›é€‰ï¼ˆè¯†åˆ«æŒç»­ä½æµåŠ¨æ€§ï¼‰
            if 'turnover_rate' in daily.columns:
                daily['avg_turnover_5d'] = daily.groupby('ts_code')['turnover_rate'].transform(
                    lambda x: x.rolling(5, min_periods=3).mean()
                )
                persistent_low_turnover_mask = daily['avg_turnover_5d'] < min_turnover_rate * 0.5
                persistent_low_count = persistent_low_turnover_mask.sum()
                daily = daily[~persistent_low_turnover_mask].copy()
                print(f"      âœ“ æŒç»­ä½æ¢æ‰‹ç‡è¿‡æ»¤ï¼ˆ5æ—¥å‡å€¼<{min_turnover_rate*0.5}%ï¼‰: å‰”é™¤ {persistent_low_count:,} æ¡")
                daily = daily.drop(columns=['avg_turnover_5d'], errors='ignore')
            
            # æ–¹æ³•4: æˆäº¤é‡‘é¢ç­›é€‰ï¼ˆç»å¯¹æµåŠ¨æ€§ï¼‰
            # è®¡ç®—æ—¥å‡æˆäº¤é‡‘é¢ï¼ˆä¸‡å…ƒï¼‰
            daily['amount_wan'] = daily['amount']  # amount å·²ç»æ˜¯ä¸‡å…ƒå•ä½
            
            # æŒ‰è‚¡ç¥¨åˆ†ç»„è®¡ç®—20æ—¥å¹³å‡æˆäº¤é‡‘é¢
            daily['avg_amount_20d'] = daily.groupby('ts_code')['amount_wan'].transform(
                lambda x: x.rolling(20, min_periods=10).mean()
            )
            
            # è¿‡æ»¤æ—¥å‡æˆäº¤é‡‘é¢è¿‡ä½çš„è‚¡ç¥¨ï¼ˆ< 1000ä¸‡å…ƒï¼‰
            min_daily_amount = 1000  # ä¸‡å…ƒ
            low_amount_mask = (
                daily['avg_amount_20d'].notna() & 
                (daily['avg_amount_20d'] < min_daily_amount)
            )
            low_amount_count = low_amount_mask.sum()
            daily = daily[~low_amount_mask].copy()
            print(f"      âœ“ æˆäº¤é‡‘é¢è¿‡æ»¤ï¼ˆ20æ—¥å‡å€¼<{min_daily_amount}ä¸‡å…ƒï¼‰: å‰”é™¤ {low_amount_count:,} æ¡")
            
            # æ–¹æ³•5: æµé€šå¸‚å€¼ç­›é€‰ï¼ˆé¿å…è¶…å°ç›˜è‚¡ï¼‰
            if 'float_share' in daily.columns and 'close' in daily.columns:
                # è®¡ç®—æµé€šå¸‚å€¼ï¼ˆä¸‡å…ƒï¼‰= æµé€šè‚¡æœ¬ï¼ˆä¸‡è‚¡ï¼‰Ã— æ”¶ç›˜ä»·
                daily['float_mv'] = daily['float_share'] * daily['close']
                
                # è¿‡æ»¤æµé€šå¸‚å€¼è¿‡å°çš„è‚¡ç¥¨ï¼ˆ< 5äº¿å…ƒ = 50000ä¸‡å…ƒï¼‰
                min_float_mv = 50000  # ä¸‡å…ƒï¼ˆ5äº¿ï¼‰
                small_float_mask = (
                    daily['float_mv'].notna() & 
                    (daily['float_mv'] < min_float_mv)
                )
                small_float_count = small_float_mask.sum()
                daily = daily[~small_float_mask].copy()
                print(f"      âœ“ æµé€šå¸‚å€¼è¿‡æ»¤ï¼ˆ<{min_float_mv/10000:.1f}äº¿å…ƒï¼‰: å‰”é™¤ {small_float_count:,} æ¡")
                
                daily = daily.drop(columns=['float_mv'], errors='ignore')
            
            # æ–¹æ³•6: æ¢æ‰‹ç‡ç¨³å®šæ€§ç­›é€‰ï¼ˆé¿å…æµåŠ¨æ€§ä¸ç¨³å®šçš„è‚¡ç¥¨ï¼‰
            if 'turnover_rate' in daily.columns:
                daily['turnover_std_20d'] = daily.groupby('ts_code')['turnover_rate'].transform(
                    lambda x: x.rolling(20, min_periods=10).std()
                )
                daily['turnover_mean_20d'] = daily.groupby('ts_code')['turnover_rate'].transform(
                    lambda x: x.rolling(20, min_periods=10).mean()
                )
                
                # å˜å¼‚ç³»æ•° = æ ‡å‡†å·® / å‡å€¼
                # è¿‡æ»¤å˜å¼‚ç³»æ•°è¿‡å¤§çš„è‚¡ç¥¨ï¼ˆæµåŠ¨æ€§ä¸ç¨³å®šï¼‰
                daily['turnover_cv'] = np.where(
                    daily['turnover_mean_20d'] > 0,
                    daily['turnover_std_20d'] / daily['turnover_mean_20d'],
                    np.nan
                )
                
                unstable_turnover_mask = (
                    daily['turnover_cv'].notna() & 
                    (daily['turnover_cv'] > 5)  # å˜å¼‚ç³»æ•° > 5 è§†ä¸ºä¸ç¨³å®š
                )
                unstable_count = unstable_turnover_mask.sum()
                daily = daily[~unstable_turnover_mask].copy()
                print(f"      âœ“ æ¢æ‰‹ç‡ç¨³å®šæ€§è¿‡æ»¤ï¼ˆå˜å¼‚ç³»æ•°>5ï¼‰: å‰”é™¤ {unstable_count:,} æ¡")
                
                daily = daily.drop(columns=['turnover_std_20d', 'turnover_mean_20d', 'turnover_cv'], errors='ignore')
            
            # æ–¹æ³•7: é‡æ¯”å¼‚å¸¸ç­›é€‰ï¼ˆè¯†åˆ«å¼‚å¸¸äº¤æ˜“æ—¥ï¼‰
            if 'volume_ratio' in daily.columns:
                # é‡æ¯”è¿‡é«˜ï¼ˆ>10ï¼‰æˆ–è¿‡ä½ï¼ˆ<0.1ï¼‰éƒ½å¯èƒ½æœ‰é—®é¢˜
                abnormal_volume_ratio_mask = (
                    daily['volume_ratio'].notna() & 
                    ((daily['volume_ratio'] > 10) | (daily['volume_ratio'] < 0.1))
                )
                abnormal_vr_count = abnormal_volume_ratio_mask.sum()
                daily = daily[~abnormal_volume_ratio_mask].copy()
                print(f"      âœ“ é‡æ¯”å¼‚å¸¸è¿‡æ»¤ï¼ˆ<0.1 æˆ– >10ï¼‰: å‰”é™¤ {abnormal_vr_count:,} æ¡")
            
            # æ¸…ç†ä¸´æ—¶åˆ—
            daily = daily.drop(columns=['amount_wan', 'avg_amount_20d'], errors='ignore')
            
            # æµåŠ¨æ€§ç­›é€‰æ€»ç»“
            print(f"\n   ğŸ“Š æµåŠ¨æ€§ç­›é€‰æ€»ç»“:")
            remaining_stocks = daily['ts_code'].nunique()
            remaining_records = len(daily)
            print(f"      å‰©ä½™è‚¡ç¥¨æ•°: {remaining_stocks}")
            print(f"      å‰©ä½™è®°å½•æ•°: {remaining_records:,}")
            
        else:
            print(f"   âš ï¸  è­¦å‘Š: æ— æ³•åŠ è½½ daily_basic æ•°æ®ï¼Œè·³è¿‡æµåŠ¨æ€§ç­›é€‰")
            print(f"   å°†ä½¿ç”¨ç®€åŒ–çš„æµåŠ¨æ€§ç­›é€‰ï¼ˆåŸºäºæˆäº¤é‡ï¼‰")
            
            # ç®€åŒ–çš„æµåŠ¨æ€§ç­›é€‰ï¼ˆä»…åŸºäºæˆäº¤é‡ï¼‰
            # è®¡ç®—20æ—¥å¹³å‡æˆäº¤é‡
            daily['avg_vol_20d'] = daily.groupby('ts_code')['vol'].transform(
                lambda x: x.rolling(20, min_periods=10).mean()
            )
            
            # è¿‡æ»¤å¹³å‡æˆäº¤é‡è¿‡ä½çš„è‚¡ç¥¨
            vol_median = daily['avg_vol_20d'].median()
            low_vol_mask = (
                daily['avg_vol_20d'].notna() & 
                (daily['avg_vol_20d'] < vol_median * 0.1)  # ä½äºä¸­ä½æ•°çš„10%
            )
            low_vol_count = low_vol_mask.sum()
            daily = daily[~low_vol_mask].copy()
            print(f"   âœ“ ä½æˆäº¤é‡è¿‡æ»¤ï¼ˆ<ä¸­ä½æ•°10%ï¼‰: å‰”é™¤ {low_vol_count:,} æ¡è®°å½•")
            
            daily = daily.drop(columns=['avg_vol_20d'], errors='ignore')
            
    except Exception as e:
        print(f"   âš ï¸  è­¦å‘Š: æµåŠ¨æ€§ç­›é€‰å¤±è´¥ ({e})ï¼Œè·³è¿‡æ­¤æ­¥éª¤")
    
    # 1.6 è¿‡æ»¤ä½ä»·è‚¡
    low_price_mask = daily['close'] < min_price
    low_price_count = low_price_mask.sum()
    daily = daily[~low_price_mask].copy()
    print(f"   âœ“ è¿‡æ»¤ä½ä»·è‚¡ï¼ˆä»·æ ¼<{min_price}å…ƒï¼‰: å‰”é™¤ {low_price_count:,} æ¡è®°å½•")
    
    # 1.7 è¿‡æ»¤å¼‚å¸¸æ¶¨è·Œå¹…æ•°æ®
    extreme_pct_mask = daily['pct_chg'].abs() > 30  # å•æ—¥æ¶¨è·Œå¹…è¶…è¿‡ 30% è§†ä¸ºå¼‚å¸¸
    extreme_pct_count = extreme_pct_mask.sum()
    daily = daily[~extreme_pct_mask].copy()
    print(f"   âœ“ è¿‡æ»¤å¼‚å¸¸æ¶¨è·Œå¹…æ•°æ®ï¼ˆ|æ¶¨è·Œå¹…|>30%ï¼‰: å‰”é™¤ {extreme_pct_count:,} æ¡è®°å½•")
    
    # === æˆäº¤é‡å¼‚å¸¸å¤„ç†ï¼ˆæ–°å¢ï¼‰===
    print(f"\n   æˆäº¤é‡å¼‚å¸¸æ£€æµ‹ä¸å¤„ç†:")
    
    # 1.8 è¿‡æ»¤æˆäº¤é‡ä¸º0æˆ–è´Ÿæ•°çš„å¼‚å¸¸æ•°æ®
    zero_volume_mask = (daily['vol'] <= 0)
    zero_volume_count = zero_volume_mask.sum()
    daily = daily[~zero_volume_mask].copy()
    print(f"   âœ“ è¿‡æ»¤é›¶æˆäº¤é‡æ•°æ®: å‰”é™¤ {zero_volume_count:,} æ¡è®°å½•")
    
    # 1.9 è¿‡æ»¤æˆäº¤é‡å¼‚å¸¸æ”¾å¤§ï¼ˆå¯èƒ½æ˜¯æ•°æ®é”™è¯¯æˆ–ç‰¹æ®Šäº‹ä»¶ï¼‰
    # è®¡ç®—æ¯åªè‚¡ç¥¨çš„æˆäº¤é‡ç§»åŠ¨å¹³å‡å’Œæ ‡å‡†å·®
    daily['vol_ma'] = daily.groupby('ts_code')['vol'].transform(
        lambda x: x.rolling(20, min_periods=5).mean()
    )
    daily['vol_std'] = daily.groupby('ts_code')['vol'].transform(
        lambda x: x.rolling(20, min_periods=5).std()
    )
    
    # å¼‚å¸¸æ”¾é‡å®šä¹‰ï¼šæˆäº¤é‡è¶…è¿‡å‡å€¼+10å€æ ‡å‡†å·®
    extreme_volume_mask = (
        (daily['vol'] > daily['vol_ma'] + 10 * daily['vol_std']) & 
        (daily['vol_std'] > 0)
    )
    extreme_volume_count = extreme_volume_mask.sum()
    
    if extreme_volume_count > 0:
        print(f"   âš ï¸  æ£€æµ‹åˆ° {extreme_volume_count:,} ä¸ªå¼‚å¸¸æ”¾é‡æ•°æ®ï¼ˆ>å‡å€¼+10Ïƒï¼‰")
        # å¯¹äºå¼‚å¸¸æ”¾é‡ï¼Œé™åˆ¶å…¶å€¼è€Œä¸æ˜¯ç›´æ¥åˆ é™¤ï¼ˆå¯èƒ½æ˜¯çœŸå®çš„é‡å¤§äº‹ä»¶ï¼‰
        daily.loc[extreme_volume_mask, 'vol'] = (
            daily.loc[extreme_volume_mask, 'vol_ma'] + 
            5 * daily.loc[extreme_volume_mask, 'vol_std']
        )
        print(f"      å·²å°†å¼‚å¸¸å€¼é™åˆ¶åˆ°å‡å€¼+5Ïƒ")
    
    # 1.10 è¿‡æ»¤æˆäº¤é‡å¼‚å¸¸ç¼©å°ï¼ˆå¯èƒ½æ˜¯æ•°æ®ç¼ºå¤±ï¼‰
    # å¼‚å¸¸ç¼©é‡å®šä¹‰ï¼šæˆäº¤é‡ä½äºå‡å€¼çš„1%ï¼ˆä¸”å‡å€¼>0ï¼‰
    extreme_low_volume_mask = (
        (daily['vol'] < daily['vol_ma'] * 0.01) & 
        (daily['vol_ma'] > 0)
    )
    extreme_low_volume_count = extreme_low_volume_mask.sum()
    daily = daily[~extreme_low_volume_mask].copy()
    print(f"   âœ“ è¿‡æ»¤å¼‚å¸¸ç¼©é‡æ•°æ®ï¼ˆ<å‡å€¼1%ï¼‰: å‰”é™¤ {extreme_low_volume_count:,} æ¡è®°å½•")
    
    # 1.11 æˆäº¤é‡ä¸æˆäº¤é¢ä¸€è‡´æ€§æ£€æŸ¥
    if 'amount' in daily.columns:
        # è®¡ç®—éšå«ä»·æ ¼ï¼šæˆäº¤é¢ / æˆäº¤é‡ï¼ˆæ‰‹è½¬æ¢ä¸ºè‚¡ï¼‰
        daily['implied_price'] = daily['amount'] * 1000 / (daily['vol'] * 100)  # æˆäº¤é¢å•ä½ï¼šåƒå…ƒï¼Œæˆäº¤é‡å•ä½ï¼šæ‰‹
        
        # æ£€æŸ¥éšå«ä»·æ ¼æ˜¯å¦ä¸æ”¶ç›˜ä»·æ¥è¿‘ï¼ˆå…è®¸20%è¯¯å·®ï¼‰
        price_mismatch_mask = (
            (daily['implied_price'].notna()) &
            (daily['close'] > 0) &
            (
                (daily['implied_price'] / daily['close'] > 1.5) | 
                (daily['implied_price'] / daily['close'] < 0.5)
            )
        )
        price_mismatch_count = price_mismatch_mask.sum()
        
        if price_mismatch_count > 0:
            print(f"   âš ï¸  æ£€æµ‹åˆ° {price_mismatch_count:,} ä¸ªé‡ä»·ä¸ä¸€è‡´æ•°æ®")
            daily = daily[~price_mismatch_mask].copy()
            print(f"      å·²å‰”é™¤é‡ä»·ä¸ä¸€è‡´æ•°æ®")
        
        # æ¸…ç†ä¸´æ—¶åˆ—
        daily = daily.drop(columns=['implied_price'], errors='ignore')
    
    # æ¸…ç†ä¸´æ—¶è®¡ç®—åˆ—
    daily = daily.drop(columns=['vol_ma', 'vol_std'], errors='ignore')
    
    # ç­›é€‰æ€»ç»“
    filtered_count = len(daily)
    filter_rate = (original_count - filtered_count) / original_count * 100
    print(f"\n   ğŸ“Š ç­›é€‰æ±‡æ€»:")
    print(f"      åŸå§‹æ•°æ®: {original_count:,} æ¡")
    print(f"      ç­›é€‰å: {filtered_count:,} æ¡")
    print(f"      è¿‡æ»¤æ¯”ä¾‹: {filter_rate:.2f}%")
    print(f"      ä¿ç•™è‚¡ç¥¨æ•°: {daily['ts_code'].nunique()}")
    
    # è®¡ç®—å„ç±» OBV è¡ç”Ÿå› å­
    print(f"\næ­¥éª¤ 2: è®¡ç®—åŸºç¡€ OBV å’Œè¡ç”Ÿå› å­...")
    print(f"   OBV è®¡ç®—æ”¹è¿›:")
    print(f"      âœ“ ä½¿ç”¨ç™¾åˆ†æ¯”å˜åŒ–åˆ¤æ–­æ–¹å‘ï¼ˆé¿å…ä»·æ ¼é‡çº§å½±å“ï¼‰")
    print(f"      âœ“ è®¾ç½®å˜åŒ–é˜ˆå€¼è¿‡æ»¤å™ªéŸ³ï¼ˆ{0.0001*100:.3f}%ï¼‰")
    print(f"      âœ“ ä»·æ ¼å¹³ç¨³æ—¶å»¶ç»­å‰ä¸€æ—¥æ–¹å‘")
    print(f"      âœ“ ä»0å¼€å§‹ç´¯ç§¯ï¼ˆæ ‡å‡†åšæ³•ï¼‰")
    
    result_parts = []
    
    for code, group in daily.groupby('ts_code'):
        df = group.sort_values('trade_date').copy()
        
        # === æˆäº¤é‡è´¨é‡æ£€æŸ¥ï¼ˆæ–°å¢ï¼‰===
        # ç¡®ä¿æˆäº¤é‡éƒ½æ˜¯æ­£æ•°
        if (df['vol'] <= 0).any():
            print(f"   âš ï¸  è­¦å‘Š: è‚¡ç¥¨ {code} ä»æœ‰é›¶æˆäº¤é‡ï¼Œå·²è·³è¿‡")
            continue
        
        # æ£€æŸ¥æˆäº¤é‡çš„è¿ç»­æ€§ï¼ˆæ˜¯å¦æœ‰å¤§é‡ç¼ºå¤±ï¼‰
        expected_days = (df['trade_date'].max() - df['trade_date'].min()).days
        actual_days = len(df)
        coverage_ratio = actual_days / (expected_days / 7 * 5)  # ä¼°ç®—äº¤æ˜“æ—¥æ•°é‡
        
        if coverage_ratio < 0.5:  # æ•°æ®è¦†ç›–ç‡ä½äº50%
            print(f"   âš ï¸  è­¦å‘Š: è‚¡ç¥¨ {code} æ•°æ®è¦†ç›–ç‡ä»… {coverage_ratio*100:.1f}%ï¼Œå·²è·³è¿‡")
            continue
        
        # === ä¼˜åŒ–çš„ OBV è®¡ç®— ===
        # é—®é¢˜1: ä½¿ç”¨ç›¸å¯¹å˜åŒ–è€Œéç»å¯¹å˜åŒ–ï¼Œé¿å…ä»·æ ¼é‡çº§å½±å“
        # é—®é¢˜2: å¤„ç†ä»·æ ¼ç›¸ç­‰çš„æƒ…å†µï¼ˆæ²¿ç”¨å‰ä¸€å¤©çš„æ–¹å‘ï¼‰
        # é—®é¢˜3: åˆå§‹å€¼ä»0å¼€å§‹ï¼ˆæ ‡å‡†åšæ³•ï¼‰
        # é—®é¢˜4: æˆäº¤é‡å¼‚å¸¸çš„æƒ…å†µéœ€è¦ç‰¹æ®Šå¤„ç†
        
        # è®¡ç®—ä»·æ ¼å˜åŠ¨
        df['prev_close'] = df['close'].shift(1)
        
        # æ›´ç²¾ç¡®çš„æ–¹å‘åˆ¤æ–­ï¼ˆä½¿ç”¨ç™¾åˆ†æ¯”å˜åŒ–ï¼Œé¿å…å¾®å°ä»·æ ¼å˜åŠ¨çš„å™ªéŸ³ï¼‰
        price_change_pct = (df['close'] - df['prev_close']) / df['prev_close']
        
        # è®¾å®šé˜ˆå€¼ï¼Œå°äºé˜ˆå€¼è§†ä¸ºæ— å˜åŒ–ï¼ˆè¿‡æ»¤å™ªéŸ³ï¼‰
        price_threshold = 0.0001  # 0.01% çš„å˜åŒ–é˜ˆå€¼
        
        def determine_direction(change_pct, prev_direction):
            """
            ç¡®å®šå½“æ—¥æ–¹å‘
            - æ¶¨å¹… > é˜ˆå€¼: +1
            - è·Œå¹… < -é˜ˆå€¼: -1
            - å…¶ä»–æƒ…å†µ: å»¶ç»­å‰ä¸€æ—¥æ–¹å‘ï¼ˆå¦‚æœæ˜¯ç¬¬ä¸€å¤©ï¼Œåˆ™ä¸º0ï¼‰
            """
            if pd.isna(change_pct):
                return 0
            elif change_pct > price_threshold:
                return 1
            elif change_pct < -price_threshold:
                return -1
            else:
                # ä»·æ ¼å‡ ä¹ä¸å˜ï¼Œå»¶ç»­å‰ä¸€æ—¥æ–¹å‘
                return prev_direction if not pd.isna(prev_direction) else 0
        
        # è®¡ç®—æ–¹å‘ï¼ˆä½¿ç”¨å¾ªç¯ä»¥æ”¯æŒå»¶ç»­å‰ä¸€æ—¥æ–¹å‘ï¼‰
        directions = [0]  # ç¬¬ä¸€å¤©é»˜è®¤ä¸º0
        for i in range(1, len(df)):
            direction = determine_direction(
                price_change_pct.iloc[i], 
                directions[-1]
            )
            directions.append(direction)
        
        df['direction'] = directions
        
        # è®¡ç®— OBVï¼ˆä»0å¼€å§‹ç´¯ç§¯ï¼‰
        # æˆäº¤é‡å®‰å…¨æ€§æ£€æŸ¥
        vol_with_direction = df['direction'] * df['vol']
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸å¤§çš„å•æ—¥OBVå˜åŒ–
        vol_median = df['vol'].median()
        extreme_obv_change = vol_with_direction.abs() > (vol_median * 100)
        
        if extreme_obv_change.any():
            extreme_count = extreme_obv_change.sum()
            print(f"   âš ï¸  è­¦å‘Š: è‚¡ç¥¨ {code} æœ‰ {extreme_count} ä¸ªæç«¯OBVå˜åŒ–ï¼Œå·²é™åˆ¶")
            # å°†æç«¯å€¼é™åˆ¶åˆ°ä¸­ä½æ•°çš„50å€
            vol_with_direction = vol_with_direction.clip(
                -vol_median * 50, 
                vol_median * 50
            )
        
        df['obv'] = vol_with_direction.cumsum()
        
        # éªŒè¯ï¼šç¡®ä¿ OBV è®¡ç®—æ­£ç¡®
        # å¯¹äºç¬¬ä¸€å¤©ï¼ŒOBV = direction * vol
        # å¯¹äºåç»­å¤©ï¼ŒOBV = å‰ä¸€å¤©OBV + direction * vol
        
        # æ•°æ®è´¨é‡æ£€æŸ¥
        if df['obv'].isna().any():
            print(f"   âš ï¸  è­¦å‘Š: è‚¡ç¥¨ {code} å­˜åœ¨ NaN å€¼ï¼Œå·²è·³è¿‡")
            continue
        
        # è¿‡æ»¤å¼‚å¸¸OBVå€¼ï¼ˆä¾‹å¦‚çªç„¶å˜åŒ–è¿‡å¤§ï¼‰
        obv_change = df['obv'].diff().abs()
        obv_median_change = obv_change.median()
        # å¼‚å¸¸å€¼å®šä¹‰ï¼šå˜åŒ–è¶…è¿‡ä¸­ä½æ•°çš„100å€
        if obv_median_change > 0:
            abnormal_mask = obv_change > (obv_median_change * 100)
            if abnormal_mask.sum() > 0:
                print(f"   âš ï¸  è­¦å‘Š: è‚¡ç¥¨ {code} å­˜åœ¨ {abnormal_mask.sum()} ä¸ªå¼‚å¸¸OBVå˜åŒ–")
        
        result_parts.append(df)
    
    if not result_parts:
        raise ValueError("æ‰€æœ‰è‚¡ç¥¨çš„ OBV è®¡ç®—éƒ½å¤±è´¥äº†")
    
    print(f"âœ… å®Œæˆ {len(result_parts)} åªè‚¡ç¥¨çš„åŸºç¡€ OBV è®¡ç®—")
    
    # OBV è®¡ç®—è´¨é‡æ£€æŸ¥
    print(f"\n   OBV è®¡ç®—è´¨é‡æ£€æŸ¥:")
    all_obv_changes = []
    all_vol_ratios = []  # æ–°å¢ï¼šæˆäº¤é‡æ¯”ç‡æ£€æŸ¥
    
    for df in result_parts:
        obv_pct_change = df['obv'].pct_change().abs()
        all_obv_changes.extend(obv_pct_change.dropna().tolist())
        
        # æ£€æŸ¥æˆäº¤é‡çš„ç¨³å®šæ€§
        vol_ratio = df['vol'] / df['vol'].rolling(20).mean()
        all_vol_ratios.extend(vol_ratio.dropna().tolist())
    
    if all_obv_changes:
        all_obv_changes = pd.Series(all_obv_changes)
        print(f"      OBV å˜åŒ–ç‡ä¸­ä½æ•°: {all_obv_changes.median():.4f}")
        print(f"      OBV å˜åŒ–ç‡å‡å€¼: {all_obv_changes.mean():.4f}")
        print(f"      OBV å¼‚å¸¸å˜åŒ–(>100%)æ¯”ä¾‹: {(all_obv_changes > 1.0).mean():.2%}")
    
    if all_vol_ratios:
        all_vol_ratios = pd.Series(all_vol_ratios)
        print(f"\n      æˆäº¤é‡ç¨³å®šæ€§æ£€æŸ¥:")
        print(f"         æˆäº¤é‡/å‡å€¼ ä¸­ä½æ•°: {all_vol_ratios.median():.2f}")
        print(f"         å¼‚å¸¸æ”¾é‡(>5å€å‡å€¼)æ¯”ä¾‹: {(all_vol_ratios > 5).mean():.2%}")
        print(f"         å¼‚å¸¸ç¼©é‡(<0.2å€å‡å€¼)æ¯”ä¾‹: {(all_vol_ratios < 0.2).mean():.2%}")
    
    # è®¡ç®—è¡ç”Ÿå› å­
    print(f"\n   è®¡ç®— OBV è¡ç”Ÿå› å­...")
    for i, df in enumerate(result_parts):
        # === å› å­ 1: OBV è¶‹åŠ¿æ–œç‡ ===
        # ä½¿ç”¨çº¿æ€§å›å½’è®¡ç®—æ–œç‡
        def calc_slope(series):
            if len(series) < trend_period or series.isna().any():
                return np.nan
            x = np.arange(len(series))
            y = series.values
            try:
                slope = np.polyfit(x, y, 1)[0]
                return slope
            except:
                return np.nan
        
        df['obv_slope'] = df['obv'].rolling(trend_period).apply(calc_slope, raw=False)
        
        # === å› å­ 2: OBV å˜åŒ–ç‡ ===
        # ä½¿ç”¨å®‰å…¨çš„ç™¾åˆ†æ¯”å˜åŒ–è®¡ç®—ï¼Œé¿å…é™¤ä»¥0
        obv_shifted = df['obv'].shift(trend_period)
        # é¿å…é™¤ä»¥0æˆ–æå°å€¼
        df['obv_change'] = np.where(
            obv_shifted.abs() > 1e-10,  # åªæœ‰å½“åˆ†æ¯è¶³å¤Ÿå¤§æ—¶æ‰è®¡ç®—
            (df['obv'] - obv_shifted) / obv_shifted.abs(),
            0  # å¦åˆ™è¿”å›0
        )
        
        # é™åˆ¶å˜åŒ–ç‡èŒƒå›´ï¼Œé¿å…æç«¯å€¼
        df['obv_change'] = df['obv_change'].clip(-10, 10)  # é™åˆ¶åœ¨Â±1000%
        
        # === å› å­ 3: OBV ç›¸å¯¹å¼ºåº¦ï¼ˆåˆ†ä½æ•°æ’åï¼‰===
        df['obv_rank'] = df['obv'].rolling(rank_period).apply(
            lambda x: pd.Series(x).rank(pct=True).iloc[-1] if len(x) >= trend_period else np.nan,
            raw=False
        )
        
        # === å› å­ 4: é‡ä»·èƒŒç¦»åº¦ ===
        # è®¡ç®—ä»·æ ¼è¶‹åŠ¿æ–œç‡
        def calc_price_slope(series):
            if len(series) < divergence_period or series.isna().any():
                return np.nan
            x = np.arange(len(series))
            y = series.values
            try:
                slope = np.polyfit(x, y, 1)[0]
                return slope
            except:
                return np.nan
        
        price_slope = df['close'].rolling(divergence_period).apply(calc_price_slope, raw=False)
        obv_slope_div = df['obv'].rolling(divergence_period).apply(calc_price_slope, raw=False)
        
        # æ ‡å‡†åŒ–åè®¡ç®—èƒŒç¦»åº¦ï¼ˆæ­£å€¼è¡¨ç¤ºé‡èƒ½å¼ºäºä»·æ ¼ï¼‰
        # ä½¿ç”¨æ›´ç¨³å¥çš„æ ‡å‡†åŒ–æ–¹æ³•
        def safe_normalize(series):
            """å®‰å…¨çš„æ ‡å‡†åŒ–ï¼Œé¿å…é™¤ä»¥0"""
            mean = series.mean()
            std = series.std()
            if pd.isna(mean) or pd.isna(std) or std < 1e-8:
                return pd.Series(0, index=series.index)
            return (series - mean) / std
        
        price_slope_norm = safe_normalize(price_slope)
        obv_slope_norm = safe_normalize(obv_slope_div)
        df['obv_divergence'] = obv_slope_norm - price_slope_norm
        
        # === å› å­ 5: OBV çªç ´å¼ºåº¦ ===
        df['obv_high'] = df['obv'].rolling(rank_period).max()
        obv_high_shifted = df['obv_high'].shift(1)
        
        # å®‰å…¨çš„çªç ´å¼ºåº¦è®¡ç®—
        df['obv_breakthrough'] = np.where(
            obv_high_shifted.abs() > 1e-10,
            (df['obv'] - obv_high_shifted) / obv_high_shifted.abs(),
            0
        )
        
        # é™åˆ¶çªç ´å¼ºåº¦èŒƒå›´
        df['obv_breakthrough'] = df['obv_breakthrough'].clip(-5, 5)
        
        result_parts[i] = df
    
    print(f"âœ… å®Œæˆæ‰€æœ‰è¡ç”Ÿå› å­è®¡ç®—")
    
    # åˆå¹¶æ‰€æœ‰è‚¡ç¥¨
    combined = pd.concat(result_parts, ignore_index=True)
    
    # è¿‡æ»¤åˆ°æŒ‡å®šæ—¥æœŸèŒƒå›´
    combined = combined[combined['trade_date'] >= start_date].copy()
    
    print(f"\næ­¥éª¤ 3: æˆªé¢æ ‡å‡†åŒ–å„å­å› å­...")
    
    # æˆªé¢æ ‡å‡†åŒ–æ¯ä¸ªå› å­
    factor_cols = ['obv_slope', 'obv_change', 'obv_rank', 'obv_divergence', 'obv_breakthrough']
    
    print(f"   æ ‡å‡†åŒ–å‰å¼‚å¸¸å€¼ç»Ÿè®¡:")
    for col in factor_cols:
        col_data = combined[col].dropna()
        if len(col_data) > 0:
            print(f"      {col}:")
            print(f"         å‡å€¼: {col_data.mean():.4f}, æ ‡å‡†å·®: {col_data.std():.4f}")
            print(f"         æœ€å°å€¼: {col_data.min():.4f}, æœ€å¤§å€¼: {col_data.max():.4f}")
            print(f"         æç«¯å€¼(|z|>5): {(abs((col_data - col_data.mean()) / (col_data.std() + 1e-8)) > 5).sum()} ä¸ª")
    
    # ç¬¬ä¸€æ­¥ï¼šå¤„ç†æ— ç©·å€¼å’Œç¼ºå¤±å€¼
    for col in factor_cols:
        # æ›¿æ¢æ— ç©·å€¼ä¸º NaN
        combined[col] = combined[col].replace([np.inf, -np.inf], np.nan)
        
        # ç»Ÿè®¡ç¼ºå¤±å€¼
        nan_count = combined[col].isna().sum()
        if nan_count > 0:
            print(f"   å¤„ç† {col} çš„ {nan_count} ä¸ªç¼ºå¤±å€¼")
    
    # ç¬¬äºŒæ­¥ï¼šæç«¯å€¼å¤„ç†ï¼ˆåœ¨æ ‡å‡†åŒ–ä¹‹å‰ï¼ŒæŒ‰æ—¥æœŸåˆ†ç»„å¤„ç†ï¼‰
    print(f"\n   æç«¯å€¼å¤„ç†ï¼ˆMAD æ–¹æ³•ï¼‰:")
    for col in factor_cols:
        def winsorize_by_mad(series, n_mad=5):
            """
            ä½¿ç”¨ MAD (Median Absolute Deviation) æ–¹æ³•å¤„ç†æç«¯å€¼
            æ¯”æ ‡å‡†å·®æ–¹æ³•æ›´ç¨³å¥ï¼Œä¸å—æç«¯å€¼å½±å“
            """
            if series.isna().all() or len(series) < 10:
                return series
            
            median = series.median()
            mad = (series - median).abs().median()
            
            if mad == 0:
                # MAD ä¸º 0 è¯´æ˜æ•°æ®å˜åŒ–å¾ˆå°ï¼Œä½¿ç”¨æ ‡å‡†å·®æ–¹æ³•
                std = series.std()
                if std > 0:
                    lower = series.mean() - 5 * std
                    upper = series.mean() + 5 * std
                else:
                    return series
            else:
                # MAD æ–¹æ³•ï¼šæç«¯å€¼å®šä¹‰ä¸ºåç¦»ä¸­ä½æ•°è¶…è¿‡ n_mad ä¸ª MAD
                lower = median - n_mad * 1.4826 * mad  # 1.4826 æ˜¯ä½¿ MAD ç­‰ä»·äºæ ‡å‡†å·®çš„ç³»æ•°
                upper = median + n_mad * 1.4826 * mad
            
            # Winsorizeï¼šå°†æç«¯å€¼æ‹‰å›åˆ°è¾¹ç•Œ
            return series.clip(lower, upper)
        
        # æŒ‰æ—¥æœŸåˆ†ç»„å¤„ç†æç«¯å€¼
        combined[col] = combined.groupby('trade_date')[col].transform(
            lambda x: winsorize_by_mad(x, n_mad=5)
        )
        
        # ç»Ÿè®¡å¤„ç†æ•ˆæœ
        after_data = combined[col].dropna()
        if len(after_data) > 0:
            print(f"      {col}: èŒƒå›´ [{after_data.min():.4f}, {after_data.max():.4f}]")
    
    # ç¬¬ä¸‰æ­¥ï¼šæˆªé¢æ ‡å‡†åŒ–
    print(f"\n   æ‰§è¡Œæˆªé¢æ ‡å‡†åŒ–...")
    
    def safe_standardize(series, min_std=1e-8, min_samples=10):
        """
        å®‰å…¨çš„æˆªé¢æ ‡å‡†åŒ–å‡½æ•°
        
        Parameters
        ----------
        series : pd.Series
            å¾…æ ‡å‡†åŒ–çš„åºåˆ—
        min_std : float
            æœ€å°æ ‡å‡†å·®é˜ˆå€¼ï¼Œä½äºæ­¤å€¼è§†ä¸ºæ— å˜åŒ–
        min_samples : int
            æœ€å°æ ·æœ¬æ•°ï¼Œä½äºæ­¤å€¼ä¸è¿›è¡Œæ ‡å‡†åŒ–
        
        Returns
        -------
        pd.Series
            æ ‡å‡†åŒ–åçš„åºåˆ—
        """
        # ç§»é™¤ NaN å€¼
        valid_data = series.dropna()
        
        # æ ·æœ¬æ•°ä¸è¶³
        if len(valid_data) < min_samples:
            return pd.Series(0, index=series.index)
        
        # è®¡ç®—ç»Ÿè®¡é‡
        mean = valid_data.mean()
        std = valid_data.std()
        
        # æ£€æŸ¥ç»Ÿè®¡é‡æœ‰æ•ˆæ€§
        if pd.isna(mean) or pd.isna(std):
            return pd.Series(0, index=series.index)
        
        # æ ‡å‡†å·®è¿‡å°ï¼ˆæ•°æ®å‡ ä¹æ— å˜åŒ–ï¼‰
        if std < min_std:
            return pd.Series(0, index=series.index)
        
        # æ‰§è¡Œæ ‡å‡†åŒ–
        result = (series - mean) / std
        
        # æ›¿æ¢å¯èƒ½äº§ç”Ÿçš„æ— ç©·å€¼
        result = result.replace([np.inf, -np.inf], 0)
        
        return result
    
    for col in factor_cols:
        combined[col] = combined.groupby('trade_date')[col].transform(safe_standardize)
        
        # éªŒè¯æ ‡å‡†åŒ–ç»“æœ
        invalid_count = combined[col].isin([np.inf, -np.inf]).sum()
        if invalid_count > 0:
            print(f"      è­¦å‘Š: {col} å­˜åœ¨ {invalid_count} ä¸ªæ— ç©·å€¼ï¼Œå·²æ¸…ç†")
            combined[col] = combined[col].replace([np.inf, -np.inf], np.nan)
    
    # ç¬¬å››æ­¥ï¼šæ ‡å‡†åŒ–åå†æ¬¡æˆªå°¾ï¼ˆé™åˆ¶åœ¨ [-3, 3] æ ‡å‡†å·®èŒƒå›´å†…ï¼‰
    print(f"   æ ‡å‡†åŒ–åæˆªå°¾å¤„ç†ï¼ˆÂ±3Ïƒï¼‰...")
    clip_count = {}
    for col in factor_cols:
        original = combined[col].copy()
        combined[col] = combined[col].clip(-3, 3)
        clipped = (original != combined[col]).sum()
        clip_count[col] = clipped
        if clipped > 0:
            print(f"      {col}: æˆªå°¾ {clipped} ä¸ªå€¼")
    
    # ç¬¬äº”æ­¥ï¼šæœ€ç»ˆæ•°æ®è´¨é‡æ£€æŸ¥
    print(f"\n   æœ€ç»ˆæ•°æ®è´¨é‡æ£€æŸ¥:")
    for col in factor_cols:
        col_data = combined[col].dropna()
        if len(col_data) > 0:
            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å¼‚å¸¸å€¼
            extreme_count = (col_data.abs() > 3).sum()
            inf_count = np.isinf(col_data).sum()
            nan_ratio = combined[col].isna().mean()
            
            print(f"      {col}:")
            print(f"         |z|>3: {extreme_count} ä¸ª ({extreme_count/len(col_data)*100:.2f}%)")
            print(f"         æ— ç©·å€¼: {inf_count} ä¸ª")
            print(f"         ç¼ºå¤±ç‡: {nan_ratio*100:.2f}%")
            
            if extreme_count > 0 or inf_count > 0:
                print(f"         âš ï¸  è­¦å‘Š: ä»å­˜åœ¨å¼‚å¸¸å€¼ï¼")
    
    print(f"âœ… å®Œæˆæˆªé¢æ ‡å‡†åŒ–")
    
    print(f"\næ­¥éª¤ 4: åˆæˆç»¼åˆå› å­...")
    
    # åˆæˆæœ€ç»ˆå› å­ï¼ˆç­‰æƒå¹³å‡ï¼Œå¯æ ¹æ® IC æµ‹è¯•è°ƒæ•´æƒé‡ï¼‰
    # æ¨èæƒé‡ï¼šè¶‹åŠ¿å› å­æƒé‡æ›´é«˜
    weights = {
        'obv_slope': 0.30,        # è¶‹åŠ¿æ–œç‡
        'obv_change': 0.20,       # å˜åŒ–ç‡
        'obv_rank': 0.20,         # ç›¸å¯¹å¼ºåº¦
        'obv_divergence': 0.15,   # é‡ä»·èƒŒç¦»
        'obv_breakthrough': 0.15, # çªç ´å¼ºåº¦
    }
    
    # æ£€æŸ¥å­å› å­è´¨é‡
    print(f"   å­å› å­è´¨é‡æ£€æŸ¥:")
    for col, weight in weights.items():
        valid_count = combined[col].notna().sum()
        valid_ratio = valid_count / len(combined)
        print(f"      {col} (æƒé‡={weight}): æœ‰æ•ˆç‡ {valid_ratio*100:.2f}%")
    
    combined['factor'] = sum(combined[col] * weight for col, weight in weights.items())
    
    # å¤„ç†ç»¼åˆå› å­çš„ç¼ºå¤±å€¼
    # å¦‚æœæŸäº›å­å› å­ç¼ºå¤±ï¼Œç»¼åˆå› å­ä¹Ÿä¼šæ˜¯ NaNï¼Œè¿™æ˜¯åˆç†çš„
    factor_nan_count = combined['factor'].isna().sum()
    if factor_nan_count > 0:
        print(f"   ç»¼åˆå› å­ç¼ºå¤±å€¼: {factor_nan_count} ä¸ª ({factor_nan_count/len(combined)*100:.2f}%)")
    
    # å†æ¬¡æ ‡å‡†åŒ–ç»¼åˆå› å­
    print(f"   æ ‡å‡†åŒ–ç»¼åˆå› å­...")
    combined['factor'] = combined.groupby('trade_date')['factor'].transform(safe_standardize)
    
    # æ£€æŸ¥æ ‡å‡†åŒ–åçš„æ— ç©·å€¼
    factor_inf_after = combined['factor'].isin([np.inf, -np.inf]).sum()
    if factor_inf_after > 0:
        print(f"      æ¸…ç† {factor_inf_after} ä¸ªæ— ç©·å€¼")
        combined['factor'] = combined['factor'].replace([np.inf, -np.inf], np.nan)
    
    # ç»¼åˆå› å­æœ€ç»ˆå¼‚å¸¸å€¼å¤„ç†
    print(f"   ç»¼åˆå› å­å¼‚å¸¸å€¼å¤„ç†:")
    
    # ä½¿ç”¨ MAD æ–¹æ³•
    def final_winsorize(series):
        if series.isna().all() or len(series) < 10:
            return series
        median = series.median()
        mad = (series - median).abs().median()
        if mad > 0:
            lower = median - 5 * 1.4826 * mad
            upper = median + 5 * 1.4826 * mad
            return series.clip(lower, upper)
        return series
    
    combined['factor'] = combined.groupby('trade_date')['factor'].transform(final_winsorize)
    
    # æœ€ç»ˆæˆªå°¾
    original_factor = combined['factor'].copy()
    combined['factor'] = combined['factor'].clip(-3, 3)
    final_clip_count = (original_factor != combined['factor']).sum()
    print(f"      æœ€ç»ˆæˆªå°¾: {final_clip_count} ä¸ªå€¼")
    
    # ç»¼åˆå› å­ç»Ÿè®¡
    factor_data = combined['factor'].dropna()
    if len(factor_data) > 0:
        print(f"      å‡å€¼: {factor_data.mean():.4f}")
        print(f"      æ ‡å‡†å·®: {factor_data.std():.4f}")
        print(f"      ååº¦: {factor_data.skew():.4f}")
        print(f"      å³°åº¦: {factor_data.kurtosis():.4f}")
        print(f"      èŒƒå›´: [{factor_data.min():.4f}, {factor_data.max():.4f}]")
    
    print(f"âœ… ç»¼åˆå› å­åˆæˆå®Œæˆ")
    print(f"   å› å­æƒé‡: {weights}")
    
    # è®¾ç½® MultiIndex
    result = combined[['trade_date', 'ts_code', 'factor'] + factor_cols].set_index(['trade_date', 'ts_code'])
    
    # ç»Ÿè®¡ä¿¡æ¯
    print(f"\n{'='*60}")
    print(f"âœ… OBV å¢å¼ºç‰ˆå› å­è®¡ç®—å®Œæˆï¼")
    print(f"   æœ‰æ•ˆè®°å½•æ•°: {len(result):,}")
    print(f"   è¦†ç›–è‚¡ç¥¨æ•°: {result.index.get_level_values('ts_code').nunique()}")
    print(f"   è¦†ç›–äº¤æ˜“æ—¥æ•°: {result.index.get_level_values('trade_date').nunique()}")
    
    print(f"\nå› å­å€¼ç»Ÿè®¡ï¼ˆç»¼åˆå› å­ï¼‰:")
    factor_stats = result['factor'].describe()
    print(f"   æ•°é‡: {int(factor_stats['count']):,}")
    print(f"   å‡å€¼: {factor_stats['mean']:.4f}")
    print(f"   æ ‡å‡†å·®: {factor_stats['std']:.4f}")
    print(f"   æœ€å°å€¼: {factor_stats['min']:.4f}")
    print(f"   25%åˆ†ä½: {factor_stats['25%']:.4f}")
    print(f"   ä¸­ä½æ•°: {factor_stats['50%']:.4f}")
    print(f"   75%åˆ†ä½: {factor_stats['75%']:.4f}")
    print(f"   æœ€å¤§å€¼: {factor_stats['max']:.4f}")
    
    # æ£€æŸ¥æ•°æ®åˆ†å¸ƒå¥åº·åº¦
    print(f"\næ•°æ®è´¨é‡è¯„ä¼°:")
    skewness = result['factor'].skew()
    kurtosis = result['factor'].kurtosis()
    print(f"   ååº¦: {skewness:.4f} {'(æ­£å¸¸)' if abs(skewness) < 1 else '(åæ–œè¾ƒå¤§)'}")
    print(f"   å³°åº¦: {kurtosis:.4f} {'(æ­£å¸¸)' if abs(kurtosis) < 3 else '(å°–å³°æˆ–åšå°¾)'}")
    
    # ç¼ºå¤±å€¼ç»Ÿè®¡
    total_possible = len(result.index.get_level_values('trade_date').unique()) * len(result.index.get_level_values('ts_code').unique())
    missing_rate = (total_possible - len(result)) / total_possible
    print(f"   ç¼ºå¤±ç‡: {missing_rate*100:.2f}%")
    
    print(f"{'='*60}\n")
    
    return result


def run_obv_factor_backtest(start_date: str = '2024-01-01',
                          end_date: str = '2024-02-29',
                          stock_codes: Optional[List[str]] = None,
                          rebalance_freq: str = 'weekly',
                          transaction_cost: float = 0.0003,
                          long_direction: str = 'high',
                          use_advanced: bool = True,
                          trend_period: int = 20,
                          divergence_period: int = 20,
                          rank_period: int = 120,
                          # æ•°æ®è´¨é‡ç­›é€‰å‚æ•°
                          filter_st: bool = True,
                          filter_suspend: bool = True,
                          filter_limit: bool = True,
                          min_turnover_rate: float = 0.01,
                          min_price: float = 1.0) -> dict:
    """
    ä½¿ç”¨ BacktestEngine ä¸»è·¯å¾„è¿è¡Œ OBV å› å­ç­–ç•¥å›æµ‹ã€‚
    
    Parameters
    ----------
    start_date, end_date : str
        å›æµ‹å‘¨æœŸ
    stock_codes : Optional[List[str]]
        è‚¡ç¥¨æ± 
    rebalance_freq : str
        è°ƒä»“é¢‘ç‡: 'daily', 'weekly', 'monthly'
    transaction_cost : float
        å•è¾¹äº¤æ˜“è´¹ç”¨
    long_direction : str
        å¤šå¤´æ–¹å‘: 'high' åšå¤šé«˜å› å­å€¼ï¼ˆæ¨èï¼‰ï¼Œ'low' åšå¤šä½å› å­å€¼
    use_advanced : bool
        æ˜¯å¦ä½¿ç”¨å¢å¼ºç‰ˆå› å­ï¼ˆåŒ…å«è¶‹åŠ¿+èƒŒç¦»ï¼‰ï¼Œé»˜è®¤ True
    trend_period : int
        è¶‹åŠ¿è®¡ç®—å‘¨æœŸ
    divergence_period : int
        èƒŒç¦»è®¡ç®—å‘¨æœŸ
    rank_period : int
        ç›¸å¯¹å¼ºåº¦è®¡ç®—å‘¨æœŸ
    filter_st : bool
        æ˜¯å¦è¿‡æ»¤ ST è‚¡ç¥¨ï¼Œé»˜è®¤ True
    filter_suspend : bool
        æ˜¯å¦è¿‡æ»¤åœç‰Œæ•°æ®ï¼Œé»˜è®¤ True
    filter_limit : bool
        æ˜¯å¦è¿‡æ»¤æ¶¨è·Œåœæ•°æ®ï¼Œé»˜è®¤ True
    min_turnover_rate : float
        æœ€å°æ¢æ‰‹ç‡é˜ˆå€¼ï¼ˆ%ï¼‰ï¼Œé»˜è®¤ 0.01%
    min_price : float
        æœ€å°ä»·æ ¼é˜ˆå€¼ï¼ˆå…ƒï¼‰ï¼Œé»˜è®¤ 1.0 å…ƒ
    
    Returns
    -------
    dict
        åŒ…å«å› å­æ•°æ®ã€ç»„åˆæ”¶ç›Šã€ä¸šç»©æŒ‡æ ‡å’ŒICåˆ†æç»“æœ
    """
    # åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
    data_manager = DataManager()
    
    # ä½¿ç”¨ BacktestEngine ä¸»è·¯å¾„
    from backtest_engine.engine import BacktestEngine
    
    print("\n" + "=" * 60)
    factor_type = "OBV å¢å¼ºç‰ˆå› å­" if use_advanced else "åŸºç¡€ OBV å› å­"
    print(f"å¼€å§‹è®¡ç®— {factor_type}...")
    
    # === æ­¥éª¤ 1: è®¡ç®—å› å­ï¼ˆå¸¦å¼‚å¸¸å¤„ç†ï¼‰===
    try:
        if use_advanced:
            factor_data = calculate_obv_advanced_factor(
                data_manager=data_manager,
                start_date=start_date,
                end_date=end_date,
                stock_codes=stock_codes,
                trend_period=trend_period,
                divergence_period=divergence_period,
                rank_period=rank_period,
                filter_st=filter_st,
                filter_suspend=filter_suspend,
                filter_limit=filter_limit,
                min_turnover_rate=min_turnover_rate,
                min_price=min_price,
            )
        else:
            factor_data = calculate_obv_factor(
                data_manager=data_manager,
                start_date=start_date,
                end_date=end_date,
                stock_codes=stock_codes
            )
    except Exception as e:
        print(f"âŒ å› å­è®¡ç®—å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {
            'factor_data': None,
            'portfolio_returns': None,
            'positions': None,
            'performance_metrics': {},
            'analysis_results': {},
            'error': str(e)
        }
    
    # === æ­¥éª¤ 2: ç©ºå€¼æ£€æŸ¥ ===
    if factor_data is None:
        print("âŒ å› å­æ•°æ®ä¸º None")
        return {
            'factor_data': None,
            'portfolio_returns': None,
            'positions': None,
            'performance_metrics': {},
            'analysis_results': {},
            'error': 'factor_data is None'
        }
    
    if factor_data.empty:
        print("âŒ å› å­æ•°æ®ä¸ºç©º")
        return {
            'factor_data': factor_data,
            'portfolio_returns': None,
            'positions': None,
            'performance_metrics': {},
            'analysis_results': {},
            'error': 'factor_data is empty'
        }
    
    # æ£€æŸ¥å› å­åˆ—æ˜¯å¦å­˜åœ¨
    if 'factor' not in factor_data.columns:
        print("âŒ å› å­æ•°æ®ç¼ºå°‘ 'factor' åˆ—")
        return {
            'factor_data': factor_data,
            'portfolio_returns': None,
            'positions': None,
            'performance_metrics': {},
            'analysis_results': {},
            'error': 'Missing factor column'
        }
    
    # æ£€æŸ¥å› å­å€¼çš„æœ‰æ•ˆæ€§
    valid_factor_count = factor_data['factor'].notna().sum()
    total_factor_count = len(factor_data)
    
    if valid_factor_count == 0:
        print("âŒ æ‰€æœ‰å› å­å€¼éƒ½æ˜¯ NaN")
        return {
            'factor_data': factor_data,
            'portfolio_returns': None,
            'positions': None,
            'performance_metrics': {},
            'analysis_results': {},
            'error': 'All factor values are NaN'
        }
    
    if valid_factor_count < total_factor_count * 0.1:
        print(f"âš ï¸  è­¦å‘Š: æœ‰æ•ˆå› å­å€¼æ¯”ä¾‹è¿‡ä½ ({valid_factor_count/total_factor_count*100:.1f}%)")
    
    print(f"å› å­å€¼èŒƒå›´: [{factor_data['factor'].min():.4f}, {factor_data['factor'].max():.4f}]")
    
    # å›æµ‹å‰æ•°æ®è´¨é‡æ£€æŸ¥
    print(f"\nå›æµ‹å‰æ•°æ®è´¨é‡æ£€æŸ¥:")
    factor_inf_count = np.isinf(factor_data['factor']).sum()
    factor_nan_count = factor_data['factor'].isna().sum()
    print(f"   æ— ç©·å€¼æ•°é‡: {factor_inf_count}")
    print(f"   ç¼ºå¤±å€¼æ•°é‡: {factor_nan_count}")
    print(f"   æœ‰æ•ˆå€¼æ•°é‡: {valid_factor_count} ({valid_factor_count/total_factor_count*100:.1f}%)")
    
    if factor_inf_count > 0 or factor_nan_count > 0:
        print(f"   æ¸…ç†å¼‚å¸¸å€¼...")
        # ç§»é™¤æ— ç©·å€¼å’Œç¼ºå¤±å€¼
        factor_data = factor_data[~np.isinf(factor_data['factor'])].copy()
        factor_data = factor_data.dropna(subset=['factor'])
        print(f"   æ¸…ç†åè®°å½•æ•°: {len(factor_data)}")
        
        if len(factor_data) == 0:
            print("âŒ æ¸…ç†åæ— æœ‰æ•ˆæ•°æ®")
            return {
                'factor_data': None,
                'portfolio_returns': None,
                'positions': None,
                'performance_metrics': {},
                'analysis_results': {},
                'error': 'No valid data after cleaning'
            }
    
    print("=" * 60 + "\n")
    
    # åˆ›å»ºå›æµ‹å¼•æ“
    engine = BacktestEngine(
        data_manager=data_manager,
        fee=transaction_cost,
        long_direction=long_direction,
        rebalance_freq=rebalance_freq,
        factor_name='factor',
    )
    
    # ç›´æ¥è®¾ç½®å› å­æ•°æ®
    engine.factor_data = factor_data[['factor']]  # åªä½¿ç”¨ç»¼åˆå› å­åˆ—
    
    # === æ­¥éª¤ 3: å‡†å¤‡æ”¶ç›Šç‡æ•°æ®ï¼ˆå¸¦ç©ºå€¼ä¿æŠ¤ï¼‰===
    print("å‡†å¤‡æ”¶ç›Šç‡æ•°æ®...")
    
    stock_list = factor_data.index.get_level_values('ts_code').unique().tolist()
    
    if not stock_list:
        print("âŒ è‚¡ç¥¨åˆ—è¡¨ä¸ºç©º")
        return {
            'factor_data': factor_data,
            'portfolio_returns': None,
            'positions': None,
            'performance_metrics': {},
            'analysis_results': {},
            'error': 'Empty stock list'
        }
    
    print(f"   åŠ è½½ {len(stock_list)} åªè‚¡ç¥¨çš„æ•°æ®...")
    
    try:
        stock_data = data_manager.load_data(
            'daily',
            start_date=start_date,
            end_date=end_date,
            stock_codes=stock_list
        )
    except Exception as e:
        print(f"âŒ åŠ è½½è‚¡ç¥¨æ•°æ®å¤±è´¥: {e}")
        return {
            'factor_data': factor_data,
            'portfolio_returns': None,
            'positions': None,
            'performance_metrics': {},
            'analysis_results': {},
            'error': f'Failed to load stock data: {e}'
        }
    
    if stock_data is None:
        print("âŒ è‚¡ç¥¨æ•°æ®ä¸º None")
        return {
            'factor_data': factor_data,
            'portfolio_returns': None,
            'positions': None,
            'performance_metrics': {},
            'analysis_results': {},
            'error': 'stock_data is None'
        }
    
    if stock_data.empty:
        print("âŒ è‚¡ç¥¨æ•°æ®ä¸ºç©º")
        return {
            'factor_data': factor_data,
            'portfolio_returns': None,
            'positions': None,
            'performance_metrics': {},
            'analysis_results': {},
            'error': 'stock_data is empty'
        }
    
    print(f"   æˆåŠŸåŠ è½½ {len(stock_data)} æ¡è®°å½•")
    
    # è®¡ç®—æ¬¡æ—¥æ”¶ç›Šç‡ï¼ˆå¸¦ç©ºå€¼ä¿æŠ¤ï¼‰
    print("   è®¡ç®—æ”¶ç›Šç‡...")
    stock_data = stock_data.sort_values(['ts_code', 'trade_date'])
    
    # ç¡®ä¿ close åˆ—å­˜åœ¨ä¸”æœ‰æ•ˆ
    if 'close' not in stock_data.columns:
        print("âŒ è‚¡ç¥¨æ•°æ®ç¼ºå°‘ 'close' åˆ—")
        return {
            'factor_data': factor_data,
            'portfolio_returns': None,
            'positions': None,
            'performance_metrics': {},
            'analysis_results': {},
            'error': 'Missing close price column'
        }
    
    # æ£€æŸ¥ä»·æ ¼æœ‰æ•ˆæ€§
    valid_close_count = stock_data['close'].notna().sum()
    if valid_close_count == 0:
        print("âŒ æ‰€æœ‰æ”¶ç›˜ä»·éƒ½æ˜¯ NaN")
        return {
            'factor_data': factor_data,
            'portfolio_returns': None,
            'positions': None,
            'performance_metrics': {},
            'analysis_results': {},
            'error': 'All close prices are NaN'
        }
    
    # å®‰å…¨è®¡ç®—æ”¶ç›Šç‡
    try:
        stock_data['next_return'] = stock_data.groupby('ts_code')['close'].pct_change().shift(-1)
    except Exception as e:
        print(f"âŒ è®¡ç®—æ”¶ç›Šç‡å¤±è´¥: {e}")
        return {
            'factor_data': factor_data,
            'portfolio_returns': None,
            'positions': None,
            'performance_metrics': {},
            'analysis_results': {},
            'error': f'Failed to calculate returns: {e}'
        }
    
    # æ£€æŸ¥æ”¶ç›Šç‡æœ‰æ•ˆæ€§
    valid_return_count = stock_data['next_return'].notna().sum()
    print(f"   æœ‰æ•ˆæ”¶ç›Šç‡æ•°é‡: {valid_return_count} ({valid_return_count/len(stock_data)*100:.1f}%)")
    
    if valid_return_count == 0:
        print("âŒ æ‰€æœ‰æ”¶ç›Šç‡éƒ½æ˜¯ NaN")
        return {
            'factor_data': factor_data,
            'portfolio_returns': None,
            'positions': None,
            'performance_metrics': {},
            'analysis_results': {},
            'error': 'All returns are NaN'
        }
    
    # === æ­¥éª¤ 4: åˆå¹¶å› å­å’Œæ”¶ç›Šç‡ï¼ˆå¸¦ç©ºå€¼ä¿æŠ¤ï¼‰===
    print("   åˆå¹¶å› å­å’Œæ”¶ç›Šç‡æ•°æ®...")
    
    factor_reset = factor_data.reset_index()
    stock_subset = stock_data[['ts_code', 'trade_date', 'next_return']].copy()
    
    try:
        engine.combined_data = pd.merge(
            factor_reset[['trade_date', 'ts_code', 'factor']],
            stock_subset,
            on=['ts_code', 'trade_date'],
            how='inner'
        )
    except Exception as e:
        print(f"âŒ åˆå¹¶æ•°æ®å¤±è´¥: {e}")
        return {
            'factor_data': factor_data,
            'portfolio_returns': None,
            'positions': None,
            'performance_metrics': {},
            'analysis_results': {},
            'error': f'Failed to merge data: {e}'
        }
    
    print(f"   åˆå¹¶åè®°å½•æ•°: {len(engine.combined_data)}")
    
    if engine.combined_data.empty:
        print("âŒ åˆå¹¶åæ•°æ®ä¸ºç©ºï¼ˆå¯èƒ½æ˜¯æ—¥æœŸä¸åŒ¹é…ï¼‰")
        return {
            'factor_data': factor_data,
            'portfolio_returns': None,
            'positions': None,
            'performance_metrics': {},
            'analysis_results': {},
            'error': 'Empty data after merge'
        }
    
    # æ¸…ç†ç¼ºå¤±å€¼
    before_clean = len(engine.combined_data)
    engine.combined_data.dropna(subset=['factor', 'next_return'], inplace=True)
    after_clean = len(engine.combined_data)
    
    if before_clean > after_clean:
        print(f"   æ¸…ç†ç¼ºå¤±å€¼: {before_clean - after_clean} æ¡")
    
    if engine.combined_data.empty:
        print("âŒ æ¸…ç†ç¼ºå¤±å€¼åæ•°æ®ä¸ºç©º")
        return {
            'factor_data': factor_data,
            'portfolio_returns': None,
            'positions': None,
            'performance_metrics': {},
            'analysis_results': {},
            'error': 'Empty data after cleaning NaN'
        }
    
    print(f"   æœ€ç»ˆæœ‰æ•ˆè®°å½•: {len(engine.combined_data)}")
    
    # === æ­¥éª¤ 5: è¿è¡Œå›æµ‹ï¼ˆå¸¦å¼‚å¸¸å¤„ç†ï¼‰===
    print("\nå¼€å§‹å›æµ‹...")
    
    try:
        portfolio_returns = engine.run()
    except Exception as e:
        print(f"âŒ å›æµ‹è¿è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {
            'factor_data': factor_data,
            'portfolio_returns': None,
            'positions': None,
            'performance_metrics': {},
            'analysis_results': {},
            'error': f'Backtest execution failed: {e}'
        }
    
    print("å›æµ‹å®Œæˆï¼\n")
    
    # === æ­¥éª¤ 6: è®¡ç®—ä¸šç»©æŒ‡æ ‡ï¼ˆå¸¦ç©ºå€¼ä¿æŠ¤ï¼‰===
    if portfolio_returns is None:
        print("âŒ å›æµ‹ç»“æœä¸º None")
        return {
            'factor_data': factor_data,
            'portfolio_returns': None,
            'positions': None,
            'performance_metrics': {},
            'analysis_results': {},
            'error': 'portfolio_returns is None'
        }
    
    
    # è®¡ç®—åŸºæœ¬ä¸šç»©æŒ‡æ ‡ï¼ˆåŸºäº Long_Onlyï¼‰
    if not isinstance(portfolio_returns, pd.DataFrame):
        print("âŒ å›æµ‹ç»“æœä¸æ˜¯ DataFrame")
        return {
            'factor_data': factor_data,
            'portfolio_returns': portfolio_returns,
            'positions': None,
            'performance_metrics': {},
            'analysis_results': {},
            'error': 'portfolio_returns is not a DataFrame'
        }
    
    if 'Long_Only' not in portfolio_returns.columns:
        print(f"âŒ å›æµ‹ç»“æœç¼ºå°‘ 'Long_Only' åˆ—")
        print(f"   å¯ç”¨åˆ—: {portfolio_returns.columns.tolist()}")
        return {
            'factor_data': factor_data,
            'portfolio_returns': portfolio_returns,
            'positions': None,
            'performance_metrics': {},
            'analysis_results': {},
            'error': 'Missing Long_Only column'
        }
    
    series = portfolio_returns['Long_Only']
    
    # æ£€æŸ¥æ”¶ç›Šåºåˆ—æœ‰æ•ˆæ€§
    if series is None or len(series) == 0:
        print("âŒ Long_Only æ”¶ç›Šåºåˆ—ä¸ºç©º")
        return {
            'factor_data': factor_data,
            'portfolio_returns': portfolio_returns,
            'positions': None,
            'performance_metrics': {},
            'analysis_results': {},
            'error': 'Empty returns series'
        }
    
    valid_returns = series.notna().sum()
    if valid_returns == 0:
        print("âŒ æ‰€æœ‰æ”¶ç›Šç‡éƒ½æ˜¯ NaN")
        return {
            'factor_data': factor_data,
            'portfolio_returns': portfolio_returns,
            'positions': None,
            'performance_metrics': {},
            'analysis_results': {},
            'error': 'All returns are NaN'
        }
    
    print(f"æœ‰æ•ˆæ”¶ç›Šç‡æ•°é‡: {valid_returns}/{len(series)}")
    
    # å®‰å…¨è®¡ç®—ä¸šç»©æŒ‡æ ‡
    try:
        cum = (1 + series).cumprod()
        
        if len(cum) == 0 or cum.isna().all():
            raise ValueError("ç´¯ç§¯æ”¶ç›Šè®¡ç®—å¤±è´¥")
        
        total_return = float(cum.iloc[-1] - 1) if len(cum) > 0 else 0.0
        trading_days = len(series)
        
        if trading_days > 0:
            annualized_return = float(cum.iloc[-1] ** (252 / trading_days) - 1)
        else:
            annualized_return = 0.0
        
        volatility = float(series.std() * np.sqrt(252))
        
        if volatility > 0 and not np.isnan(annualized_return):
            sharpe_ratio = float(annualized_return / volatility)
        else:
            sharpe_ratio = 0.0
        
        running_max = cum.cummax()
        drawdown = cum / running_max - 1
        max_drawdown = float(drawdown.min()) if not drawdown.empty else 0.0
        
    except Exception as e:
        print(f"âš ï¸  ä¸šç»©æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}")
        total_return = 0.0
        annualized_return = 0.0
        volatility = 0.0
        sharpe_ratio = 0.0
        max_drawdown = 0.0
    
    # === æ­¥éª¤ 7: IC åˆ†æï¼ˆå¸¦å¼‚å¸¸å¤„ç†ï¼‰===
    try:
        analyzer = engine.get_performance_analysis()
        metrics_df = analyzer.calculate_metrics()
        ic_series = analyzer.ic_series
        
        analysis_results = {
            'metrics': metrics_df,
            'ic_series': ic_series
        }
    except Exception as e:
        print(f"âš ï¸  IC åˆ†æå¤±è´¥: {e}")
        analysis_results = {
            'metrics': None,
            'ic_series': None
        }
    
    return {
        'factor_data': factor_data,
        'portfolio_returns': portfolio_returns,
        'positions': None,
        'performance_metrics': {
            'total_return': total_return,
            'annualized_return': annualized_return,
            'volatility': volatility,
            'sharpe_ratio': sharpe_ratio,
            'max_drawdown': max_drawdown,
            'rebalance_count': len(engine._get_rebalance_dates()),
        },
        'analysis_results': analysis_results,
    }


def main():
    """ä¸»å‡½æ•°ï¼šæ¼”ç¤º OBV å¢å¼ºç‰ˆå› å­è®¡ç®—å’Œå›æµ‹"""
    print("=" * 60)
    print("OBV å¢å¼ºç‰ˆå› å­ç­–ç•¥æ¼”ç¤º")
    print("åŒ…å«: è¶‹åŠ¿æ–œç‡ + å˜åŒ–ç‡ + ç›¸å¯¹å¼ºåº¦ + é‡ä»·èƒŒç¦» + çªç ´å¼ºåº¦")
    print("æ–°å¢: æ•°æ®è´¨é‡ç­›é€‰ï¼ˆST/åœç‰Œ/æ¶¨è·Œåœ/ä½æµåŠ¨æ€§/ä½ä»·è‚¡ï¼‰")
    print("æ–°å¢: å¼‚å¸¸å€¼å¤„ç†ï¼ˆMADæ–¹æ³• + Winsorize + æˆªå°¾ï¼‰")
    print("=" * 60)

    try:
        # é…ç½®å‚æ•°
        config = {
            'start_date': '2015-01-01',
            'end_date': '2025-09-30',
            'rebalance_freq': 'weekly',
            'transaction_cost': 0.0003,  # 0.03% äº¤æ˜“è´¹ç”¨
            'long_direction': 'high',  # åšå¤šé«˜å› å­å€¼ï¼ˆèµ„é‡‘æµå…¥å¼ºï¼‰
            'use_advanced': True,  # ä½¿ç”¨å¢å¼ºç‰ˆå› å­
            'trend_period': 20,  # è¶‹åŠ¿è®¡ç®—å‘¨æœŸ
            'divergence_period': 20,  # èƒŒç¦»è®¡ç®—å‘¨æœŸ
            'rank_period': 120,  # ç›¸å¯¹å¼ºåº¦å‘¨æœŸ
            # æ•°æ®è´¨é‡ç­›é€‰å‚æ•°
            'filter_st': True,  # è¿‡æ»¤ ST è‚¡ç¥¨
            'filter_suspend': True,  # è¿‡æ»¤åœç‰Œæ•°æ®
            'filter_limit': True,  # è¿‡æ»¤æ¶¨è·Œåœæ•°æ®
            'min_turnover_rate': 0.01,  # æœ€å°æ¢æ‰‹ç‡ 0.01%
            'min_price': 1.0,  # æœ€å°ä»·æ ¼ 1 å…ƒ
        }

        print("\nå›æµ‹é…ç½®:")
        print(f"  æ—¶é—´èŒƒå›´: {config['start_date']} ~ {config['end_date']}")
        print(f"  è°ƒä»“é¢‘ç‡: {config['rebalance_freq']}")
        print(f"  äº¤æ˜“è´¹ç”¨: {config['transaction_cost']:.4f}")
        print(f"\nå› å­å‚æ•°:")
        print(f"  è¶‹åŠ¿å‘¨æœŸ: {config['trend_period']} å¤©")
        print(f"  èƒŒç¦»å‘¨æœŸ: {config['divergence_period']} å¤©")
        print(f"  ç›¸å¯¹å¼ºåº¦å‘¨æœŸ: {config['rank_period']} å¤©")
        print(f"\næ•°æ®è´¨é‡ç­›é€‰:")
        print(f"  è¿‡æ»¤ ST è‚¡ç¥¨: {config['filter_st']}")
        print(f"  è¿‡æ»¤åœç‰Œæ•°æ®: {config['filter_suspend']}")
        print(f"  è¿‡æ»¤æ¶¨è·Œåœ: {config['filter_limit']}")
        print(f"  æœ€å°æ¢æ‰‹ç‡: {config['min_turnover_rate']}%")
        print(f"  æœ€å°ä»·æ ¼: {config['min_price']} å…ƒ")

        # è¿è¡Œå›æµ‹
        results = run_obv_factor_backtest(**config)
        
        # æ£€æŸ¥å›æµ‹æ˜¯å¦æˆåŠŸ
        if 'error' in results and results['error']:
            print(f"\nâŒ å›æµ‹å¤±è´¥: {results['error']}")
            return
        
        if results['portfolio_returns'] is None:
            print(f"\nâŒ å›æµ‹æœªè¿”å›æœ‰æ•ˆç»“æœ")
            return

        # ç»“æœæ€»ç»“ï¼ˆåŸºäº Long_Onlyï¼‰
        print("\n" + "=" * 60)
        print("å›æµ‹ç»“æœæ€»ç»“ (Long_Only)")
        print("=" * 60)
        
        metrics = results['performance_metrics']
        
        # æ£€æŸ¥æŒ‡æ ‡æœ‰æ•ˆæ€§
        if not metrics:
            print("âš ï¸  æ— æ³•è·å–ä¸šç»©æŒ‡æ ‡")
            return
        
        print(f"\nğŸ“Š ä¸šç»©æŒ‡æ ‡:")
        print(f"  å¤æ™®æ¯”ç‡: {metrics.get('sharpe_ratio', 0):.3f}")
        print(f"  æ€»æ”¶ç›Š: {metrics.get('total_return', 0):.2%}")
        print(f"  å¹´åŒ–æ”¶ç›Š: {metrics.get('annualized_return', 0):.2%}")
        print(f"  å¹´åŒ–æ³¢åŠ¨: {metrics.get('volatility', 0):.2%}")
        print(f"  æœ€å¤§å›æ’¤: {metrics.get('max_drawdown', 0):.2%}")
        print(f"  è°ƒä»“æ¬¡æ•°: {metrics.get('rebalance_count', 0)}")

        # IC åˆ†æ
        analysis_results = results.get('analysis_results', {})
        if analysis_results and analysis_results.get('ic_series') is not None:
            ic = analysis_results['ic_series']
            if len(ic) > 0:
                print(f"\nğŸ“Š IC åˆ†æ:")
                print(f"  IC å‡å€¼: {ic.mean():.4f}")
                print(f"  IC æ ‡å‡†å·®: {ic.std():.4f}")
                if ic.std() > 0:
                    print(f"  ICIR: {ic.mean() / ic.std():.4f}")
                print(f"  IC>0 å æ¯”: {(ic > 0).mean():.2%}")
            else:
                print(f"\nâš ï¸  IC åºåˆ—ä¸ºç©º")
        else:
            print(f"\nâš ï¸  æ— æ³•è·å– IC åˆ†æç»“æœ")
        
        # å­å› å­è´¡çŒ®åˆ†æ
        if results['factor_data'] is not None and 'obv_slope' in results['factor_data'].columns:
            print(f"\nğŸ“Š å­å› å­ç»Ÿè®¡:")
            sub_factors = ['obv_slope', 'obv_change', 'obv_rank', 'obv_divergence', 'obv_breakthrough']
            for factor_name in sub_factors:
                if factor_name in results['factor_data'].columns:
                    factor_series = results['factor_data'][factor_name]
                    valid_count = factor_series.notna().sum()
                    
                    if valid_count > 0:
                        print(f"\n  {factor_name}:")
                        print(f"    æœ‰æ•ˆå€¼: {valid_count}")
                        print(f"    å‡å€¼: {factor_series.mean():.4f}")
                        print(f"    æ ‡å‡†å·®: {factor_series.std():.4f}")
                        print(f"    æœ€å°å€¼: {factor_series.min():.4f}")
                        print(f"    æœ€å¤§å€¼: {factor_series.max():.4f}")
                    else:
                        print(f"\n  {factor_name}: æ— æœ‰æ•ˆå€¼")
                else:
                    print(f"\n  {factor_name}: æœªæ‰¾åˆ°")
        else:
            print(f"\nâš ï¸  æ— æ³•è·å–å­å› å­æ•°æ®")
        
        print("\n" + "=" * 60)
        print("ğŸ’¡ ç­–ç•¥è¯´æ˜:")
        print("  â€¢ åšå¤šé«˜å› å­å€¼è‚¡ç¥¨ï¼ˆèµ„é‡‘æŒç»­æµå…¥ + é‡ä»·é…åˆï¼‰")
        print("  â€¢ OBV è¶‹åŠ¿å› å­æ•æ‰ä¸»åŠ›å»ºä»“ä¿¡å·")
        print("  â€¢ é‡ä»·èƒŒç¦»å› å­è¯†åˆ«ä»·é‡ä¸åŒ¹é…é£é™©")
        print("  â€¢ çªç ´å› å­ç¡®è®¤å¼ºåŠ¿è‚¡æŒç»­æ€§")
        print("  â€¢ æ•°æ®è´¨é‡ç­›é€‰ç¡®ä¿äº¤æ˜“å¯è¡Œæ€§")
        print("\nğŸ’¡ æ•°æ®å¤„ç†ç‰¹ç‚¹:")
        print("  â€¢ OBV è®¡ç®—ï¼šç™¾åˆ†æ¯”å˜åŒ– + æ–¹å‘å»¶ç»­ + å™ªéŸ³è¿‡æ»¤")
        print("  â€¢ æˆäº¤é‡å¤„ç†ï¼š")
        print("    - é›¶æˆäº¤é‡/åœç‰Œæ•°æ®è¿‡æ»¤")
        print("    - å¼‚å¸¸æ”¾é‡é™åˆ¶ï¼ˆ>å‡å€¼+10Ïƒ â†’ é™åˆ¶åˆ°+5Ïƒï¼‰")
        print("    - å¼‚å¸¸ç¼©é‡è¿‡æ»¤ï¼ˆ<å‡å€¼1%ï¼‰")
        print("    - é‡ä»·ä¸€è‡´æ€§éªŒè¯")
        print("    - å•æ—¥æç«¯OBVå˜åŒ–é™åˆ¶ï¼ˆ<50å€ä¸­ä½æ•°ï¼‰")
        print("  â€¢ å¼‚å¸¸å€¼å¤„ç†ï¼šMAD æ–¹æ³•ï¼ˆæ¯”æ ‡å‡†å·®æ›´ç¨³å¥ï¼‰")
        print("  â€¢ å¤šå±‚é˜²æŠ¤ï¼šWinsorize â†’ æ ‡å‡†åŒ– â†’ æˆªå°¾")
        print("  â€¢ è´¨é‡ç›‘æ§ï¼šååº¦/å³°åº¦/ç¼ºå¤±ç‡/æˆäº¤é‡ç¨³å®šæ€§")
        print("  â€¢ æ•°å€¼ç¨³å®šæ€§ï¼š")
        print("    - æ‰€æœ‰é™¤æ³•æ“ä½œæ·»åŠ æœ€å°å€¼ä¿æŠ¤ï¼ˆ1e-10ï¼‰")
        print("    - æ ‡å‡†åŒ–å‰æ£€æŸ¥æ ·æœ¬æ•°å’Œæ ‡å‡†å·®")
        print("    - è‡ªåŠ¨æ£€æµ‹å¹¶æ›¿æ¢æ— ç©·å€¼/NaN")
        print("    - ç™¾åˆ†æ¯”å˜åŒ–é™åˆ¶åœ¨åˆç†èŒƒå›´ï¼ˆÂ±1000%ï¼‰")
        print("=" * 60)

        print("\nâœ… OBV å¢å¼ºç‰ˆå› å­ç­–ç•¥æ¼”ç¤ºå®Œæˆ!")

    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise


if __name__ == "__main__":
    main()
