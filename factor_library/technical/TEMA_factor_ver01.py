"""
TEMA (Triple Exponential Moving Average) æŠ€æœ¯å› å­

æœ¬æ¨¡å—å®ç°äº†åŸºäºä¸‰é‡æŒ‡æ•°ç§»åŠ¨å¹³å‡çº¿çš„ç»¼åˆæŠ€æœ¯å› å­ï¼Œ
åŒ…æ‹¬å› å­è®¡ç®—ã€å›æµ‹åˆ†æã€é€‰è‚¡ä¿¡å·ç”Ÿæˆç­‰å®Œæ•´åŠŸèƒ½ã€‚

**ä¸»è¦åŠŸèƒ½**ï¼š
1. calculate_tema_factor(): è®¡ç®—TEMAç»¼åˆæŠ€æœ¯å› å­
2. run_tema_factor_backtest(): è¿è¡Œå› å­ç­–ç•¥å›æµ‹
3. generate_tema_signals(): ç”Ÿæˆå¤šçº§é€‰è‚¡ä¿¡å·
4. get_top_stocks(): è·å–Top Næ¨èè‚¡ç¥¨

**TEMAç®€ä»‹**ï¼š
ä¸‰é‡æŒ‡æ•°ç§»åŠ¨å¹³å‡çº¿(TEMA)æ˜¯ä¸€ç§é«˜çº§æŠ€æœ¯æŒ‡æ ‡ï¼Œç”±Patrick Mulloyäº1994å¹´å¼€å‘ã€‚
é€šè¿‡å¯¹ä»·æ ¼è¿›è¡Œä¸‰é‡æŒ‡æ•°å¹³æ»‘ï¼ŒTEMAèƒ½å¤Ÿæœ‰æ•ˆå‡å°‘æ»åæ€§ï¼ŒåŒæ—¶ä¿æŒå¹³æ»‘çš„è¶‹åŠ¿çº¿ã€‚

æ ¸å¿ƒç»„æˆéƒ¨åˆ†ï¼š
- EMA1ï¼šç¬¬ä¸€æ¬¡æŒ‡æ•°ç§»åŠ¨å¹³å‡
- EMA2ï¼šEMA1çš„æŒ‡æ•°ç§»åŠ¨å¹³å‡
- EMA3ï¼šEMA2çš„æŒ‡æ•°ç§»åŠ¨å¹³å‡
- TEMA = 3*EMA1 - 3*EMA2 + EMA3

**å› å­æ„å»ºé€»è¾‘**ï¼š
æœ¬å› å­æ•´åˆäº†å››ä¸ªç»´åº¦ï¼š
1. TEMAä¹–ç¦»ç‡ï¼ˆ40%ï¼‰ï¼šä»·æ ¼ç›¸å¯¹TEMAçš„åç¦»ç¨‹åº¦
2. TEMAæ–œç‡ï¼ˆ30%ï¼‰ï¼šTEMAçš„å˜åŒ–è¶‹åŠ¿å’Œæ–¹å‘
3. TEMAåŠ¨é‡ï¼ˆ20%ï¼‰ï¼šTEMAçš„å˜åŒ–é€Ÿåº¦
4. TEMAäº¤å‰ä¿¡å·ï¼ˆ10%ï¼‰ï¼šçŸ­æœŸTEMAä¸é•¿æœŸTEMAçš„äº¤å‰å…³ç³»

ç»¼åˆè¯„åˆ†åè¿›è¡Œæˆªé¢æ ‡å‡†åŒ–ï¼Œç”Ÿæˆz-scoreå½¢å¼çš„å› å­å€¼ã€‚

**ä½¿ç”¨ç¤ºä¾‹**ï¼š

åŸºç¡€ç”¨æ³•ï¼š
>>> from pathlib import Path
>>> import sys
>>> PROJECT_ROOT = Path(__file__).resolve().parents[2]
>>> sys.path.append(str(PROJECT_ROOT))
>>> from data_manager.data import DataManager
>>> 
>>> data_manager = DataManager()
>>> 
>>> # è®¡ç®—å› å­
>>> factor = calculate_tema_factor(
...     data_manager,
...     start_date='2023-01-01',
...     end_date='2023-12-31'
... )
>>> 
>>> # ç”Ÿæˆä¿¡å·
>>> signals = generate_tema_signals(factor)
>>> 
>>> # è·å–æ¨èè‚¡ç¥¨
>>> top_stocks = get_top_stocks(signals, date='2023-12-31', top_n=10)

å®Œæ•´å›æµ‹ï¼š
>>> results = run_tema_factor_backtest(
...     start_date='2023-01-01',
...     end_date='2023-12-31',
...     rebalance_freq='weekly'
... )
>>> print(results['performance_metrics'])

**å› å­ç‰¹ç‚¹**ï¼š
- ä¼˜åŠ¿ï¼š
  * å¤šç»´åº¦ç»¼åˆè¯„åˆ†ï¼Œå‡å°‘å•ä¸€æŒ‡æ ‡çš„å‡ä¿¡å·
  * å“åº”é€Ÿåº¦å¿«ï¼Œæ»åæ€§å°
  * é€‚åˆçŸ­ä¸­æœŸè¶‹åŠ¿è·Ÿè¸ªç­–ç•¥
  * å‚æ•°å¯è°ƒï¼Œé€‚åº”ä¸åŒå¸‚åœºç¯å¢ƒ

- å±€é™ï¼š
  * åœ¨éœ‡è¡å¸‚ä¸­å¯èƒ½é¢‘ç¹è°ƒæ•´
  * éœ€è¦è¶³å¤Ÿçš„å†å²æ•°æ®
  * å¯¹å™ªéŸ³è¾ƒä¸ºæ•æ„Ÿ

**æ•°æ®è¦æ±‚**ï¼š
- å¿…éœ€å­—æ®µï¼štrade_date, ts_code, close
- æœ€å°æ•°æ®é‡ï¼šå»ºè®®è‡³å°‘60ä¸ªäº¤æ˜“æ—¥
- æ•°æ®è´¨é‡ï¼šéœ€è¦æ¸…æ´—å¼‚å¸¸å€¼ï¼ˆæ”¶ç›˜ä»·â‰¤0ç­‰ï¼‰

**ç‰ˆæœ¬å†å²**ï¼š
- v1.0: åŸºç¡€TEMAå› å­å®ç°ï¼ˆé¢å‘å¯¹è±¡ï¼‰
- v2.0: é‡æ„ä¸ºå‡½æ•°å¼è®¾è®¡ï¼Œç»Ÿä¸€æ¥å£
- v2.1: æ·»åŠ DataManageré›†æˆ
- v2.2: æ·»åŠ è¯¦ç»†æ–‡æ¡£å’Œæ—¥å¿—ç³»ç»Ÿ

ä½œè€…ï¼šé‡åŒ–æŠ•èµ„å›¢é˜Ÿ
æ—¥æœŸï¼š2025-11-06
å‚è€ƒï¼šMulloy, Patrick (1994). "Smoothing Data with Faster Moving Averages"
"""

import pandas as pd
import numpy as np
from pathlib import Path
import sys
from typing import Union, Optional, List, Dict
import logging
import warnings
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)


def setup_logger(
    level: int = logging.INFO,
    log_file: Optional[str] = None,
    console: bool = True,
    file_mode: str = 'a'
) -> None:
    """
    é…ç½®æ—¥å¿—ç³»ç»Ÿ
    
    Parameters
    ----------
    level : int, default=logging.INFO
        æ—¥å¿—çº§åˆ«
    log_file : str, optional
        æ—¥å¿—æ–‡ä»¶è·¯å¾„
    console : bool, default=True
        æ˜¯å¦è¾“å‡ºåˆ°æ§åˆ¶å°
    file_mode : str, default='a'
        æ–‡ä»¶å†™å…¥æ¨¡å¼
    """
    logger.handlers.clear()
    logger.setLevel(level)
    
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    if console:
        console_handler = logging.StreamHandler()
        console_handler.setLevel(level)
        console_handler.setFormatter(formatter)
        logger.addHandler(console_handler)
    
    if log_file:
        file_handler = logging.FileHandler(log_file, mode=file_mode, encoding='utf-8')
        file_handler.setLevel(level)
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)


# é»˜è®¤åˆå§‹åŒ–æ—¥å¿—
setup_logger()

# è·¯å¾„é…ç½®
PROJECT_ROOT = Path(__file__).resolve().parents[2]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

from data_manager.data import DataManager


def get_index_components(
    data_manager: DataManager, 
    index_code: str = '000852.SH', 
    trade_date: Optional[str] = None
) -> List[str]:
    """
    è·å–æŒ‡å®šæŒ‡æ•°çš„æˆåˆ†è‚¡åˆ—è¡¨
    
    Parameters
    ----------
    data_manager : DataManager
        æ•°æ®ç®¡ç†å™¨å®ä¾‹
    index_code : str, default='000852.SH'
        æŒ‡æ•°ä»£ç 
        - '000852.SH': ä¸­è¯1000
        - '000300.SH': æ²ªæ·±300
        - '000905.SH': ä¸­è¯500
        - '000016.SH': ä¸Šè¯50
    trade_date : Optional[str], default=None
        æŒ‡å®šæ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD' æˆ– 'YYYYMMDD'
        å¦‚æœä¸ºNoneï¼Œä½¿ç”¨æœ€æ–°ä¸€æœŸæ•°æ®
    
    Returns
    -------
    List[str]
        æˆåˆ†è‚¡ä»£ç åˆ—è¡¨
    """
    from pathlib import Path
    import warnings
    
    # ç›´æ¥ä»raw_dataåŠ è½½æŒ‡æ•°æƒé‡æ•°æ®
    raw_data_path = Path(__file__).resolve().parent.parent.parent / 'data_manager' / 'raw_data' / 'index_weight_data.parquet'
    
    try:
        index_weights = pd.read_parquet(raw_data_path)
    except Exception as e:
        logger.warning(f"æ— æ³•åŠ è½½ index_weight æ•°æ®: {e}")
        warnings.warn(f"æ— æ³•åŠ è½½ index_weight æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œ data_manager/data_loader/index_weight_data_loader.py")
        return []
    
    if index_weights is None or index_weights.empty:
        logger.warning("index_weight æ•°æ®ä¸ºç©º")
        warnings.warn("index_weight æ•°æ®ä¸ºç©ºï¼Œè¯·å…ˆè¿è¡Œ data_manager/data_loader/index_weight_data_loader.py")
        return []
    
    # ç­›é€‰æŒ‡å®šæŒ‡æ•°
    index_data = index_weights[index_weights['index_code'] == index_code].copy()
    
    if index_data.empty:
        logger.warning(f"æœªæ‰¾åˆ°æŒ‡æ•° {index_code} çš„æƒé‡æ•°æ®")
        warnings.warn(f"æœªæ‰¾åˆ°æŒ‡æ•° {index_code} çš„æƒé‡æ•°æ®")
        return []
    
    # å¦‚æœæŒ‡å®šäº†æ—¥æœŸï¼Œç­›é€‰è¯¥æ—¥æœŸçš„æ•°æ®
    if trade_date is not None:
        if '-' in trade_date:
            trade_date = trade_date.replace('-', '')
        index_data = index_data[index_data['trade_date'] == trade_date]
        
        if index_data.empty:
            logger.warning(f"æ—¥æœŸ {trade_date} æ— æ•°æ®ï¼Œä½¿ç”¨æœ€æ–°ä¸€æœŸ")
            index_data = index_weights[index_weights['index_code'] == index_code].copy()
            latest_date = index_data['trade_date'].max()
            index_data = index_data[index_data['trade_date'] == latest_date]
    else:
        # ä½¿ç”¨æœ€æ–°ä¸€æœŸæ•°æ®
        latest_date = index_data['trade_date'].max()
        index_data = index_data[index_data['trade_date'] == latest_date]
    
    # æå–æˆåˆ†è‚¡ä»£ç 
    components = index_data['con_code'].unique().tolist()
    
    logger.info(f"è·å–æŒ‡æ•° {index_code} æˆåˆ†è‚¡: {len(components)} åª")
    print(f"âœ… è·å–æŒ‡æ•° {index_code} æˆåˆ†è‚¡:")
    print(f"   æ—¥æœŸ: {index_data['trade_date'].iloc[0] if not index_data.empty else 'N/A'}")
    print(f"   æˆåˆ†è‚¡æ•°é‡: {len(components)}")
    
    return components


def calculate_tema(series: pd.Series, n: int) -> pd.Series:
    """
    è®¡ç®—ä¸‰é‡æŒ‡æ•°ç§»åŠ¨å¹³å‡çº¿(TEMA)
    
    TEMA = 3*EMA1 - 3*EMA2 + EMA3
    å…¶ä¸­ï¼š
    - EMA1 = EMA(price, n)
    - EMA2 = EMA(EMA1, n)
    - EMA3 = EMA(EMA2, n)
    
    Parameters
    ----------
    series : pd.Series
        ä»·æ ¼åºåˆ—
    n : int
        å‘¨æœŸå‚æ•°
        
    Returns
    -------
    pd.Series
        TEMAå€¼åºåˆ—
    """
    try:
        e1 = series.ewm(span=n, adjust=False).mean()
        e2 = e1.ewm(span=n, adjust=False).mean()
        e3 = e2.ewm(span=n, adjust=False).mean()
        tema = 3 * e1 - 3 * e2 + e3
        return tema
    except Exception as e:
        logger.error(f"TEMAè®¡ç®—å¤±è´¥: {str(e)}")
        raise


def calculate_tema_factor(
    data_manager: DataManager,
    start_date: str,
    end_date: str,
    stock_codes: Optional[List[str]] = None,
    tema_period: int = 20,
    slope_period: int = 5,
    momentum_period: int = 10,
    short_n: int = 10,
    long_n: int = 20,
) -> pd.DataFrame:
    """
    è®¡ç®—åŸºäºTEMAçš„ç»¼åˆæŠ€æœ¯å› å­
    
    **å› å­é€»è¾‘**ï¼š
    TEMAå› å­æ•´åˆäº†ä»·æ ¼ç›¸å¯¹TEMAçš„ä¹–ç¦»ç‡ã€TEMAçš„æ–œç‡ã€TEMAçš„åŠ¨é‡ï¼Œ
    ä»¥åŠçŸ­æœŸ/é•¿æœŸTEMAçš„äº¤å‰ä¿¡å·ç­‰å¤šä¸ªç»´åº¦ï¼Œç”Ÿæˆä¸€ä¸ªç»¼åˆæŠ€æœ¯è¯„åˆ†ã€‚
    
    **å› å­è®¡ç®—å…¬å¼**ï¼š
    ç»¼åˆå› å­ = ä¹–ç¦»ç‡æ ‡å‡†åŒ– Ã— 0.4 + æ–œç‡æ ‡å‡†åŒ– Ã— 0.3 + 
               åŠ¨é‡æ ‡å‡†åŒ– Ã— 0.2 + äº¤å‰ä¿¡å· Ã— 0.1
    
    å…¶ä¸­ï¼š
    - ä¹–ç¦»ç‡ = (ä»·æ ¼ - TEMA) / TEMA Ã— 100
    - æ–œç‡ = (TEMA_t - TEMA_{t-n}) / n
    - åŠ¨é‡ = (TEMA_t - TEMA_{t-n}) / TEMA_{t-n} Ã— 100
    - äº¤å‰ä¿¡å· = 1 if çŸ­æœŸTEMA > é•¿æœŸTEMA else -1
    
    **å› å­æ–¹å‘**ï¼š
    - é«˜å› å­å€¼ â†’ æŠ€æœ¯é¢å¼ºåŠ¿ï¼Œé€‚åˆåšå¤š
    - ä½å› å­å€¼ â†’ æŠ€æœ¯é¢å¼±åŠ¿ï¼Œé¿å…æˆ–åšç©º
    
    **æ•°æ®è¦æ±‚**ï¼š
    - è‡³å°‘éœ€è¦max(tema_period, momentum_period, long_n)ä¸ªäº¤æ˜“æ—¥çš„å†å²æ•°æ®
    - å‡½æ•°è‡ªåŠ¨æ‰©å±•æ•°æ®ç¼“å†²æœŸä»¥ç¡®ä¿æ•°æ®å……è¶³
    
    Parameters
    ----------
    data_manager : DataManager
        æ•°æ®ç®¡ç†å™¨å®ä¾‹
    start_date : str
        å› å­è®¡ç®—å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD'
    end_date : str
        å› å­è®¡ç®—ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD'
    stock_codes : Optional[List[str]], default=None
        è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œå¦‚ä¸ºNoneåˆ™ä½¿ç”¨æ‰€æœ‰å¯ç”¨è‚¡ç¥¨
    tema_period : int, default=20
        TEMAè®¡ç®—å‘¨æœŸ
    slope_period : int, default=5
        æ–œç‡è®¡ç®—å‘¨æœŸ
    momentum_period : int, default=10
        åŠ¨é‡è®¡ç®—å‘¨æœŸ
    short_n : int, default=10
        çŸ­æœŸTEMAå‘¨æœŸ
    long_n : int, default=20
        é•¿æœŸTEMAå‘¨æœŸ
        
    Returns
    -------
    pd.DataFrame
        MultiIndex (trade_date, ts_code) with single column 'factor'
        - trade_date: äº¤æ˜“æ—¥æœŸï¼ˆdatetimeç±»å‹ï¼‰
        - ts_code: è‚¡ç¥¨ä»£ç 
        - factor: æ ‡å‡†åŒ–åçš„å› å­å€¼ï¼ˆz-scoreï¼‰
        
    Raises
    ------
    ValueError
        - æ— æ³•è·å–æ—¥è¡Œæƒ…æ•°æ®
        - æ•°æ®ç¼ºå°‘å¿…è¦åˆ—
        
    Examples
    --------
    >>> from data_manager.data import DataManager
    >>> data_manager = DataManager()
    >>> 
    >>> # è®¡ç®—æŒ‡å®šè‚¡ç¥¨çš„TEMAå› å­
    >>> factor = calculate_tema_factor(
    ...     data_manager=data_manager,
    ...     start_date='2023-01-01',
    ...     end_date='2023-12-31',
    ...     stock_codes=['000001.SZ', '600000.SH']
    ... )
    """
    # è‚¡ç¥¨æ± å¤„ç†
    if stock_codes is None:
        logger.warning("æœªæŒ‡å®šè‚¡ç¥¨æ± ï¼Œå°†ä½¿ç”¨æ‰€æœ‰å¯ç”¨è‚¡ç¥¨ï¼ˆå¯èƒ½å¯¼è‡´è®¡ç®—ç¼“æ…¢ï¼‰")
        print("âš ï¸ æœªæŒ‡å®šè‚¡ç¥¨æ± ï¼Œå°†ä½¿ç”¨æ‰€æœ‰å¯ç”¨è‚¡ç¥¨...")
        all_daily = data_manager.load_data('daily', start_date=start_date, end_date=end_date)
        if all_daily is None or all_daily.empty:
            raise ValueError("æ— æ³•è·å–æ—¥è¡Œæƒ…æ•°æ®ä»¥ç¡®å®šè‚¡ç¥¨æ± ")
        stock_codes = all_daily['ts_code'].unique().tolist()
        logger.info(f"è‡ªåŠ¨ç¡®å®šè‚¡ç¥¨æ± : {len(stock_codes)} åªè‚¡ç¥¨")
    else:
        logger.info(f"ä½¿ç”¨æŒ‡å®šè‚¡ç¥¨æ± : {len(stock_codes)} åªè‚¡ç¥¨")
    
    # æ·»åŠ æ•°æ®ç¼“å†²æœŸå¤„ç†
    buffer_days = max(tema_period, momentum_period, long_n) * 3
    
    try:
        start_date_extended = (pd.to_datetime(start_date) - pd.Timedelta(days=buffer_days)).strftime('%Y-%m-%d')
    except Exception as e:
        logger.error(f"æ—¥æœŸè§£æå¤±è´¥: {e}")
        raise
    
    logger.info(f"{'='*60}")
    logger.info(f"è®¡ç®— TEMA ç»¼åˆæŠ€æœ¯å› å­")
    logger.info(f"{'='*60}")
    logger.info(f"ç›®æ ‡æ—¥æœŸèŒƒå›´: {start_date} ~ {end_date}")
    logger.info(f"æ•°æ®åŠ è½½èŒƒå›´: {start_date_extended} ~ {end_date} (å«ç¼“å†²æœŸ)")
    logger.info(f"è‚¡ç¥¨æ± : {len(stock_codes)} åªè‚¡ç¥¨")
    
    print(f"\n{'='*60}")
    print(f"è®¡ç®— TEMA ç»¼åˆæŠ€æœ¯å› å­")
    print(f"{'='*60}")
    print(f"ç›®æ ‡æ—¥æœŸèŒƒå›´: {start_date} ~ {end_date}")
    print(f"æ•°æ®åŠ è½½èŒƒå›´: {start_date_extended} ~ {end_date} (å«ç¼“å†²æœŸ)")
    print(f"è‚¡ç¥¨æ± : {len(stock_codes)} åªè‚¡ç¥¨")
    
    # åŠ è½½æ—¥çº¿æ•°æ®
    logger.info("å¼€å§‹åŠ è½½æ—¥çº¿æ•°æ®...")
    print(f"\nåŠ è½½æ—¥çº¿æ•°æ®...")
    
    try:
        daily = data_manager.load_data(
            'daily',
            start_date=start_date_extended,
            end_date=end_date,
            stock_codes=stock_codes
        )
    except Exception as e:
        logger.error(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
        raise
    
    if daily is None or daily.empty:
        logger.error("æ— æ³•è·å–æ—¥è¡Œæƒ…æ•°æ®")
        raise ValueError("æ— æ³•è·å–æ—¥è¡Œæƒ…æ•°æ®")
    
    # æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†
    logger.info("å¼€å§‹æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†...")
    daily = daily.copy()
    
    # è½¬æ¢æ—¥æœŸæ ¼å¼
    logger.debug("è½¬æ¢æ—¥æœŸæ ¼å¼...")
    print(f"è½¬æ¢æ—¥æœŸæ ¼å¼...")
    try:
        daily['trade_date'] = pd.to_datetime(daily['trade_date'])
        daily = daily.sort_values(['ts_code', 'trade_date']).reset_index(drop=True)
    except Exception as e:
        logger.error(f"æ—¥æœŸè½¬æ¢å¤±è´¥: {e}")
        raise
    
    # æ£€æŸ¥å¿…è¦å­—æ®µ
    logger.debug("æ£€æŸ¥å¿…è¦å­—æ®µ...")
    required_cols = ['close', 'ts_code', 'trade_date']
    missing_cols = [col for col in required_cols if col not in daily.columns]
    if missing_cols:
        logger.error(f"æ•°æ®ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
        raise ValueError(f"æ•°æ®ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
    
    # åˆ é™¤ç¼ºå¤±å€¼
    daily = daily.dropna(subset=['trade_date', 'close'])
    logger.debug(f"åˆ é™¤ç¼ºå¤±å€¼åè®°å½•æ•°: {len(daily)}")
    
    # æ•°æ®è´¨é‡æ£€æŸ¥å’Œå¼‚å¸¸å€¼å¤„ç†
    logger.info("å¼€å§‹æ•°æ®è´¨é‡æ£€æŸ¥...")
    print(f"æ•°æ®è´¨é‡æ£€æŸ¥...")
    original_count = len(daily)
    
    # è¿‡æ»¤å¼‚å¸¸å€¼
    daily = daily[daily['close'] > 0]
    
    filtered_count = len(daily)
    if filtered_count < original_count:
        logger.warning(f"è¿‡æ»¤å¼‚å¸¸å€¼: {original_count - filtered_count} æ¡")
        print(f"âš ï¸ è¿‡æ»¤å¼‚å¸¸å€¼: {original_count - filtered_count} æ¡")
    else:
        logger.info("æœªå‘ç°å¼‚å¸¸å€¼")
        print(f"âœ… æœªå‘ç°å¼‚å¸¸å€¼")
    
    if daily.empty:
        logger.error("è¿‡æ»¤åæ•°æ®ä¸ºç©º")
        raise ValueError("è¿‡æ»¤åæ•°æ®ä¸ºç©º")
    
    n_stocks = daily['ts_code'].nunique()
    avg_records = len(daily) / n_stocks if n_stocks > 0 else 0
    logger.info(f"æ•°æ®åŠ è½½å®Œæˆ: æ—¶é—´èŒƒå›´ {daily['trade_date'].min()} ~ {daily['trade_date'].max()}, "
                f"{n_stocks} åªè‚¡ç¥¨, {len(daily):,} æ¡è®°å½•, å¹³å‡æ¯åª {avg_records:.0f} æ¡")
    
    print(f"\næ•°æ®åŠ è½½å®Œæˆ:")
    print(f"  æ—¶é—´èŒƒå›´: {daily['trade_date'].min()} ~ {daily['trade_date'].max()}")
    print(f"  è‚¡ç¥¨æ•°é‡: {n_stocks}")
    print(f"  æ•°æ®è®°å½•: {len(daily):,} æ¡")
    print(f"  å¹³å‡æ¯åªè‚¡ç¥¨: {avg_records:.0f} æ¡")
    
    # æŒ‰è‚¡ç¥¨åˆ†ç»„è®¡ç®—TEMAå› å­
    logger.info("å¼€å§‹è®¡ç®— TEMA æŒ‡æ ‡...")
    print(f"\nå¼€å§‹è®¡ç®— TEMA æŒ‡æ ‡...")
    factor_results = []
    failed_stocks = []
    insufficient_data_stocks = []
    
    total_stocks = daily['ts_code'].nunique()
    logger.info(f"å¾…å¤„ç†è‚¡ç¥¨æ€»æ•°: {total_stocks}")
    
    for idx, code in enumerate(daily['ts_code'].unique(), 1):
        try:
            stock_data = daily[daily['ts_code'] == code].copy()
            
            # æ£€æŸ¥æ•°æ®é‡æ˜¯å¦å……è¶³
            min_required = max(tema_period, momentum_period, long_n) + 10
            if len(stock_data) < min_required:
                insufficient_data_stocks.append(code)
                logger.debug(f"[{idx}/{total_stocks}] {code} - æ•°æ®ä¸è¶³ ({len(stock_data)} < {min_required})")
                continue
            
            # è®¡ç®—TEMAä¹–ç¦»ç‡å› å­
            tema_values = calculate_tema(stock_data['close'], tema_period)
            deviation = (stock_data['close'] - tema_values) / tema_values * 100
            
            # è®¡ç®—TEMAæ–œç‡å› å­
            slope = (tema_values - tema_values.shift(slope_period)) / slope_period
            
            # è®¡ç®—TEMAåŠ¨é‡å› å­
            momentum = (tema_values - tema_values.shift(momentum_period)) / tema_values.shift(momentum_period) * 100
            
            # è®¡ç®—TEMAäº¤å‰ä¿¡å·å› å­
            short_tema = calculate_tema(stock_data['close'], short_n)
            long_tema = calculate_tema(stock_data['close'], long_n)
            cross_signal = np.where(short_tema > long_tema, 1, -1)
            
            # æ„å»ºä¸´æ—¶DataFrameç”¨äºæ ‡å‡†åŒ–
            temp_df = pd.DataFrame({
                'deviation': deviation.values,
                'slope': slope.values,
                'momentum': momentum.values,
                'cross_signal': cross_signal
            }, index=stock_data.index)
            
            # å¯¹æ¯ä¸ªå­å› å­è¿›è¡Œæ ‡å‡†åŒ–ï¼ˆä»…é’ˆå¯¹è¯¥è‚¡ç¥¨ï¼‰
            for col in ['deviation', 'slope', 'momentum']:
                col_mean = temp_df[col].mean()
                col_std = temp_df[col].std()
                if col_std > 0:
                    temp_df[col] = (temp_df[col] - col_mean) / col_std
                else:
                    temp_df[col] = 0
            
            # ç»¼åˆå› å­ = åŠ æƒå¹³å‡
            factor = (
                temp_df['deviation'] * 0.4 +
                temp_df['slope'] * 0.3 +
                temp_df['momentum'] * 0.2 +
                temp_df['cross_signal'] * 0.1
            )
            
            # ä¿å­˜ç»“æœ
            result_df = pd.DataFrame({
                'trade_date': stock_data['trade_date'].values,
                'ts_code': code,
                'factor': factor.values
            })
            
            factor_results.append(result_df)
            
            if idx % 50 == 0 or idx == total_stocks:
                logger.info(f"è¿›åº¦: {idx}/{total_stocks} ({idx/total_stocks*100:.1f}%)")
                print(f"è¿›åº¦: {idx}/{total_stocks} ({idx/total_stocks*100:.1f}%)")
                
        except Exception as e:
            failed_stocks.append(code)
            logger.error(f"[{idx}/{total_stocks}] {code} - è®¡ç®—å¤±è´¥: {str(e)}")
            continue
    
    # ç»Ÿè®¡è®¡ç®—ç»“æœ
    logger.info(f"è®¡ç®—å®Œæˆ - æˆåŠŸ: {len(factor_results)}, æ•°æ®ä¸è¶³: {len(insufficient_data_stocks)}, å¤±è´¥: {len(failed_stocks)}")
    print(f"\nè®¡ç®—ç»Ÿè®¡:")
    print(f"  æˆåŠŸ: {len(factor_results)} åª")
    print(f"  æ•°æ®ä¸è¶³: {len(insufficient_data_stocks)} åª")
    print(f"  è®¡ç®—å¤±è´¥: {len(failed_stocks)} åª")
    
    if insufficient_data_stocks and len(insufficient_data_stocks) <= 10:
        logger.debug(f"æ•°æ®ä¸è¶³çš„è‚¡ç¥¨: {insufficient_data_stocks}")
        print(f"  æ•°æ®ä¸è¶³è‚¡ç¥¨: {insufficient_data_stocks[:5]}..." if len(insufficient_data_stocks) > 5 else insufficient_data_stocks)
    
    if failed_stocks:
        logger.warning(f"è®¡ç®—å¤±è´¥çš„è‚¡ç¥¨: {failed_stocks}")
        print(f"  âš ï¸ è®¡ç®—å¤±è´¥è‚¡ç¥¨: {failed_stocks[:5]}..." if len(failed_stocks) > 5 else failed_stocks)
    
    if not factor_results:
        logger.error("æ²¡æœ‰æˆåŠŸè®¡ç®—ä»»ä½•è‚¡ç¥¨çš„å› å­å€¼")
        raise ValueError("æ²¡æœ‰æˆåŠŸè®¡ç®—ä»»ä½•è‚¡ç¥¨çš„å› å­å€¼ï¼Œè¯·æ£€æŸ¥æ•°æ®è´¨é‡æˆ–å‚æ•°è®¾ç½®")
    
    # åˆå¹¶ç»“æœ
    print(f"\nåˆå¹¶å› å­æ•°æ®...")
    try:
        factor_df = pd.concat(factor_results, ignore_index=True)
    except Exception as e:
        logger.error(f"åˆå¹¶æ•°æ®å¤±è´¥: {e}")
        raise
    
    factor_df = factor_df.dropna(subset=['factor'])
    
    if factor_df.empty:
        logger.error("åˆå¹¶åå› å­æ•°æ®ä¸ºç©º")
        raise ValueError("åˆå¹¶åå› å­æ•°æ®ä¸ºç©º")
    
    print(f"\nå› å­è®¡ç®—å®Œæˆ:")
    print(f"  æœ‰æ•ˆè‚¡ç¥¨æ•°: {factor_df['ts_code'].nunique()}")
    print(f"  æœ‰æ•ˆè®°å½•æ•°: {len(factor_df):,} æ¡")
    print(f"  ç¼ºå¤±å€¼æ•°é‡: {factor_df['factor'].isna().sum()}")
    
    # æˆªé¢æ ‡å‡†åŒ–å¤„ç†
    print(f"è¿›è¡Œæˆªé¢æ ‡å‡†åŒ–å¤„ç†...")
    logger.info("è¿›è¡Œæˆªé¢æ ‡å‡†åŒ–å¤„ç†...")
    
    try:
        def standardize_factor(group):
            """æˆªé¢æ ‡å‡†åŒ–ï¼šæ¯æ—¥å› å­å€¼è½¬ä¸ºz-score"""
            mean = group.mean()
            std = group.std()
            if std > 0:
                return (group - mean) / std
            else:
                return group - mean
        
        factor_df['factor'] = factor_df.groupby('trade_date')['factor'].transform(standardize_factor)
        logger.info("æˆªé¢æ ‡å‡†åŒ–å®Œæˆ")
        print(f"âœ… æˆªé¢æ ‡å‡†åŒ–å®Œæˆ")
            
    except Exception as e:
        logger.error(f"æ ‡å‡†åŒ–å¤±è´¥: {e}")
        raise
    
    # è¿‡æ»¤åˆ°ç›®æ ‡æ—¥æœŸèŒƒå›´
    try:
        factor_df = factor_df[
            (factor_df['trade_date'] >= pd.to_datetime(start_date)) &
            (factor_df['trade_date'] <= pd.to_datetime(end_date))
        ]
    except Exception as e:
        logger.error(f"æ—¥æœŸè¿‡æ»¤å¤±è´¥: {e}")
        raise
    
    if factor_df.empty:
        logger.error("è¿‡æ»¤åˆ°ç›®æ ‡æ—¥æœŸèŒƒå›´åæ•°æ®ä¸ºç©º")
        raise ValueError("è¿‡æ»¤åˆ°ç›®æ ‡æ—¥æœŸèŒƒå›´åæ•°æ®ä¸ºç©º")
    
    # è®¾ç½®å¤šé‡ç´¢å¼•
    try:
        result = factor_df.set_index(['trade_date', 'ts_code'])
    except Exception as e:
        logger.error(f"è®¾ç½®ç´¢å¼•å¤±è´¥: {e}")
        raise
    
    print(f"\nâœ… TEMA å› å­è®¡ç®—å®Œæˆï¼")
    print(f"  æœ€ç»ˆè®°å½•æ•°: {len(result):,} æ¡")
    print(f"  è¦†ç›–è‚¡ç¥¨æ•°: {result.index.get_level_values('ts_code').nunique()}")
    print(f"  è¦†ç›–äº¤æ˜“æ—¥: {result.index.get_level_values('trade_date').nunique()}")
    
    # å› å­ç»Ÿè®¡
    factor_values = result['factor']
    print(f"\nå› å­ç»Ÿè®¡:")
    print(f"  å‡å€¼: {factor_values.mean():.4f} (åº”æ¥è¿‘0)")
    print(f"  æ ‡å‡†å·®: {factor_values.std():.4f} (åº”æ¥è¿‘1)")
    print(f"  æœ€å°å€¼: {factor_values.min():.4f}")
    print(f"  æœ€å¤§å€¼: {factor_values.max():.4f}")
    print(f"  ä¸­ä½æ•°: {factor_values.median():.4f}")
    
    # å¼‚å¸¸å€¼æ£€æµ‹
    extreme_values = ((factor_values < -5) | (factor_values > 5)).sum()
    if extreme_values > 0:
        logger.warning(f"å‘ç° {extreme_values} ä¸ªæç«¯å€¼ (|z-score| > 5)")
        print(f"  âš ï¸ æç«¯å€¼: {extreme_values} ä¸ª (|z-score| > 5)")
    
    print(f"{'='*60}\n")
    
    return result


def generate_tema_signals(
    factor_data: pd.DataFrame,
    strong_buy_threshold: float = 1.0,
    buy_threshold: float = 0.5,
    sell_threshold: float = -0.5,
    strong_sell_threshold: float = -1.0
) -> pd.DataFrame:
    """
    åŸºäºTEMAå› å­ç”Ÿæˆå¤šçº§é€‰è‚¡ä¿¡å·
    
    **ä¿¡å·é€»è¾‘**ï¼š
    æ ¹æ®æ ‡å‡†åŒ–åçš„å› å­å€¼ï¼ˆz-scoreï¼‰ï¼Œå°†è‚¡ç¥¨åˆ’åˆ†ä¸º5ä¸ªç­‰çº§ï¼š
    - å¼ºçƒˆä¹°å…¥ï¼ˆ2ï¼‰ï¼šå› å­å€¼ â‰¥ 1.0Ïƒï¼ˆå‰16%ï¼‰
    - ä¹°å…¥ï¼ˆ1ï¼‰ï¼š0.5Ïƒ â‰¤ å› å­å€¼ < 1.0Ïƒï¼ˆ16%-31%ï¼‰
    - ä¸­æ€§ï¼ˆ0ï¼‰ï¼š-0.5Ïƒ < å› å­å€¼ < 0.5Ïƒï¼ˆä¸­é—´38%ï¼‰
    - å–å‡ºï¼ˆ-1ï¼‰ï¼š-1.0Ïƒ < å› å­å€¼ â‰¤ -0.5Ïƒï¼ˆ31%-16%ï¼‰
    - å¼ºçƒˆå–å‡ºï¼ˆ-2ï¼‰ï¼šå› å­å€¼ â‰¤ -1.0Ïƒï¼ˆå16%ï¼‰
    
    Parameters
    ----------
    factor_data : pd.DataFrame
        TEMAå› å­æ•°æ®ï¼ŒMultiIndex (trade_date, ts_code)
    strong_buy_threshold : float, default=1.0
        å¼ºçƒˆä¹°å…¥ä¿¡å·é˜ˆå€¼
    buy_threshold : float, default=0.5
        ä¹°å…¥ä¿¡å·é˜ˆå€¼
    sell_threshold : float, default=-0.5
        å–å‡ºä¿¡å·é˜ˆå€¼
    strong_sell_threshold : float, default=-1.0
        å¼ºçƒˆå–å‡ºä¿¡å·é˜ˆå€¼
        
    Returns
    -------
    pd.DataFrame
        åŒ…å«ä¿¡å·çš„DataFrameï¼Œåˆ—åŒ…æ‹¬ï¼š
        - factor: åŸå§‹å› å­å€¼
        - signal: æ•°å€¼ä¿¡å·ï¼ˆ-2 åˆ° 2ï¼‰
        - signal_label: ä¸­æ–‡ä¿¡å·æ ‡ç­¾
    """
    logger.info(f"å¼€å§‹ç”Ÿæˆ TEMA ä¿¡å· - é˜ˆå€¼: å¼ºä¹°={strong_buy_threshold}, ä¹°={buy_threshold}, å–={sell_threshold}, å¼ºå–={strong_sell_threshold}")
    
    if not isinstance(factor_data, pd.DataFrame):
        raise TypeError("factor_data å¿…é¡»æ˜¯ DataFrame ç±»å‹")
    
    if factor_data.empty:
        logger.warning("è¾“å…¥å› å­æ•°æ®ä¸ºç©º")
        return pd.DataFrame()
    
    # å¤åˆ¶æ•°æ®
    signals = factor_data.copy()
    
    if 'factor' not in signals.columns:
        raise ValueError("factor_data å¿…é¡»åŒ…å« 'factor' åˆ—")
    
    # ç”Ÿæˆæ•°å€¼ä¿¡å·
    def categorize_signal(factor_value):
        if pd.isna(factor_value):
            return 0
        elif factor_value >= strong_buy_threshold:
            return 2
        elif factor_value >= buy_threshold:
            return 1
        elif factor_value <= strong_sell_threshold:
            return -2
        elif factor_value <= sell_threshold:
            return -1
        else:
            return 0
    
    try:
        signals['signal'] = signals['factor'].apply(categorize_signal)
    except Exception as e:
        logger.error(f"ä¿¡å·åˆ†ç±»å¤±è´¥: {e}")
        raise
    
    # ç”Ÿæˆä¿¡å·æ ‡ç­¾
    signal_labels = {
        2: 'å¼ºçƒˆä¹°å…¥',
        1: 'ä¹°å…¥',
        0: 'ä¸­æ€§',
        -1: 'å–å‡º',
        -2: 'å¼ºçƒˆå–å‡º'
    }
    signals['signal_label'] = signals['signal'].map(signal_labels)
    
    # ç»Ÿè®¡ä¿¡å·åˆ†å¸ƒ
    signal_counts = signals['signal'].value_counts().sort_index()
    logger.info(f"ä¿¡å·åˆ†å¸ƒ: {signal_counts.to_dict()}")
    print(f"\nä¿¡å·åˆ†å¸ƒ:")
    for sig, label in signal_labels.items():
        count = signal_counts.get(sig, 0)
        pct = count / len(signals) * 100 if len(signals) > 0 else 0
        print(f"  {label}({sig}): {count} ({pct:.1f}%)")
    
    return signals


def get_top_stocks(
    signals: pd.DataFrame,
    date: str,
    top_n: int = 10,
    signal_filter: int = 1
) -> pd.DataFrame:
    """
    è·å–æŒ‡å®šæ—¥æœŸçš„Top Næ¨èè‚¡ç¥¨
    
    Parameters
    ----------
    signals : pd.DataFrame
        ä¿¡å·æ•°æ®ï¼ŒMultiIndex (trade_date, ts_code)
    date : str
        æŸ¥è¯¢æ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD'
    top_n : int, default=10
        è¿”å›çš„è‚¡ç¥¨æ•°é‡
    signal_filter : int, default=1
        ä¿¡å·ç­›é€‰é˜ˆå€¼ï¼Œåªè¿”å›ä¿¡å· >= signal_filter çš„è‚¡ç¥¨
        
    Returns
    -------
    pd.DataFrame
        Top Nè‚¡ç¥¨åˆ—è¡¨ï¼ŒæŒ‰å› å­å€¼é™åºæ’åˆ—
    """
    try:
        date_dt = pd.to_datetime(date)
        
        # æå–æŒ‡å®šæ—¥æœŸçš„æ•°æ®
        if isinstance(signals.index, pd.MultiIndex):
            date_signals = signals.xs(date_dt, level='trade_date')
        else:
            date_signals = signals[signals.index == date_dt]
        
        if date_signals.empty:
            logger.warning(f"æ—¥æœŸ {date} æ— æ•°æ®")
            print(f"âš ï¸ æ—¥æœŸ {date} æ— æ•°æ®")
            return pd.DataFrame()
        
        # ç­›é€‰ä¿¡å·
        filtered = date_signals[date_signals['signal'] >= signal_filter]
        
        # æŒ‰å› å­å€¼æ’åº
        top_stocks = filtered.nlargest(top_n, 'factor')
        
        logger.info(f"æ—¥æœŸ {date} æ¨è {len(top_stocks)} åªè‚¡ç¥¨")
        print(f"\nğŸ“Š {date} Top {len(top_stocks)} æ¨èè‚¡ç¥¨:")
        print(top_stocks[['factor', 'signal', 'signal_label']])
        
        return top_stocks
        
    except Exception as e:
        logger.error(f"è·å–Topè‚¡ç¥¨å¤±è´¥: {e}")
        raise


def run_tema_factor_backtest(
    start_date: str = '2023-01-01',
    end_date: str = '2023-12-31',
    stock_codes: Optional[List[str]] = None,
    tema_period: int = 20,
    slope_period: int = 5,
    momentum_period: int = 10,
    short_n: int = 10,
    long_n: int = 20,
    rebalance_freq: str = 'weekly',
    transaction_cost: float = 0.0003,
) -> dict:
    """
    è¿è¡ŒTEMAå› å­å›æµ‹
    
    **ç­–ç•¥è¯´æ˜**ï¼š
    - é‡‡ç”¨Long-Onlyç­–ç•¥
    - æ¯æ—¥ç­‰æƒæŒæœ‰æ‰€æœ‰å› å­å€¼ä¸ºæ­£çš„è‚¡ç¥¨
    - å®šæœŸè°ƒä»“
    
    Parameters
    ----------
    start_date, end_date : str
        å›æµ‹å‘¨æœŸ
    stock_codes : Optional[List[str]]
        è‚¡ç¥¨æ± 
    tema_period : int, default=20
        TEMAè®¡ç®—å‘¨æœŸ
    slope_period : int, default=5
        æ–œç‡è®¡ç®—å‘¨æœŸ
    momentum_period : int, default=10
        åŠ¨é‡è®¡ç®—å‘¨æœŸ
    short_n : int, default=10
        çŸ­æœŸTEMAå‘¨æœŸ
    long_n : int, default=20
        é•¿æœŸTEMAå‘¨æœŸ
    rebalance_freq : str, default='weekly'
        è°ƒä»“é¢‘ç‡: 'daily', 'weekly', 'monthly'
    transaction_cost : float, default=0.0003
        å•è¾¹äº¤æ˜“æˆæœ¬
        
    Returns
    -------
    dict
        åŒ…å«å›æµ‹ç»“æœçš„å­—å…¸:
        - factor_data: å› å­æ•°æ®
        - portfolio_returns: ç»„åˆæ”¶ç›Š
        - performance_metrics: ä¸šç»©æŒ‡æ ‡
        - analysis_results: ICåˆ†æç»“æœ
    """
    print("=" * 60)
    print("TEMA æŠ€æœ¯å› å­å›æµ‹")
    print("=" * 60)
    print(f"\nå›æµ‹é…ç½®:")
    print(f"  æ—¶é—´èŒƒå›´: {start_date} ~ {end_date}")
    print(f"  TEMAå‘¨æœŸ: {tema_period}")
    print(f"  è°ƒä»“é¢‘ç‡: {rebalance_freq}")
    print(f"  äº¤æ˜“æˆæœ¬: {transaction_cost:.4f}")
    
    # åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
    data_manager = DataManager()
    
    # è®¡ç®—å› å­
    factor_data = calculate_tema_factor(
        data_manager=data_manager,
        start_date=start_date,
        end_date=end_date,
        stock_codes=stock_codes,
        tema_period=tema_period,
        slope_period=slope_period,
        momentum_period=momentum_period,
        short_n=short_n,
        long_n=long_n,
    )
    
    if factor_data.empty:
        print("âš ï¸ å› å­æ•°æ®ä¸ºç©ºï¼Œæ— æ³•å›æµ‹")
        return {
            'factor_data': None,
            'portfolio_returns': None,
            'performance_metrics': {},
            'analysis_results': {}
        }
    
    # å‡†å¤‡æ”¶ç›Šç‡æ•°æ®
    stock_list = factor_data.index.get_level_values('ts_code').unique().tolist()
    
    stock_data = data_manager.load_data(
        'daily',
        start_date=start_date,
        end_date=end_date,
        stock_codes=stock_list
    )
    
    if stock_data is None or stock_data.empty:
        raise ValueError("æ— æ³•åŠ è½½ç”¨äºå›æµ‹çš„è‚¡ç¥¨æ•°æ®")
    
    stock_data['trade_date'] = pd.to_datetime(stock_data['trade_date'])
    stock_data = stock_data.sort_values(['ts_code', 'trade_date'])
    
    # è®¡ç®—ä¸‹ä¸€æ—¥æ”¶ç›Šç‡
    stock_data['next_close'] = stock_data.groupby('ts_code')['close'].shift(-1)
    stock_data['next_return'] = (stock_data['next_close'] / stock_data['close']) - 1
    
    # åˆå¹¶å› å­å’Œæ”¶ç›Šæ•°æ®
    combined = pd.merge(
        factor_data.reset_index(),
        stock_data[['trade_date', 'ts_code', 'next_return']],
        on=['trade_date', 'ts_code'],
        how='inner'
    )
    
    combined = combined.dropna(subset=['next_return'])
    
    # Long-Onlyç­–ç•¥ï¼šç­‰æƒæŒæœ‰æ‰€æœ‰æœ‰å› å­å€¼çš„è‚¡ç¥¨
    portfolio_returns = combined.groupby('trade_date')['next_return'].mean()
    
    # æ¨¡æ‹Ÿäº¤æ˜“æˆæœ¬
    if rebalance_freq == 'daily':
        rebalance_dates = portfolio_returns.index
    else:
        freq_map = {'weekly': 'W-MON', 'monthly': 'MS'}
        rebalance_dates = pd.date_range(
            start=start_date, 
            end=end_date, 
            freq=freq_map.get(rebalance_freq)
        )
    
    if rebalance_dates is not None and len(portfolio_returns) > 0:
        cost_impact = len(rebalance_dates) * transaction_cost / len(portfolio_returns)
        portfolio_returns -= cost_impact
    
    # è®¡ç®—ä¸šç»©æŒ‡æ ‡
    cum_returns = (1 + portfolio_returns).cumprod()
    total_return = cum_returns.iloc[-1] - 1 if not cum_returns.empty else 0
    
    days = len(portfolio_returns)
    annualized_return = (1 + total_return) ** (252 / days) - 1 if days > 0 else 0
    
    volatility = portfolio_returns.std() * np.sqrt(252)
    sharpe_ratio = annualized_return / volatility if volatility > 0 else 0
    
    running_max = cum_returns.cummax()
    drawdown = cum_returns / running_max - 1
    max_drawdown = drawdown.min() if not drawdown.empty else 0
    
    # ICåˆ†æ
    ic_series = None
    ic_mean = None
    ic_std = None
    icir = None
    ic_positive_ratio = None
    
    try:
        ic_list = []
        for date in combined['trade_date'].unique():
            date_data = combined[combined['trade_date'] == date]
            if len(date_data) >= 10:
                correlation = date_data[['factor', 'next_return']].corr(method='spearman').iloc[0, 1]
                if not np.isnan(correlation):
                    ic_list.append({'trade_date': date, 'ic': correlation})
        
        if ic_list:
            ic_series = pd.DataFrame(ic_list).set_index('trade_date')['ic']
            ic_mean = ic_series.mean()
            ic_std = ic_series.std()
            icir = ic_mean / ic_std if ic_std > 0 else 0
            ic_positive_ratio = (ic_series > 0).mean()
    except Exception as e:
        logger.error(f"ICè®¡ç®—å¤±è´¥: {e}")
        print(f"âš ï¸ ICè®¡ç®—å¤±è´¥: {e}")
    
    # æ‰“å°ç»“æœ
    print("\n" + "=" * 60)
    print("å›æµ‹ç»“æœ")
    print("=" * 60)
    
    print(f"\nğŸ“Š ä¸šç»©æŒ‡æ ‡:")
    print(f"  æ€»æ”¶ç›Šç‡: {total_return:.2%}")
    print(f"  å¹´åŒ–æ”¶ç›Šç‡: {annualized_return:.2%}")
    print(f"  å¹´åŒ–æ³¢åŠ¨ç‡: {volatility:.2%}")
    print(f"  å¤æ™®æ¯”ç‡: {sharpe_ratio:.2f}")
    print(f"  æœ€å¤§å›æ’¤: {max_drawdown:.2%}")
    
    if ic_series is not None:
        print(f"\nğŸ“Š ICåˆ†æ:")
        print(f"  ICå‡å€¼: {ic_mean:.4f}")
        print(f"  ICæ ‡å‡†å·®: {ic_std:.4f}")
        print(f"  ICIR: {icir:.4f}")
        print(f"  IC>0å æ¯”: {ic_positive_ratio:.2%}")
    
    print(f"\nğŸ“ˆ å› å­è¦†ç›–:")
    print(f"  æœ‰æ•ˆå› å­è®°å½•æ•°: {len(factor_data)}")
    print(f"  è¦†ç›–è‚¡ç¥¨æ•°: {factor_data.index.get_level_values('ts_code').nunique()}")
    print(f"  è¦†ç›–äº¤æ˜“æ—¥æ•°: {factor_data.index.get_level_values('trade_date').nunique()}")
    
    return {
        'factor_data': factor_data,
        'portfolio_returns': portfolio_returns,
        'performance_metrics': {
            'total_return': total_return,
            'annualized_return': annualized_return,
            'volatility': volatility,
            'sharpe_ratio': sharpe_ratio,
            'max_drawdown': max_drawdown,
        },
        'analysis_results': {
            'ic_series': ic_series,
            'ic_mean': ic_mean,
            'ic_std': ic_std,
            'icir': icir,
            'ic_positive_ratio': ic_positive_ratio,
        }
    }


def main():
    """ä¸»å‡½æ•°ï¼šæ¼”ç¤ºTEMAå› å­è®¡ç®—å’Œå›æµ‹"""
    print("=" * 60)
    print("TEMA æŠ€æœ¯å› å­æ¼”ç¤º")
    print("=" * 60)
    
    try:
        # é…ç½®å‚æ•°
        config = {
            'start_date': '2023-01-01',
            'end_date': '2023-12-31',
            'tema_period': 20,
            'slope_period': 5,
            'momentum_period': 10,
            'short_n': 10,
            'long_n': 20,
            'rebalance_freq': 'weekly',
            'transaction_cost': 0.0003,
        }
        
        print("\nå›æµ‹é…ç½®:")
        for key, value in config.items():
            print(f"  {key}: {value}")
        
        # è¿è¡Œå›æµ‹
        results = run_tema_factor_backtest(**config)
        
        if results['factor_data'] is not None:
            # ç”Ÿæˆä¿¡å·
            print("\n" + "=" * 60)
            print("ç”Ÿæˆé€‰è‚¡ä¿¡å·")
            print("=" * 60)
            signals = generate_tema_signals(results['factor_data'])
            
            # è·å–æœ€æ–°ä¸€å¤©çš„æ¨èè‚¡ç¥¨
            latest_date = results['factor_data'].index.get_level_values('trade_date').max()
            top_stocks = get_top_stocks(signals, date=latest_date.strftime('%Y-%m-%d'), top_n=10)
        
        print("\nâœ… å›æµ‹å®Œæˆï¼")
        
    except Exception as e:
        print(f"\nâŒ è¿è¡Œå‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()
