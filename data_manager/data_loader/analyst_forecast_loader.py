"""
å–æ–¹åˆ†æå¸ˆç›ˆåˆ©é¢„æµ‹æ•°æ®ä¸‹è½½å™¨

åŠŸèƒ½ï¼š
- ä¸‹è½½ Tushare æä¾›çš„åˆ†æå¸ˆç›ˆåˆ©é¢„æµ‹æ•°æ®ï¼ˆé€šè¿‡ report_rc æ¥å£ï¼‰
- åŒ…å« EPSã€è¥ä¸šæ”¶å…¥ã€å‡€åˆ©æ¶¦ç­‰é¢„æµ‹æŒ‡æ ‡
- æ”¯æŒå…¨å¸‚åœºè‚¡ç¥¨çš„é¢„æµ‹æ•°æ®è·å–

æ•°æ®å­—æ®µè¯´æ˜ï¼ˆreport_rcæ¥å£ï¼‰ï¼š
- ts_code: è‚¡ç¥¨ä»£ç 
- ann_date: é¢„æµ‹å‘å¸ƒæ—¥æœŸ
- report_date: æŠ¥å‘ŠæœŸï¼ˆè¢«é¢„æµ‹çš„è´¢æŠ¥æœŸï¼‰
- report_type: æŠ¥å‘Šç±»å‹ï¼ˆ1=å¹´æŠ¥ã€2=ä¸­æŠ¥ã€3=å­£æŠ¥ï¼‰
- eps_avg: å¹³å‡é¢„æµ‹æ¯è‚¡æ”¶ç›Šï¼ˆEPSï¼‰
- eps_max: æœ€é«˜é¢„æµ‹æ¯è‚¡æ”¶ç›Š
- eps_min: æœ€ä½é¢„æµ‹æ¯è‚¡æ”¶ç›Š
- eps_std: é¢„æµ‹EPSæ ‡å‡†å·®
- revenue_avg: å¹³å‡é¢„æµ‹è¥ä¸šæ”¶å…¥ï¼ˆä¸‡å…ƒï¼‰
- revenue_max: æœ€é«˜é¢„æµ‹è¥ä¸šæ”¶å…¥
- revenue_min: æœ€ä½é¢„æµ‹è¥ä¸šæ”¶å…¥
- revenue_std: é¢„æµ‹è¥ä¸šæ”¶å…¥æ ‡å‡†å·®
- net_profit_avg: å¹³å‡é¢„æµ‹å‡€åˆ©æ¶¦ï¼ˆä¸‡å…ƒï¼‰
- net_profit_max: æœ€é«˜é¢„æµ‹å‡€åˆ©æ¶¦
- net_profit_min: æœ€ä½é¢„æµ‹å‡€åˆ©æ¶¦
- net_profit_std: é¢„æµ‹å‡€åˆ©æ¶¦æ ‡å‡†å·®
- pe_avg: å¹³å‡é¢„æµ‹å¸‚ç›ˆç‡
- roe_avg: å¹³å‡é¢„æµ‹å‡€èµ„äº§æ”¶ç›Šç‡

æ³¨æ„äº‹é¡¹ï¼š
- report_rc æ¥å£éœ€è¦ç§¯åˆ†æƒé™ï¼ˆå»ºè®®ä½¿ç”¨ 1000ç§¯åˆ† æˆ–ä»¥ä¸Šçš„è´¦æˆ·ï¼‰
- æ•°æ®æ›´æ–°é¢‘ç‡ï¼šæ—¥æ›´
- API é™æµï¼šæ¯åˆ†é’Ÿè°ƒç”¨ä¸è¶…è¿‡100æ¬¡ï¼ˆå»ºè®®æ¯æ¬¡è°ƒç”¨é—´éš”0.6ç§’ï¼‰
"""

import tushare as ts
import pandas as pd
import time
import sys
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
PROJECT_ROOT = Path(__file__).resolve().parents[2]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

from config import get_tushare_token, RAW_DATA_PATH

# åˆå§‹åŒ– Tushare API
ts.set_token(get_tushare_token())
pro = ts.pro_api()

print("=" * 80)
print("å–æ–¹åˆ†æå¸ˆç›ˆåˆ©é¢„æµ‹æ•°æ®ä¸‹è½½å™¨")
print("=" * 80)
print("Tushare API åˆå§‹åŒ–æˆåŠŸã€‚")

# è·å–Aè‚¡ä¸Šå¸‚å…¬å¸åˆ—è¡¨
print("\næ­£åœ¨è·å–æœ€æ–°çš„Aè‚¡ä¸Šå¸‚å…¬å¸åˆ—è¡¨...")
try:
    stock_list_df = pro.stock_basic(
        exchange='', 
        list_status='L', 
        fields='ts_code,name,industry,list_date'
    )
    print(f"âœ… æˆåŠŸè·å– {len(stock_list_df)} å®¶ä¸Šå¸‚å…¬å¸çš„åŸºæœ¬ä¿¡æ¯ã€‚")
except Exception as e:
    print(f"âŒ è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–Tokenè®¾ç½®: {e}")
    exit()

# å®šä¹‰ä¸‹è½½å‚æ•°
# è·å–è¿‘æœŸçš„é¢„æµ‹æ•°æ®ï¼ˆå»ºè®®æ ¹æ®éœ€æ±‚è°ƒæ•´æ—¶é—´èŒƒå›´ï¼‰
start_date = '20200101'  # ä»2020å¹´å¼€å§‹
end_date = datetime.now().strftime('%Y%m%d')  # åˆ°ä»Šå¤©

print(f"\nä¸‹è½½å‚æ•°:")
print(f"  æ—¶é—´èŒƒå›´: {start_date} è‡³ {end_date}")
print(f"  è‚¡ç¥¨æ•°é‡: {len(stock_list_df)}")
print(f"  æ•°æ®æ¥å£: report_rc (ç›ˆåˆ©é¢„æµ‹æ±‡æ€»)")

# åˆ›å»ºç©ºçš„DataFrameç”¨äºå­˜å‚¨æ‰€æœ‰æ•°æ®
all_forecast_data = pd.DataFrame()

# ç»Ÿè®¡å˜é‡
success_count = 0
fail_count = 0
total_records = 0

# å¾ªç¯è·å–æ‰€æœ‰Aè‚¡å…¬å¸çš„ç›ˆåˆ©é¢„æµ‹æ•°æ®
total_stocks = len(stock_list_df)
print(f"\nå‡†å¤‡å¼€å§‹ä¸‹è½½ {total_stocks} åªè‚¡ç¥¨çš„ç›ˆåˆ©é¢„æµ‹æ•°æ®ï¼Œè¿™å°†éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
print("=" * 80)

# éå†è‚¡ç¥¨åˆ—è¡¨ä¸­çš„æ¯ä¸€åªè‚¡ç¥¨
for index, row in stock_list_df.iterrows():
    ts_code = row['ts_code']
    stock_name = row['name']
    industry = row['industry']
    
    # æ‰“å°è¿›åº¦
    progress = (index + 1) / total_stocks * 100
    print(f"[{index + 1}/{total_stocks}] ({progress:.1f}%) æ­£åœ¨å¤„ç†: {ts_code} ({stock_name}) - {industry}")
    
    try:
        # è°ƒç”¨ report_rc æ¥å£è·å–è¯¥è‚¡ç¥¨çš„ç›ˆåˆ©é¢„æµ‹æ•°æ®
        # è¿™ä¸ªæ¥å£è¿”å›çš„æ˜¯åˆ†æå¸ˆé¢„æµ‹çš„æ±‡æ€»æ•°æ®ï¼ˆå‡å€¼ã€æœ€å¤§ã€æœ€å°ç­‰ï¼‰
        df_single_stock = pro.report_rc(
            ts_code=ts_code,
            start_date=start_date,
            end_date=end_date,
            fields='ts_code,ann_date,report_date,report_type,eps_avg,eps_max,eps_min,eps_std,revenue_avg,revenue_max,revenue_min,revenue_std,net_profit_avg,net_profit_max,net_profit_min,net_profit_std,pe_avg,roe_avg'
        )
        
        # å¦‚æœæˆåŠŸè·å–åˆ°æ•°æ®
        if df_single_stock is not None and not df_single_stock.empty:
            # å°†æ–°è·å–çš„æ•°æ®æ‹¼æ¥åˆ°æ€»DataFrameä¸­
            all_forecast_data = pd.concat(
                [all_forecast_data, df_single_stock], 
                ignore_index=True
            )
            record_count = len(df_single_stock)
            total_records += record_count
            success_count += 1
            print(f"  âœ… æˆåŠŸè·å– {record_count} æ¡é¢„æµ‹è®°å½• | ç´¯è®¡: {total_records} æ¡")
        else:
            fail_count += 1
            print(f"  âš ï¸  æœªæ‰¾åˆ°é¢„æµ‹æ•°æ®")
        
        # APIé¢‘ç‡é™åˆ¶ï¼šæ¯æ¬¡è°ƒç”¨åç­‰å¾…0.6ç§’
        # Tushare å¯¹ç§¯åˆ†æ¥å£æœ‰æ›´ä¸¥æ ¼çš„é™åˆ¶ï¼Œå»ºè®®é€‚å½“å»¶é•¿ç­‰å¾…æ—¶é—´
        time.sleep(0.6)
        
    except Exception as e:
        fail_count += 1
        print(f"  âŒ è·å–æ•°æ®æ—¶å‡ºé”™: {e}")
        # å³ä½¿å‡ºé”™ä¹Ÿç»§ç»­å¤„ç†ä¸‹ä¸€åªè‚¡ç¥¨
        continue
    
    # æ¯å¤„ç†100åªè‚¡ç¥¨ï¼Œæ˜¾ç¤ºä¸€æ¬¡æ±‡æ€»ç»Ÿè®¡
    if (index + 1) % 100 == 0:
        print("-" * 80)
        print(f"é˜¶æ®µæ€§ç»Ÿè®¡ [{index + 1}/{total_stocks}]:")
        print(f"  æˆåŠŸ: {success_count} | å¤±è´¥: {fail_count} | æ€»è®°å½•æ•°: {total_records}")
        print("-" * 80)

print("\n" + "=" * 80)
print("æ‰€æœ‰è‚¡ç¥¨çš„ç›ˆåˆ©é¢„æµ‹æ•°æ®è·å–å®Œæˆï¼")
print("=" * 80)

# æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
print("\nğŸ“Š ä¸‹è½½ç»Ÿè®¡:")
print(f"  æ€»è‚¡ç¥¨æ•°: {total_stocks}")
print(f"  æˆåŠŸè·å–: {success_count} ({success_count/total_stocks*100:.1f}%)")
print(f"  æœªæ‰¾åˆ°æ•°æ®: {fail_count} ({fail_count/total_stocks*100:.1f}%)")
print(f"  æ€»è®°å½•æ•°: {total_records}")

# æ•°æ®è´¨é‡æ£€æŸ¥
if not all_forecast_data.empty:
    print("\nğŸ“ˆ æ•°æ®è´¨é‡æ£€æŸ¥:")
    print(f"  æ•°æ®æ€»è¡Œæ•°: {len(all_forecast_data):,}")
    print(f"  æ•°æ®æ€»åˆ—æ•°: {len(all_forecast_data.columns)}")
    print(f"  è¦†ç›–è‚¡ç¥¨æ•°: {all_forecast_data['ts_code'].nunique()}")
    print(f"  æ—¶é—´èŒƒå›´: {all_forecast_data['ann_date'].min()} è‡³ {all_forecast_data['ann_date'].max()}")
    
    # æ£€æŸ¥å…³é”®å­—æ®µçš„ç¼ºå¤±ç‡
    print("\n  å…³é”®å­—æ®µç¼ºå¤±ç‡:")
    key_fields = ['eps_avg', 'revenue_avg', 'net_profit_avg', 'pe_avg', 'roe_avg']
    for field in key_fields:
        if field in all_forecast_data.columns:
            missing_rate = all_forecast_data[field].isna().sum() / len(all_forecast_data) * 100
            print(f"    {field}: {missing_rate:.2f}%")
    
    # æ˜¾ç¤ºæ•°æ®æ ·ä¾‹
    print("\n  æ•°æ®æ ·ä¾‹ï¼ˆå‰5è¡Œï¼‰:")
    print(all_forecast_data.head())
    
    # æ˜¾ç¤ºæ•°æ®ç±»å‹
    print("\n  æ•°æ®ç±»å‹:")
    print(all_forecast_data.dtypes)
    
    # ä¿å­˜æ•°æ®åˆ°Parquetæ–‡ä»¶
    output_file = RAW_DATA_PATH / 'analyst_forecast_data.parquet'
    print(f"\nğŸ’¾ æ­£åœ¨ä¿å­˜æ•°æ®åˆ°: {output_file}")
    
    try:
        all_forecast_data.to_parquet(output_file, index=False, engine='pyarrow')
        file_size_mb = output_file.stat().st_size / (1024 * 1024)
        print(f"âœ… æ•°æ®ä¿å­˜æˆåŠŸï¼æ–‡ä»¶å¤§å°: {file_size_mb:.2f} MB")
    except Exception as e:
        print(f"âŒ ä¿å­˜æ•°æ®æ—¶å‡ºé”™: {e}")
else:
    print("\nâš ï¸  è­¦å‘Š: æœªè·å–åˆ°ä»»ä½•æ•°æ®ï¼Œè¯·æ£€æŸ¥:")
    print("  1. Tushareè´¦æˆ·ç§¯åˆ†æ˜¯å¦è¶³å¤Ÿï¼ˆreport_rcæ¥å£éœ€è¦ç§¯åˆ†æƒé™ï¼‰")
    print("  2. API Tokenæ˜¯å¦æ­£ç¡®é…ç½®")
    print("  3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")

print("\n" + "=" * 80)
print("ç¨‹åºæ‰§è¡Œå®Œæ¯•ï¼")
print("=" * 80)
