from pathlib import Path
import sys
import pandas as pd

# æ·»åŠ é¡¹ç›®æ ¹è·¯å¾„ä»¥ä¾¿å¯¼å…¥ config
PROJECT_ROOT = Path(__file__).resolve().parents[2]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

from config import RAW_DATA_PATH, CLEAN_DATA_PATH


def load_raw_daily_basic():
    """
    åŠ è½½åŸå§‹çš„ daily_basic æ•°æ®
    """
    print("æ­£åœ¨åŠ è½½åŸå§‹ daily_basic æ•°æ®...")
    raw_file = RAW_DATA_PATH / 'a_stock_daily_basic_data.parquet'
    
    if not raw_file.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {raw_file}")
        return None
    
    df = pd.read_parquet(raw_file)
    print(f"âœ… åŠ è½½æˆåŠŸ: {len(df):,} æ¡è®°å½•")
    return df


def handle_daily_basic_outliers(df: pd.DataFrame) -> pd.DataFrame:
    """
    å¤„ç† daily_basic æ•°æ®ä¸­çš„ç¦»ç¾¤å€¼
    - turnover_rate: æ¢æ‰‹ç‡èŒƒå›´ [0, 100]
    - pe: å¸‚ç›ˆç‡èŒƒå›´ [-1000, 1000]
    - pb: å¸‚å‡€ç‡èŒƒå›´ [0, 100]
    - ps: å¸‚é”€ç‡èŒƒå›´ [0, 100]
    - dv_ratio: è‚¡æ¯ç‡èŒƒå›´ [0, 50]
    """
    print("å¼€å§‹å¤„ç†ç¦»ç¾¤å€¼...")
    
    # æ¢æ‰‹ç‡å‹ç¼©åˆ° [0, 100]
    if 'turnover_rate' in df.columns:
        before_outliers = ((df['turnover_rate'] < 0) | (df['turnover_rate'] > 100)).sum()
        df['turnover_rate'] = df['turnover_rate'].clip(0, 100)
        print(f"   turnover_rate: å‹ç¼©äº† {before_outliers:,} ä¸ªç¦»ç¾¤å€¼åˆ° [0, 100]")
    
    # å¸‚ç›ˆç‡å‹ç¼©åˆ° [-1000, 1000] (è´Ÿå€¼å¯èƒ½æ˜¯äºæŸ)
    if 'pe' in df.columns:
        before_outliers = ((df['pe'] < -1000) | (df['pe'] > 1000)).sum()
        df['pe'] = df['pe'].clip(-1000, 1000)
        print(f"   pe: å‹ç¼©äº† {before_outliers:,} ä¸ªç¦»ç¾¤å€¼åˆ° [-1000, 1000]")
    
    # å¸‚ç›ˆç‡TTMå‹ç¼©
    if 'pe_ttm' in df.columns:
        before_outliers = ((df['pe_ttm'] < -1000) | (df['pe_ttm'] > 1000)).sum()
        df['pe_ttm'] = df['pe_ttm'].clip(-1000, 1000)
        print(f"   pe_ttm: å‹ç¼©äº† {before_outliers:,} ä¸ªç¦»ç¾¤å€¼åˆ° [-1000, 1000]")
    
    # å¸‚å‡€ç‡å‹ç¼©åˆ° [0, 100]
    if 'pb' in df.columns:
        before_outliers = ((df['pb'] < 0) | (df['pb'] > 100)).sum()
        df['pb'] = df['pb'].clip(0, 100)
        print(f"   pb: å‹ç¼©äº† {before_outliers:,} ä¸ªç¦»ç¾¤å€¼åˆ° [0, 100]")
    
    # å¸‚é”€ç‡å‹ç¼©åˆ° [0, 100]
    if 'ps' in df.columns:
        before_outliers = ((df['ps'] < 0) | (df['ps'] > 100)).sum()
        df['ps'] = df['ps'].clip(0, 100)
        print(f"   ps: å‹ç¼©äº† {before_outliers:,} ä¸ªç¦»ç¾¤å€¼åˆ° [0, 100]")
    
    # å¸‚é”€ç‡TTMå‹ç¼©
    if 'ps_ttm' in df.columns:
        before_outliers = ((df['ps_ttm'] < 0) | (df['ps_ttm'] > 100)).sum()
        df['ps_ttm'] = df['ps_ttm'].clip(0, 100)
        print(f"   ps_ttm: å‹ç¼©äº† {before_outliers:,} ä¸ªç¦»ç¾¤å€¼åˆ° [0, 100]")
    
    # è‚¡æ¯ç‡å‹ç¼©åˆ° [0, 50]
    if 'dv_ratio' in df.columns:
        before_outliers = ((df['dv_ratio'] < 0) | (df['dv_ratio'] > 50)).sum()
        df['dv_ratio'] = df['dv_ratio'].clip(0, 50)
        print(f"   dv_ratio: å‹ç¼©äº† {before_outliers:,} ä¸ªç¦»ç¾¤å€¼åˆ° [0, 50]")
    
    # è‚¡æ¯ç‡TTMå‹ç¼©
    if 'dv_ttm' in df.columns:
        before_outliers = ((df['dv_ttm'] < 0) | (df['dv_ttm'] > 50)).sum()
        df['dv_ttm'] = df['dv_ttm'].clip(0, 50)
        print(f"   dv_ttm: å‹ç¼©äº† {before_outliers:,} ä¸ªç¦»ç¾¤å€¼åˆ° [0, 50]")
    
    print("ç¦»ç¾¤å€¼å¤„ç†å®Œæˆã€‚")
    return df


def handle_daily_basic_missing_values(df: pd.DataFrame) -> pd.DataFrame:
    """
    å¤„ç† daily_basic æ•°æ®ä¸­çš„ç¼ºå¤±å€¼
    - å¯¹äºä¼°å€¼æŒ‡æ ‡(pe, pbç­‰): ä½¿ç”¨å‘å‰å¡«å……
    - å¯¹äºå¸‚å€¼æ•°æ®: åˆ é™¤ç¼ºå¤±è¡Œ
    """
    print("å¼€å§‹å¤„ç†ç¼ºå¤±å€¼...")
    print(f"   å¤„ç†å‰æ•°æ®é‡: {len(df):,} æ¡")
    
    # æŒ‰è‚¡ç¥¨ä»£ç å’Œæ—¥æœŸæ’åº
    df = df.sort_values(by=['ts_code', 'trade_date'])
    
    # ä¼°å€¼æŒ‡æ ‡å¯ä»¥å‘å‰å¡«å……
    valuation_cols = ['turnover_rate', 'turnover_rate_f', 'volume_ratio', 
                      'pe', 'pe_ttm', 'pb', 'ps', 'ps_ttm', 
                      'dv_ratio', 'dv_ttm']
    existing_valuation_cols = [col for col in valuation_cols if col in df.columns]
    
    if existing_valuation_cols:
        df[existing_valuation_cols] = df.groupby('ts_code')[existing_valuation_cols].ffill()
        print(f"   å‘å‰å¡«å……ä¼°å€¼æŒ‡æ ‡: {existing_valuation_cols}")
    
    # å¸‚å€¼æ•°æ®ç¼ºå¤±åˆ™åˆ é™¤æ•´è¡Œ(å¸‚å€¼æ˜¯å…³é”®æŒ‡æ ‡)
    market_value_cols = ['total_share', 'float_share', 'free_share', 
                        'total_mv', 'circ_mv']
    existing_mv_cols = [col for col in market_value_cols if col in df.columns]
    
    if existing_mv_cols:
        before_drop = len(df)
        df = df.dropna(subset=existing_mv_cols, how='all')  # å¦‚æœæ‰€æœ‰å¸‚å€¼åˆ—éƒ½æ˜¯NaNæ‰åˆ é™¤
        after_drop = len(df)
        print(f"   åˆ é™¤äº† {before_drop - after_drop:,} æ¡å¸‚å€¼æ•°æ®å…¨éƒ¨ç¼ºå¤±çš„è®°å½•")
    
    # closeä»·æ ¼ç¼ºå¤±ä¹Ÿåˆ é™¤(è¿™æ˜¯daily_basicçš„åŸºå‡†ä»·)
    if 'close' in df.columns:
        before_drop = len(df)
        df = df.dropna(subset=['close'])
        after_drop = len(df)
        print(f"   åˆ é™¤äº† {before_drop - after_drop:,} æ¡closeä»·æ ¼ç¼ºå¤±çš„è®°å½•")
    
    print(f"   å¤„ç†åæ•°æ®é‡: {len(df):,} æ¡")
    print("ç¼ºå¤±å€¼å¤„ç†å®Œæˆã€‚")
    return df


def validate_daily_basic_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    æ•°æ®æœ‰æ•ˆæ€§éªŒè¯
    - ç¡®ä¿å…³é”®å­—æ®µéè´Ÿ
    - ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®
    """
    print("å¼€å§‹æ•°æ®æœ‰æ•ˆæ€§éªŒè¯...")
    
    # å¸‚å€¼å¿…é¡»ä¸ºæ­£
    if 'total_mv' in df.columns:
        before_len = len(df)
        df = df[df['total_mv'] > 0]
        after_len = len(df)
        if before_len != after_len:
            print(f"   åˆ é™¤äº† {before_len - after_len:,} æ¡total_mvâ‰¤0çš„æ— æ•ˆè®°å½•")
    
    if 'circ_mv' in df.columns:
        before_len = len(df)
        df = df[df['circ_mv'] > 0]
        after_len = len(df)
        if before_len != after_len:
            print(f"   åˆ é™¤äº† {before_len - after_len:,} æ¡circ_mvâ‰¤0çš„æ— æ•ˆè®°å½•")
    
    # è‚¡æœ¬å¿…é¡»ä¸ºæ­£
    if 'total_share' in df.columns:
        before_len = len(df)
        df = df[df['total_share'] > 0]
        after_len = len(df)
        if before_len != after_len:
            print(f"   åˆ é™¤äº† {before_len - after_len:,} æ¡total_shareâ‰¤0çš„æ— æ•ˆè®°å½•")
    
    # æ¢æ‰‹ç‡ä¸èƒ½ä¸ºè´Ÿ
    if 'turnover_rate' in df.columns:
        before_len = len(df)
        df = df[df['turnover_rate'] >= 0]
        after_len = len(df)
        if before_len != after_len:
            print(f"   åˆ é™¤äº† {before_len - after_len:,} æ¡turnover_rate<0çš„æ— æ•ˆè®°å½•")
    
    print("æ•°æ®æœ‰æ•ˆæ€§éªŒè¯å®Œæˆã€‚")
    return df


def run_pipeline():
    """
    æ‰§è¡Œå®Œæ•´çš„ daily_basic æ•°æ®æ¸…æ´—å·¥ä½œæµ
    """
    print("=" * 60)
    print("ğŸš€ å¼€å§‹æ‰§è¡Œ daily_basic æ•°æ®æ¸…æ´—æµç¨‹")
    print("=" * 60)
    
    # 1. åŠ è½½åŸå§‹æ•°æ®
    print("\nğŸ“‚ æ­¥éª¤1: æ•°æ®åŠ è½½")
    df = load_raw_daily_basic()
    
    if df is None:
        print("âŒ æ•°æ®åŠ è½½å¤±è´¥ï¼Œæ¸…æ´—æµç¨‹ä¸­æ­¢")
        return
    
    print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {len(df):,} æ¡è®°å½•")
    print(f"ğŸ“Š æ•°æ®åˆ—: {list(df.columns)}")
    
    # ç¡®ä¿å…³é”®åˆ—å­˜åœ¨
    required_cols = ['ts_code', 'trade_date', 'close']
    missing_cols = [col for col in required_cols if col not in df.columns]
    if missing_cols:
        print(f"âŒ ç¼ºå°‘å…³é”®åˆ—: {missing_cols}")
        return
    
    # 2. ä¾æ¬¡æ‰§è¡Œæ¸…æ´—æ­¥éª¤
    print("\nğŸ§¹ æ­¥éª¤2: æ•°æ®æ¸…æ´—")
    
    # 2a. å¤„ç†ç¦»ç¾¤å€¼
    print("\n--- 2a. å¤„ç†ç¦»ç¾¤å€¼ ---")
    df = handle_daily_basic_outliers(df)
    
    # 2b. å¤„ç†ç¼ºå¤±å€¼
    print("\n--- 2b. å¤„ç†ç¼ºå¤±å€¼ ---")
    df = handle_daily_basic_missing_values(df)
    
    # 2c. æ•°æ®æœ‰æ•ˆæ€§éªŒè¯
    print("\n--- 2c. æ•°æ®æœ‰æ•ˆæ€§éªŒè¯ ---")
    df = validate_daily_basic_data(df)
    
    # 3. æ•°æ®è´¨é‡æ£€æŸ¥
    print("\nğŸ” æ­¥éª¤3: æ•°æ®è´¨é‡æ£€æŸ¥")
    print(f"âœ… æœ€ç»ˆæ•°æ®é‡: {len(df):,} æ¡è®°å½•")
    print(f"ğŸ“Š æœ€ç»ˆåˆ—æ•°: {len(df.columns)} åˆ—")
    print(f"ğŸ¢ è‚¡ç¥¨æ•°é‡: {df['ts_code'].nunique():,} åª")
    print(f"ğŸ“… æ—¶é—´è·¨åº¦: {df['trade_date'].min()} ~ {df['trade_date'].max()}")
    
    # éªŒè¯å…³é”®åˆ—
    if 'ts_code' not in df.columns:
        print("âŒ è­¦å‘Š: ts_codeåˆ—ä¸¢å¤±ï¼")
    else:
        print("âœ… ts_codeåˆ—ä¿ç•™å®Œæ•´")
    
    # æ£€æŸ¥å¸‚å€¼æ•°æ®è¦†ç›–ç‡
    if 'total_mv' in df.columns:
        mv_coverage = (df['total_mv'].notna().sum() / len(df)) * 100
        print(f"âœ… total_mvæ•°æ®è¦†ç›–ç‡: {mv_coverage:.2f}%")
    
    if 'turnover_rate' in df.columns:
        tr_coverage = (df['turnover_rate'].notna().sum() / len(df)) * 100
        print(f"âœ… turnover_rateæ•°æ®è¦†ç›–ç‡: {tr_coverage:.2f}%")
    
    # 4. å­˜å‚¨æ¸…æ´—åçš„æ•°æ®
    print("\nğŸ’¾ æ­¥éª¤4: æ•°æ®å­˜å‚¨")
    save_file = CLEAN_DATA_PATH / 'a_stock_daily_basic_data_clean.parquet'
    
    df.to_parquet(save_file, index=False)
    print(f"âœ… æ•°æ®å·²ä¿å­˜è‡³: {save_file}")
    print(f"ğŸ“¦ æ–‡ä»¶å¤§å°: {save_file.stat().st_size / 1024 / 1024:.2f} MB")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ daily_basic æ•°æ®æ¸…æ´—æµç¨‹å®Œæˆï¼")
    print("=" * 60)


if __name__ == "__main__":
    run_pipeline()
