import pandas as pd
import numpy as np
import sys
from pathlib import Path
from typing import Optional, List
import warnings

# è·¯å¾„ï¼šæŠŠé¡¹ç›®æ ¹ç›®å½•åŠ å…¥ sys.pathï¼Œä¾¿äºä½¿ç”¨ç»å¯¹åŒ…å¯¼å…¥
PROJECT_ROOT = Path(__file__).resolve().parents[2]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

from data_manager.data import DataManager


def get_index_components(data_manager, index_code='000852.SH', trade_date=None):
    """
    è·å–æŒ‡å®šæŒ‡æ•°çš„æˆåˆ†è‚¡åˆ—è¡¨
    
    Parameters
    ----------
    data_manager : DataManager
        æ•°æ®ç®¡ç†å™¨å®ä¾‹
    index_code : str
        æŒ‡æ•°ä»£ç ï¼Œé»˜è®¤ä¸ºä¸­è¯1000 (000852.SH)
        å¯é€‰ï¼š000300.SH (æ²ªæ·±300), 000905.SH (ä¸­è¯500), 000016.SH (ä¸Šè¯50)
    trade_date : Optional[str]
        æŒ‡å®šæ—¥æœŸï¼Œæ ¼å¼ YYYY-MM-DD æˆ– YYYYMMDD
        å¦‚æœä¸ºNoneï¼Œä½¿ç”¨æœ€æ–°ä¸€æœŸæ•°æ®
    
    Returns
    -------
    List[str]
        æˆåˆ†è‚¡ä»£ç åˆ—è¡¨
    """
    # ç›´æ¥ä»raw_dataåŠ è½½æŒ‡æ•°æƒé‡æ•°æ®ï¼ˆè¯¥æ•°æ®ä¸éœ€è¦æ¸…æ´—ï¼‰
    from pathlib import Path
    import pandas as pd
    
    raw_data_path = Path(__file__).resolve().parent.parent.parent / 'data_manager' / 'raw_data' / 'index_weight_data.parquet'
    
    try:
        index_weights = pd.read_parquet(raw_data_path)
    except Exception as e:
        warnings.warn(f"æ— æ³•åŠ è½½ index_weight æ•°æ®: {e}\nè¯·å…ˆè¿è¡Œ data_manager/data_loader/index_weight_data_loader.py")
        return []
    
    if index_weights is None or index_weights.empty:
        warnings.warn(f"index_weight æ•°æ®ä¸ºç©ºï¼Œè¯·å…ˆè¿è¡Œ data_manager/data_loader/index_weight_data_loader.py")
        return []
    
    # ç­›é€‰æŒ‡å®šæŒ‡æ•°
    index_data = index_weights[index_weights['index_code'] == index_code].copy()
    
    if index_data.empty:
        warnings.warn(f"æœªæ‰¾åˆ°æŒ‡æ•° {index_code} çš„æƒé‡æ•°æ®")
        return []
    
    # å¦‚æœæŒ‡å®šäº†æ—¥æœŸï¼Œç­›é€‰è¯¥æ—¥æœŸçš„æ•°æ®
    if trade_date is not None:
        # è½¬æ¢æ—¥æœŸæ ¼å¼
        if '-' in trade_date:
            trade_date = trade_date.replace('-', '')
        index_data = index_data[index_data['trade_date'] == trade_date]
        
        if index_data.empty:
            # å¦‚æœæŒ‡å®šæ—¥æœŸæ²¡æœ‰æ•°æ®ï¼Œä½¿ç”¨æœ€æ¥è¿‘çš„æ—¥æœŸ
            warnings.warn(f"æŒ‡å®šæ—¥æœŸ {trade_date} æ²¡æœ‰æ•°æ®ï¼Œä½¿ç”¨æœ€æ–°ä¸€æœŸæ•°æ®")
            index_data = index_weights[index_weights['index_code'] == index_code].copy()
            latest_date = index_data['trade_date'].max()
            index_data = index_data[index_data['trade_date'] == latest_date]
    else:
        # ä½¿ç”¨æœ€æ–°ä¸€æœŸæ•°æ®
        latest_date = index_data['trade_date'].max()
        index_data = index_data[index_data['trade_date'] == latest_date]
    
    # æå–æˆåˆ†è‚¡ä»£ç 
    components = index_data['con_code'].unique().tolist()
    
    print(f"âœ… è·å–æŒ‡æ•° {index_code} æˆåˆ†è‚¡:")
    print(f"   æ—¥æœŸ: {index_data['trade_date'].iloc[0] if not index_data.empty else 'N/A'}")
    print(f"   æˆåˆ†è‚¡æ•°é‡: {len(components)}")
    
    return components


def calculate_new_high_alpha_factor(
    data_manager: DataManager,
    start_date: str,
    end_date: str,
    stock_codes: Optional[List[str]] = None,
    high_window: int = 240,
    volume_ma_window: int = 10,
    lookback_window: int = 60,
    n1_threshold: int = 20,
    n2_threshold: int = 50,
) -> pd.DataFrame:
    """
    è®¡ç®—åˆ›æ–°é«˜ç²¾é€‰Alphaå› å­ (v2) - ä½¿ç”¨æ¢æ‰‹ç‡ç‰ˆæœ¬
    
    è¯¥ç‰ˆæœ¬æ ¹æ®æ¯æ—¥æœ‰æ•ˆåˆ›æ–°é«˜æ ·æœ¬æ•°é‡ï¼Œé‡‡ç”¨åŠ¨æ€ç­›é€‰ç­–ç•¥ã€‚
    å› å­å€¼ä¸ºäºŒå…ƒå€¼ï¼ˆ1è¡¨ç¤ºå…¥é€‰ï¼ŒNaNè¡¨ç¤ºæœªå…¥é€‰ï¼‰ã€‚
    
    **å…³é”®æ”¹è¿›**ï¼šä½¿ç”¨ daily_basic ä¸­çš„æ¢æ‰‹ç‡æ›¿ä»£æˆäº¤é¢è¿›è¡Œæ”¾é‡ç¡®è®¤
    **é»˜è®¤è‚¡ç¥¨æ± **ï¼šä¸­è¯1000æˆåˆ†è‚¡ï¼ˆ000852.SHï¼‰

    Parameters
    ----------
    data_manager : DataManager
        æ•°æ®ç®¡ç†å™¨å®ä¾‹ã€‚
    start_date, end_date : str
        å›æµ‹å‘¨æœŸã€‚
    stock_codes : Optional[List[str]]
        è‚¡ç¥¨æ± ã€‚å¦‚æœä¸ºNoneï¼Œåˆ™è‡ªåŠ¨ä½¿ç”¨ä¸­è¯1000æˆåˆ†è‚¡ã€‚
    high_window : int
        æ–°é«˜çª—å£æœŸã€‚
    volume_ma_window : int
        æ¢æ‰‹ç‡å‡çº¿çª—å£ã€‚
    lookback_window : int
        å‰æœŸè¡¨ç°å›çœ‹çª—å£ã€‚
    n1_threshold, n2_threshold : int
        åŠ¨æ€ç­›é€‰æ ·æœ¬æ•°é˜ˆå€¼ã€‚

    Returns
    -------
    pd.DataFrame
        MultiIndex (trade_date, ts_code) with single column 'factor'.
        å› å­å€¼ä¸º1ï¼ˆå…¥é€‰ï¼‰æˆ–NaNï¼ˆæœªå…¥é€‰ï¼‰ã€‚
    """
    # æ­¥éª¤ 1: åˆå§‹ä¿¡å·ç”Ÿæˆ
    print("\n" + "=" * 60)
    print("æ­¥éª¤ 1: åˆå§‹ä¿¡å·ç”Ÿæˆ")
    
    # 1.1 ç¡®å®šé€‰è‚¡åŸŸ
    if stock_codes is None:
        print("æœªæŒ‡å®šè‚¡ç¥¨æ± ï¼Œä½¿ç”¨ä¸­è¯1000æˆåˆ†è‚¡...")
        stock_codes = get_index_components(data_manager, index_code='000852.SH')
        
        if not stock_codes:
            warnings.warn("æ— æ³•è·å–ä¸­è¯1000æˆåˆ†è‚¡ï¼Œå°†ä½¿ç”¨å…¨å¸‚åœºè‚¡ç¥¨ã€‚è¯·ç¡®ä¿å·²è¿è¡Œ index_weight_data_loader.py")
            stock_codes = None
        else:
            print(f"âœ… æˆåŠŸåŠ è½½ä¸­è¯1000æˆåˆ†è‚¡ï¼Œå…± {len(stock_codes)} åªè‚¡ç¥¨")

    # 1.2 åŠ è½½æ•°æ®
    buffer_days = max(high_window, lookback_window) * 2
    start_date_extended = (pd.to_datetime(start_date) - pd.Timedelta(days=buffer_days)).strftime('%Y-%m-%d')
    
    # åŠ è½½æ—¥çº¿æ•°æ®
    daily = data_manager.load_data('daily', start_date=start_date_extended, end_date=end_date, stock_codes=stock_codes)
    if daily is None or daily.empty:
        raise ValueError("æ— æ³•åŠ è½½æ—¥è¡Œæƒ…æ•°æ®ã€‚")
    
    # åŠ è½½ daily_basic æ•°æ®ä»¥è·å–æ¢æ‰‹ç‡
    daily_basic = data_manager.load_data('daily_basic', start_date=start_date_extended, end_date=end_date, stock_codes=stock_codes)
    if daily_basic is None or daily_basic.empty:
        raise ValueError("æ— æ³•åŠ è½½ daily_basic æ•°æ®ã€‚")
    
    daily = daily.copy()
    daily['trade_date'] = pd.to_datetime(daily['trade_date'])
    daily = daily.sort_values(['ts_code', 'trade_date']).reset_index(drop=True)
    
    # åˆå¹¶æ¢æ‰‹ç‡æ•°æ®
    daily_basic = daily_basic.copy()
    daily_basic['trade_date'] = pd.to_datetime(daily_basic['trade_date'])
    daily = pd.merge(
        daily,
        daily_basic[['ts_code', 'trade_date', 'turnover_rate']],
        on=['ts_code', 'trade_date'],
        how='left'
    )
    
    print(f"âœ… æˆåŠŸåŠ è½½æ•°æ®ï¼ŒåŒ…å«æ¢æ‰‹ç‡å­—æ®µ: {'turnover_rate' in daily.columns}")
    print(f"   æ•°æ®æ—¶é—´èŒƒå›´: {daily['trade_date'].min()} ~ {daily['trade_date'].max()}")
    print(f"   è‚¡ç¥¨æ•°é‡: {daily['ts_code'].nunique()}")

    # 1.3 è¯†åˆ«åˆ›æ–°é«˜äº‹ä»¶
    # è¿‡å»240ä¸ªäº¤æ˜“æ—¥ï¼ˆä¸å«å½“æ—¥ï¼‰çš„æ”¶ç›˜ä»·æ–°é«˜
    rolling_max_close = daily.groupby('ts_code')['close'].transform(
        lambda x: x.rolling(window=high_window, min_periods=high_window).max().shift(1)
    )
    is_new_high = daily['close'] > rolling_max_close
    
    initial_count = is_new_high.sum()
    print(f"è¯†åˆ«åˆ° {initial_count} ä¸ªåˆå§‹åˆ›æ–°é«˜äº‹ä»¶ã€‚")
    
    # æ­¥éª¤ 2: æ—¶åºç­›é€‰
    print("\n" + "=" * 60)
    print("æ­¥éª¤ 2: æ—¶åºç­›é€‰ï¼ˆå‰”é™¤å‡çªç ´æ ·æœ¬ï¼‰")
    
    # 2.1 å‰”é™¤æ¶¨åœæ ·æœ¬
    is_limit_up_today = daily['pct_chg'] > 9.8
    daily['next_open'] = daily.groupby('ts_code')['open'].shift(-1)
    is_limit_up_next_open = (daily['next_open'] / daily['close'] - 1) > 0.098
    
    valid_mask = is_new_high & (~is_limit_up_today) & (~is_limit_up_next_open)
    print(f"å‰”é™¤æ¶¨åœåï¼Œå‰©ä½™ {valid_mask.sum()} ä¸ªäº‹ä»¶ã€‚")

    # 2.2 ç¡®è®¤æ”¾é‡çªç ´ï¼ˆä½¿ç”¨æ¢æ‰‹ç‡ï¼‰
    print("è®¡ç®—æ¢æ‰‹ç‡ç¡®è®¤æŒ‡æ ‡...")
    daily['turnover_ma'] = daily.groupby('ts_code')['turnover_rate'].transform(
        lambda x: x.rolling(window=volume_ma_window).mean()
    )
    
    # æ‰¾åˆ°å‰æœŸé«˜ç‚¹å¯¹åº”çš„æ¢æ‰‹ç‡MA
    def get_prev_high_turnover_ma(group):
        """å¯¹å•åªè‚¡ç¥¨è®¡ç®—å‰æœŸé«˜ç‚¹çš„æ¢æ‰‹ç‡MA"""
        result = pd.Series(index=group.index, dtype=float)
        
        for i in range(len(group)):
            if i < high_window:
                result.iloc[i] = np.nan
                continue
            
            # è·å–å‰æœŸçª—å£ï¼ˆi-high_window åˆ° i-1ï¼‰
            window_close = group['close'].iloc[i - high_window : i]
            window_turnover_ma = group['turnover_ma'].iloc[i - high_window : i]
            
            # æ‰¾åˆ°çª—å£å†…æœ€é«˜ä»·å¯¹åº”çš„ç´¢å¼•
            if not window_close.empty:
                max_idx = window_close.idxmax()
                result.iloc[i] = window_turnover_ma.loc[max_idx]
            else:
                result.iloc[i] = np.nan
                
        return result
    
    daily['prev_high_turnover_ma'] = daily.groupby('ts_code', group_keys=False).apply(
        get_prev_high_turnover_ma
    ).values
    
    is_volume_breakthrough = daily['turnover_ma'] > daily['prev_high_turnover_ma']
    valid_mask = valid_mask & is_volume_breakthrough.fillna(False)
    
    effective_new_high = daily[valid_mask].copy()
    print(f"æ¢æ‰‹ç‡ç¡®è®¤åï¼Œæ¯æ—¥æœ‰æ•ˆåˆ›æ–°é«˜æ ·æœ¬æ± æ„å»ºå®Œæˆï¼Œå…± {len(effective_new_high)} ä¸ªäº‹ä»¶ã€‚")

    # æ­¥éª¤ 3: è®¡ç®—æˆªé¢ç­›é€‰æ‰€éœ€æŒ‡æ ‡
    print("\n" + "=" * 60)
    print("æ­¥éª¤ 3: è®¡ç®—æˆªé¢ç­›é€‰æ‰€éœ€æŒ‡æ ‡")
    
    daily['prior_return'] = daily.groupby('ts_code')['close'].transform(
        lambda x: x.pct_change(periods=lookback_window).shift(1)
    )
    
    # è®¡ç®—å‰æœŸå¹³å‡æ¢æ‰‹ç‡
    daily['prior_turnover'] = daily.groupby('ts_code')['turnover_rate'].transform(
        lambda x: x.rolling(window=lookback_window).mean().shift(1)
    )

    effective_new_high = pd.merge(
        effective_new_high[['trade_date', 'ts_code']],
        daily[['trade_date', 'ts_code', 'prior_return', 'prior_turnover']],
        on=['trade_date', 'ts_code'],
        how='left'
    )

    # æ­¥éª¤ 4: åŠ¨æ€æˆªé¢ç­›é€‰ä¸æœ€ç»ˆå› å­ç”Ÿæˆ
    print("\n" + "=" * 60)
    print("æ­¥éª¤ 4: åŠ¨æ€æˆªé¢ç­›é€‰ä¸æœ€ç»ˆå› å­ç”Ÿæˆ")
    
    final_selection = []
    
    for date, group in effective_new_high.groupby('trade_date'):
        n = len(group)
        if n == 0:
            continue
            
        pr_median = group['prior_return'].quantile(0.5)
        pt_median = group['prior_turnover'].quantile(0.5)
        
        selected_group = None
        
        if n < n1_threshold:
            # æƒ…å†µä¸€ï¼šN < 20ï¼Œä»…ä½¿ç”¨æŒ‡æ ‡Aï¼ˆå‰æœŸæ¶¨è·Œå¹…ï¼‰
            selected_group = group[group['prior_return'] <= pr_median]
        else:
            # æƒ…å†µäºŒå’Œä¸‰ï¼šN >= 20ï¼Œç»¼åˆä½¿ç”¨æŒ‡æ ‡Aå’ŒæŒ‡æ ‡B
            # æ³¨ï¼šç”±äºç¼ºå°‘EPSæ•°æ®ï¼ŒN >= 50 æ—¶ä¹Ÿåªä½¿ç”¨Aå’ŒB
            selected_group = group[
                (group['prior_return'] <= pr_median) &
                (group['prior_turnover'] <= pt_median)
            ]
            
        if selected_group is not None and not selected_group.empty:
            final_selection.append(selected_group)

    if not final_selection:
        print("âš ï¸ è­¦å‘Šï¼šæ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ€ç»ˆå…¥é€‰çš„è‚¡ç¥¨ã€‚")
        return pd.DataFrame(columns=['factor']).rename_axis(['trade_date', 'ts_code'])
        
    final_df = pd.concat(final_selection, ignore_index=True)
    final_df['factor'] = 1.0
    
    factor_data = final_df[['trade_date', 'ts_code', 'factor']].set_index(['trade_date', 'ts_code'])
    
    print(f"\nâœ… åˆ›æ–°é«˜ç²¾é€‰ Alpha å› å­è®¡ç®—å®Œæˆï¼å…± {len(factor_data)} æ¡æœ‰æ•ˆè®°å½•ã€‚")
    
    return factor_data.loc[factor_data.index.get_level_values('trade_date') >= pd.to_datetime(start_date)]



def run_new_high_alpha_backtest(
    start_date: str = '2022-01-01',
    end_date: str = '2023-12-31',
    stock_codes: Optional[List[str]] = None,
    high_window: int = 240,
    volume_ma_window: int = 10,
    lookback_window: int = 60,
    rebalance_freq: str = 'weekly',
    transaction_cost: float = 0.0003,
) -> dict:
    """
    è¿è¡Œæ–°ç‰ˆåˆ›æ–°é«˜ç²¾é€‰Alphaå› å­ï¼ˆv2 - æ¢æ‰‹ç‡ç‰ˆæœ¬ï¼‰çš„å›æµ‹ã€‚
    
    ç”±äºå› å­æ˜¯äºŒå…ƒå€¼ï¼ˆ1/NaNï¼‰ï¼Œæ­¤å›æµ‹é‡‡ç”¨Long-Onlyç­–ç•¥ï¼Œ
    å³æ¯æ—¥ç­‰æƒæŒæœ‰æ‰€æœ‰å› å­å€¼ä¸º1çš„è‚¡ç¥¨ã€‚
    
    **é»˜è®¤è‚¡ç¥¨æ± **ï¼šä¸­è¯1000æˆåˆ†è‚¡

    Parameters
    ----------
    start_date, end_date : str
        å›æµ‹å‘¨æœŸã€‚
    stock_codes : Optional[List[str]]
        è‚¡ç¥¨æ± ã€‚å¦‚æœä¸ºNoneï¼Œåˆ™è‡ªåŠ¨ä½¿ç”¨ä¸­è¯1000æˆåˆ†è‚¡ã€‚
    high_window, volume_ma_window, lookback_window : int
        å› å­è®¡ç®—æ‰€éœ€å‚æ•°ã€‚
    rebalance_freq : str
        è°ƒä»“é¢‘ç‡ï¼Œç”¨äºä¼°ç®—äº¤æ˜“æˆæœ¬ã€‚
    transaction_cost : float
        å•è¾¹äº¤æ˜“æˆæœ¬ã€‚

    Returns
    -------
    dict
        åŒ…å«å›æµ‹ç»“æœçš„å­—å…¸ã€‚
    """
    # åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
    data_manager = DataManager()
    
    # è®¡ç®—å› å­
    factor_data = calculate_new_high_alpha_factor(
        data_manager=data_manager,
        start_date=start_date,
        end_date=end_date,
        stock_codes=stock_codes,
        high_window=high_window,
        volume_ma_window=volume_ma_window,
        lookback_window=lookback_window,
    )
    
    if factor_data.empty:
        print("å› å­æ•°æ®ä¸ºç©ºï¼Œæ— æ³•å›æµ‹ã€‚")
        return {
            'factor_data': None,
            'portfolio_returns': None,
            'performance_metrics': {},
            'analysis_results': {}
        }
        
    # å‡†å¤‡æ”¶ç›Šç‡æ•°æ®
    stock_list = factor_data.index.get_level_values('ts_code').unique().tolist()
    
    stock_data = data_manager.load_data(
        'daily',
        start_date=start_date,
        end_date=end_date,
        stock_codes=stock_list
    )
    if stock_data is None or stock_data.empty:
        raise ValueError("æ— æ³•åŠ è½½ç”¨äºå›æµ‹çš„è‚¡ç¥¨æ•°æ®ã€‚")

    stock_data['trade_date'] = pd.to_datetime(stock_data['trade_date'])
    stock_data = stock_data.sort_values(['ts_code', 'trade_date'])
    # è®¡ç®—ä¸‹ä¸€æ—¥æ”¶ç›Šç‡ï¼š(æ˜å¤©çš„æ”¶ç›˜ä»· / ä»Šå¤©çš„æ”¶ç›˜ä»·) - 1
    stock_data['next_close'] = stock_data.groupby('ts_code')['close'].shift(-1)
    stock_data['next_return'] = (stock_data['next_close'] / stock_data['close']) - 1
    
    # åˆå¹¶æ•°æ®
    combined = pd.merge(
        factor_data.reset_index(),
        stock_data[['trade_date', 'ts_code', 'next_return']],
        on=['trade_date', 'ts_code'],
        how='inner'
    )
    
    # å»é™¤NaNå€¼
    combined = combined.dropna(subset=['next_return'])
    
    # è®¡ç®— Long-Only ç»„åˆæ¯æ—¥æ”¶ç›Š
    portfolio_returns = combined.groupby('trade_date')['next_return'].mean()
    
    # æ¨¡æ‹Ÿäº¤æ˜“æˆæœ¬
    # è·å–è°ƒä»“æ—¥
    if rebalance_freq == 'daily':
        rebalance_dates = portfolio_returns.index
    else:
        freq_map = {'weekly': 'W-MON', 'monthly': 'MS'}
        rebalance_dates = pd.date_range(start=start_date, end=end_date, freq=freq_map.get(rebalance_freq))
    
    # è¿‘ä¼¼æ¢æ‰‹ç‡æˆæœ¬
    if rebalance_dates is not None and len(portfolio_returns) > 0:
        cost_impact = len(rebalance_dates) * transaction_cost / len(portfolio_returns)
        portfolio_returns -= cost_impact
    
    # è®¡ç®—ä¸šç»©æŒ‡æ ‡
    cum_returns = (1 + portfolio_returns).cumprod()
    total_return = cum_returns.iloc[-1] - 1 if not cum_returns.empty else 0
    
    days = len(portfolio_returns)
    annualized_return = (1 + total_return) ** (252 / days) - 1 if days > 0 else 0
    
    volatility = portfolio_returns.std() * np.sqrt(252)
    sharpe_ratio = annualized_return / volatility if volatility > 0 else 0
    
    running_max = cum_returns.cummax()
    drawdown = cum_returns / running_max - 1
    max_drawdown = drawdown.min() if not drawdown.empty else 0

    return {
        'factor_data': factor_data,
        'portfolio_returns': portfolio_returns,
        'performance_metrics': {
            'total_return': total_return,
            'annualized_return': annualized_return,
            'volatility': volatility,
            'sharpe_ratio': sharpe_ratio,
            'max_drawdown': max_drawdown,
        },
        'analysis_results': {}
    }



def main():
    """ä¸»å‡½æ•°ï¼šæ¼”ç¤ºæ–°ç‰ˆåˆ›æ–°é«˜ç²¾é€‰Alphaå› å­è®¡ç®—å’Œå›æµ‹ï¼ˆä½¿ç”¨ä¸­è¯1000æˆåˆ†è‚¡ï¼‰"""
    print("=" * 60)
    print("åˆ›æ–°é«˜ç²¾é€‰ Alpha å› å­ (v2 - æ¢æ‰‹ç‡ç‰ˆæœ¬)")
    print("è‚¡ç¥¨æ± : ä¸­è¯1000æˆåˆ†è‚¡")
    print("=" * 60)

    try:
        # é…ç½®å‚æ•°
        config = {
            'start_date': '2019-01-01',
            'end_date': '2020-12-31',
            'high_window': 240,
            'volume_ma_window': 10,
            'lookback_window': 60,
            'rebalance_freq': 'weekly',
            'transaction_cost': 0.0003,
        }

        print("\nå›æµ‹é…ç½®:")
        for key, value in config.items():
            print(f"  {key}: {value}")

        # è¿è¡Œå›æµ‹
        results = run_new_high_alpha_backtest(**config)

        # æ‰“å°ç»“æœ
        print("\n" + "=" * 60)
        print("å›æµ‹ç»“æœ")
        print("=" * 60)

        if results['portfolio_returns'] is not None:
            metrics = results['performance_metrics']
            print(f"\nğŸ“Š ä¸šç»©æŒ‡æ ‡:")
            print(f"  æ€»æ”¶ç›Šç‡: {metrics['total_return']:.2%}")
            print(f"  å¹´åŒ–æ”¶ç›Šç‡: {metrics['annualized_return']:.2%}")
            print(f"  å¹´åŒ–æ³¢åŠ¨ç‡: {metrics['volatility']:.2%}")
            print(f"  å¤æ™®æ¯”ç‡: {metrics['sharpe_ratio']:.2f}")
            print(f"  æœ€å¤§å›æ’¤: {metrics['max_drawdown']:.2%}")

            print(f"\nğŸ“ˆ å› å­è¦†ç›–:")
            factor_data = results['factor_data']
            print(f"  æœ‰æ•ˆå› å­è®°å½•æ•°: {len(factor_data)}")
            print(f"  è¦†ç›–è‚¡ç¥¨æ•°: {factor_data.index.get_level_values('ts_code').nunique()}")
            print(f"  è¦†ç›–äº¤æ˜“æ—¥æ•°: {factor_data.index.get_level_values('trade_date').nunique()}")
        else:
            print("âš ï¸ å›æµ‹å¤±è´¥ï¼Œæ— å¯ç”¨æ•°æ®ã€‚")

    except Exception as e:
        print(f"\nâŒ è¿è¡Œå‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()
